{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['yafim', 'zeev', 'or', 'ron', 'sergey', 'aviya', 'elnatan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 7590.61it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 7523.15it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 7612.90it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8253.71it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8092.66it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8185.13it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8200.85it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8630.42it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 7876.62it/s]\n",
      "100%|██████████| 22000/22000 [00:02<00:00, 8716.62it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8396.37it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8050.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for d in dates:\n",
    "    for i, l in enumerate(labels):\n",
    "        for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "            x_data.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "            y_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.asarray(x_data)\n",
    "y_data = np.asarray(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136000, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108800, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 1217],\n",
       "       [   1, 5007],\n",
       "       [   2, 6636],\n",
       "       [   3, 6658],\n",
       "       [   4, 1153],\n",
       "       [   5, 5896],\n",
       "       [   6,  633]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 528,391\n",
      "Trainable params: 528,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (108800, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9ec12f1cdbc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2438\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2440\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2441\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    491\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         raise ValueError('You are passing a target array of shape ' + str(\n\u001b[0;32m--> 493\u001b[0;31m             y.shape) + ' while using as loss `categorical_crossentropy`. '\n\u001b[0m\u001b[1;32m    494\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (108800, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256, epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27200/27200 [==============================] - 1s 45us/sample - loss: 2.1906 - acc: 0.0249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1906236864538755, 0.02492647]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "    [32, 512, 0.2],\n",
    "    [32, 256, 0.2],\n",
    "    [32, 512, 0.1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(config):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(conf[0], conf[0])),\n",
    "        tf.keras.layers.Dense(conf[1], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(conf[2]),\n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108800 samples, validate on 27200 samples\n",
      "Epoch 1/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 1.1719 - acc: 0.4724 - val_loss: 0.9985 - val_acc: 0.5406\n",
      "Epoch 2/50\n",
      "108800/108800 [==============================] - 4s 34us/sample - loss: 0.9623 - acc: 0.5655 - val_loss: 0.9232 - val_acc: 0.5921\n",
      "Epoch 3/50\n",
      "108800/108800 [==============================] - 4s 34us/sample - loss: 0.9195 - acc: 0.5900 - val_loss: 0.8833 - val_acc: 0.6138\n",
      "Epoch 4/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.9030 - acc: 0.5976 - val_loss: 0.8786 - val_acc: 0.6143\n",
      "Epoch 5/50\n",
      "108800/108800 [==============================] - 4s 34us/sample - loss: 0.8800 - acc: 0.6123 - val_loss: 0.8536 - val_acc: 0.6253\n",
      "Epoch 6/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.8679 - acc: 0.6176 - val_loss: 0.8583 - val_acc: 0.6181\n",
      "Epoch 7/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.8555 - acc: 0.6227 - val_loss: 0.8883 - val_acc: 0.6030\n",
      "Epoch 8/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.8460 - acc: 0.6268 - val_loss: 0.8320 - val_acc: 0.6357\n",
      "Epoch 9/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8322 - acc: 0.6358 - val_loss: 0.8254 - val_acc: 0.6358\n",
      "Epoch 10/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8251 - acc: 0.6397 - val_loss: 0.8059 - val_acc: 0.6469\n",
      "Epoch 11/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.8173 - acc: 0.6439 - val_loss: 0.8007 - val_acc: 0.6546\n",
      "Epoch 12/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8018 - acc: 0.6531 - val_loss: 0.8122 - val_acc: 0.6461\n",
      "Epoch 13/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8019 - acc: 0.6538 - val_loss: 0.7921 - val_acc: 0.6588\n",
      "Epoch 14/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7890 - acc: 0.6600 - val_loss: 0.7952 - val_acc: 0.6541\n",
      "Epoch 15/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7908 - acc: 0.6596 - val_loss: 0.7826 - val_acc: 0.6643\n",
      "Epoch 16/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7856 - acc: 0.6619 - val_loss: 0.7645 - val_acc: 0.6721\n",
      "Epoch 17/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7790 - acc: 0.6644 - val_loss: 0.7890 - val_acc: 0.6605\n",
      "Epoch 18/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7796 - acc: 0.6639 - val_loss: 0.7737 - val_acc: 0.6686\n",
      "Epoch 19/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7687 - acc: 0.6695 - val_loss: 0.7754 - val_acc: 0.6661\n",
      "Epoch 20/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7733 - acc: 0.6681 - val_loss: 0.7730 - val_acc: 0.6739\n",
      "Epoch 21/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7631 - acc: 0.6729 - val_loss: 0.7616 - val_acc: 0.6753\n",
      "Epoch 22/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7600 - acc: 0.6744 - val_loss: 0.7634 - val_acc: 0.6726\n",
      "Epoch 23/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7615 - acc: 0.6747 - val_loss: 0.7587 - val_acc: 0.6800\n",
      "Epoch 24/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7608 - acc: 0.6744 - val_loss: 0.7557 - val_acc: 0.6798\n",
      "Epoch 25/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7621 - acc: 0.6733 - val_loss: 0.7534 - val_acc: 0.6811\n",
      "Epoch 26/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7555 - acc: 0.6765 - val_loss: 0.7665 - val_acc: 0.6746\n",
      "Epoch 27/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7565 - acc: 0.6765 - val_loss: 0.7333 - val_acc: 0.6893\n",
      "Epoch 28/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7489 - acc: 0.6777 - val_loss: 0.7422 - val_acc: 0.6824\n",
      "Epoch 29/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7414 - acc: 0.6835 - val_loss: 0.7600 - val_acc: 0.6801\n",
      "Epoch 30/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7322 - acc: 0.6882 - val_loss: 0.7324 - val_acc: 0.6889\n",
      "Epoch 31/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7441 - acc: 0.6808 - val_loss: 0.7461 - val_acc: 0.6784\n",
      "Epoch 32/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7434 - acc: 0.6812 - val_loss: 0.7465 - val_acc: 0.6804\n",
      "Epoch 33/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7357 - acc: 0.6855 - val_loss: 0.7477 - val_acc: 0.6829\n",
      "Epoch 34/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7343 - acc: 0.6870 - val_loss: 0.7565 - val_acc: 0.6777\n",
      "Epoch 35/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7309 - acc: 0.6875 - val_loss: 0.7397 - val_acc: 0.6826\n",
      "Epoch 36/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7212 - acc: 0.6914 - val_loss: 0.7404 - val_acc: 0.6849\n",
      "Epoch 37/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7168 - acc: 0.6947 - val_loss: 0.7334 - val_acc: 0.6873\n",
      "Epoch 38/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7111 - acc: 0.6971 - val_loss: 0.7177 - val_acc: 0.6962\n",
      "Epoch 39/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7032 - acc: 0.7011 - val_loss: 0.7304 - val_acc: 0.6912\n",
      "Epoch 40/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7118 - acc: 0.6973 - val_loss: 0.7288 - val_acc: 0.6898\n",
      "Epoch 41/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7092 - acc: 0.6983 - val_loss: 0.7119 - val_acc: 0.6963\n",
      "Epoch 42/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7051 - acc: 0.6995 - val_loss: 0.7279 - val_acc: 0.6899\n",
      "Epoch 43/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7092 - acc: 0.6973 - val_loss: 0.7253 - val_acc: 0.6915\n",
      "Epoch 44/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7094 - acc: 0.6969 - val_loss: 0.7311 - val_acc: 0.6877\n",
      "Epoch 45/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6954 - acc: 0.7039 - val_loss: 0.7136 - val_acc: 0.7004\n",
      "Epoch 46/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7005 - acc: 0.6998 - val_loss: 0.6997 - val_acc: 0.7056\n",
      "Epoch 47/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.6883 - acc: 0.7074 - val_loss: 0.7215 - val_acc: 0.6916\n",
      "Epoch 48/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6951 - acc: 0.7030 - val_loss: 0.7176 - val_acc: 0.6938\n",
      "Epoch 49/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.6884 - acc: 0.7088 - val_loss: 0.7205 - val_acc: 0.6957\n",
      "Epoch 50/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6874 - acc: 0.7063 - val_loss: 0.7060 - val_acc: 0.7012\n",
      "27200/27200 [==============================] - 1s 46us/sample - loss: 0.7060 - acc: 0.7012\n",
      "Train on 108800 samples, validate on 27200 samples\n",
      "Epoch 1/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 1.1763 - acc: 0.4685 - val_loss: 0.9704 - val_acc: 0.5686\n",
      "Epoch 2/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.9655 - acc: 0.5664 - val_loss: 0.9047 - val_acc: 0.6033\n",
      "Epoch 3/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.9294 - acc: 0.5861 - val_loss: 0.8849 - val_acc: 0.6109\n",
      "Epoch 4/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.8988 - acc: 0.6023 - val_loss: 0.8722 - val_acc: 0.6194\n",
      "Epoch 5/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.8859 - acc: 0.6085 - val_loss: 0.8641 - val_acc: 0.6187\n",
      "Epoch 6/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.8685 - acc: 0.6182 - val_loss: 0.8586 - val_acc: 0.6186\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8554 - acc: 0.6229 - val_loss: 0.8330 - val_acc: 0.6333\n",
      "Epoch 8/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8436 - acc: 0.6304 - val_loss: 0.8177 - val_acc: 0.6419\n",
      "Epoch 9/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8327 - acc: 0.6365 - val_loss: 0.8109 - val_acc: 0.6472\n",
      "Epoch 10/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8293 - acc: 0.6373 - val_loss: 0.8168 - val_acc: 0.6439\n",
      "Epoch 11/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8144 - acc: 0.6460 - val_loss: 0.8169 - val_acc: 0.6438\n",
      "Epoch 12/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.8097 - acc: 0.6469 - val_loss: 0.7956 - val_acc: 0.6541\n",
      "Epoch 13/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.8026 - acc: 0.6523 - val_loss: 0.7946 - val_acc: 0.6590\n",
      "Epoch 14/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.8020 - acc: 0.6524 - val_loss: 0.7888 - val_acc: 0.6561\n",
      "Epoch 15/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7989 - acc: 0.6532 - val_loss: 0.7870 - val_acc: 0.6600\n",
      "Epoch 16/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7907 - acc: 0.6593 - val_loss: 0.7768 - val_acc: 0.6690\n",
      "Epoch 17/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7873 - acc: 0.6604 - val_loss: 0.7785 - val_acc: 0.6652\n",
      "Epoch 18/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7731 - acc: 0.6678 - val_loss: 0.7871 - val_acc: 0.6590\n",
      "Epoch 19/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7728 - acc: 0.6681 - val_loss: 0.7816 - val_acc: 0.6631\n",
      "Epoch 20/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7715 - acc: 0.6684 - val_loss: 0.7728 - val_acc: 0.6637\n",
      "Epoch 21/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7660 - acc: 0.6706 - val_loss: 0.7575 - val_acc: 0.6778\n",
      "Epoch 22/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7546 - acc: 0.6778 - val_loss: 0.7566 - val_acc: 0.6747\n",
      "Epoch 23/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 0.7622 - acc: 0.6737 - val_loss: 0.7474 - val_acc: 0.6829\n",
      "Epoch 24/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7598 - acc: 0.6733 - val_loss: 0.7668 - val_acc: 0.6724\n",
      "Epoch 25/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7556 - acc: 0.6777 - val_loss: 0.7525 - val_acc: 0.6801\n",
      "Epoch 26/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7477 - acc: 0.6804 - val_loss: 0.7534 - val_acc: 0.6754\n",
      "Epoch 27/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 0.7483 - acc: 0.6788 - val_loss: 0.7624 - val_acc: 0.6742\n",
      "Epoch 28/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7452 - acc: 0.6819 - val_loss: 0.7338 - val_acc: 0.6845\n",
      "Epoch 29/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7396 - acc: 0.6831 - val_loss: 0.7505 - val_acc: 0.6785\n",
      "Epoch 30/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 0.7453 - acc: 0.6809 - val_loss: 0.7371 - val_acc: 0.6882\n",
      "Epoch 31/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7316 - acc: 0.6899 - val_loss: 0.7412 - val_acc: 0.6849\n",
      "Epoch 32/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7352 - acc: 0.6877 - val_loss: 0.7418 - val_acc: 0.6813\n",
      "Epoch 33/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7340 - acc: 0.6858 - val_loss: 0.7379 - val_acc: 0.6851\n",
      "Epoch 34/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7297 - acc: 0.6901 - val_loss: 0.7387 - val_acc: 0.6856\n",
      "Epoch 35/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 0.7245 - acc: 0.6913 - val_loss: 0.7572 - val_acc: 0.6814\n",
      "Epoch 36/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7252 - acc: 0.6904 - val_loss: 0.7476 - val_acc: 0.6787\n",
      "Epoch 37/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7370 - acc: 0.6857 - val_loss: 0.7213 - val_acc: 0.6954\n",
      "Epoch 38/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7217 - acc: 0.6928 - val_loss: 0.7274 - val_acc: 0.6914\n",
      "Epoch 39/50\n",
      "108800/108800 [==============================] - 3s 26us/sample - loss: 0.7253 - acc: 0.6896 - val_loss: 0.7360 - val_acc: 0.6855\n",
      "Epoch 40/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7124 - acc: 0.6973 - val_loss: 0.7386 - val_acc: 0.6873\n",
      "Epoch 41/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7282 - acc: 0.6875 - val_loss: 0.7456 - val_acc: 0.6784\n",
      "Epoch 42/50\n",
      "108800/108800 [==============================] - 3s 25us/sample - loss: 0.7231 - acc: 0.6910 - val_loss: 0.7305 - val_acc: 0.6904\n",
      "Epoch 43/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7210 - acc: 0.6911 - val_loss: 0.7626 - val_acc: 0.6734\n",
      "Epoch 44/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7219 - acc: 0.6901 - val_loss: 0.7228 - val_acc: 0.6885\n",
      "Epoch 45/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7119 - acc: 0.6970 - val_loss: 0.7210 - val_acc: 0.6915\n",
      "Epoch 46/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7114 - acc: 0.6953 - val_loss: 0.7193 - val_acc: 0.6968\n",
      "Epoch 47/50\n",
      "108800/108800 [==============================] - 3s 24us/sample - loss: 0.7131 - acc: 0.6944 - val_loss: 0.7252 - val_acc: 0.6928\n",
      "Epoch 48/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7136 - acc: 0.6930 - val_loss: 0.7240 - val_acc: 0.6919\n",
      "Epoch 49/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7074 - acc: 0.6961 - val_loss: 0.7170 - val_acc: 0.6966\n",
      "Epoch 50/50\n",
      "108800/108800 [==============================] - 3s 23us/sample - loss: 0.7069 - acc: 0.6966 - val_loss: 0.7264 - val_acc: 0.6867\n",
      "27200/27200 [==============================] - 1s 30us/sample - loss: 0.7264 - acc: 0.6867\n",
      "Train on 108800 samples, validate on 27200 samples\n",
      "Epoch 1/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 1.1638 - acc: 0.4799 - val_loss: 0.9658 - val_acc: 0.5684\n",
      "Epoch 2/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.9492 - acc: 0.5752 - val_loss: 0.9110 - val_acc: 0.5873\n",
      "Epoch 3/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.9126 - acc: 0.5936 - val_loss: 0.9229 - val_acc: 0.5904\n",
      "Epoch 4/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8903 - acc: 0.6082 - val_loss: 0.8602 - val_acc: 0.6221\n",
      "Epoch 5/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.8639 - acc: 0.6212 - val_loss: 0.8427 - val_acc: 0.6342\n",
      "Epoch 6/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8565 - acc: 0.6256 - val_loss: 0.8284 - val_acc: 0.6415\n",
      "Epoch 7/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8378 - acc: 0.6347 - val_loss: 0.8272 - val_acc: 0.6410\n",
      "Epoch 8/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.8294 - acc: 0.6389 - val_loss: 0.8309 - val_acc: 0.6382\n",
      "Epoch 9/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.8110 - acc: 0.6492 - val_loss: 0.8061 - val_acc: 0.6526\n",
      "Epoch 10/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8052 - acc: 0.6513 - val_loss: 0.7895 - val_acc: 0.6612\n",
      "Epoch 11/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7947 - acc: 0.6570 - val_loss: 0.7839 - val_acc: 0.6642\n",
      "Epoch 12/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7878 - acc: 0.6609 - val_loss: 0.7860 - val_acc: 0.6624\n",
      "Epoch 13/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7791 - acc: 0.6642 - val_loss: 0.7704 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7758 - acc: 0.6661 - val_loss: 0.7641 - val_acc: 0.6736\n",
      "Epoch 15/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7664 - acc: 0.6714 - val_loss: 0.7602 - val_acc: 0.6761\n",
      "Epoch 16/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7597 - acc: 0.6735 - val_loss: 0.7752 - val_acc: 0.6662\n",
      "Epoch 17/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7571 - acc: 0.6776 - val_loss: 0.7566 - val_acc: 0.6770\n",
      "Epoch 18/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7464 - acc: 0.6816 - val_loss: 0.7541 - val_acc: 0.6793\n",
      "Epoch 19/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7320 - acc: 0.6880 - val_loss: 0.7470 - val_acc: 0.6815\n",
      "Epoch 20/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7268 - acc: 0.6912 - val_loss: 0.7460 - val_acc: 0.6843\n",
      "Epoch 21/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7227 - acc: 0.6956 - val_loss: 0.7425 - val_acc: 0.6818\n",
      "Epoch 22/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7179 - acc: 0.6964 - val_loss: 0.7476 - val_acc: 0.6800\n",
      "Epoch 23/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7164 - acc: 0.6961 - val_loss: 0.7552 - val_acc: 0.6760\n",
      "Epoch 24/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7114 - acc: 0.6988 - val_loss: 0.7335 - val_acc: 0.6865\n",
      "Epoch 25/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7035 - acc: 0.7025 - val_loss: 0.7596 - val_acc: 0.6773\n",
      "Epoch 26/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6917 - acc: 0.7086 - val_loss: 0.7327 - val_acc: 0.6910\n",
      "Epoch 27/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.6966 - acc: 0.7060 - val_loss: 0.7376 - val_acc: 0.6900\n",
      "Epoch 28/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6844 - acc: 0.7133 - val_loss: 0.7247 - val_acc: 0.6948\n",
      "Epoch 29/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6743 - acc: 0.7177 - val_loss: 0.7056 - val_acc: 0.7035\n",
      "Epoch 30/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6696 - acc: 0.7206 - val_loss: 0.7015 - val_acc: 0.7064\n",
      "Epoch 31/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6701 - acc: 0.7192 - val_loss: 0.7100 - val_acc: 0.6985\n",
      "Epoch 32/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6507 - acc: 0.7290 - val_loss: 0.7013 - val_acc: 0.7083\n",
      "Epoch 33/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6491 - acc: 0.7296 - val_loss: 0.7210 - val_acc: 0.6995\n",
      "Epoch 34/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6550 - acc: 0.7295 - val_loss: 0.7041 - val_acc: 0.7063\n",
      "Epoch 35/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6455 - acc: 0.7326 - val_loss: 0.7150 - val_acc: 0.7003\n",
      "Epoch 36/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6449 - acc: 0.7319 - val_loss: 0.6794 - val_acc: 0.7204\n",
      "Epoch 37/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6352 - acc: 0.7383 - val_loss: 0.7091 - val_acc: 0.7056\n",
      "Epoch 38/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6296 - acc: 0.7395 - val_loss: 0.6872 - val_acc: 0.7142\n",
      "Epoch 39/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6283 - acc: 0.7408 - val_loss: 0.6951 - val_acc: 0.7124\n",
      "Epoch 40/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6288 - acc: 0.7392 - val_loss: 0.6911 - val_acc: 0.7104\n",
      "Epoch 41/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6286 - acc: 0.7386 - val_loss: 0.6997 - val_acc: 0.7115\n",
      "Epoch 42/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6187 - acc: 0.7437 - val_loss: 0.6803 - val_acc: 0.7180\n",
      "Epoch 43/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6162 - acc: 0.7459 - val_loss: 0.6752 - val_acc: 0.7224\n",
      "Epoch 44/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6212 - acc: 0.7450 - val_loss: 0.6822 - val_acc: 0.7201\n",
      "Epoch 45/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6158 - acc: 0.7443 - val_loss: 0.7134 - val_acc: 0.7024\n",
      "Epoch 46/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.6053 - acc: 0.7511 - val_loss: 0.6868 - val_acc: 0.7156\n",
      "Epoch 47/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6063 - acc: 0.7506 - val_loss: 0.6663 - val_acc: 0.7256\n",
      "Epoch 48/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.6047 - acc: 0.7513 - val_loss: 0.6749 - val_acc: 0.7217\n",
      "Epoch 49/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.5970 - acc: 0.7540 - val_loss: 0.6648 - val_acc: 0.7259\n",
      "Epoch 50/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.5858 - acc: 0.7601 - val_loss: 0.6649 - val_acc: 0.7292\n",
      "27200/27200 [==============================] - 1s 45us/sample - loss: 0.6649 - acc: 0.7292\n"
     ]
    }
   ],
   "source": [
    "for conf in conf_list:\n",
    "    curr_dt = set_curr_time()\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/{0}_{1}'.format(conf, curr_dt),\n",
    "                                                 histogram_freq=0, write_graph=True)\n",
    "    model = custom_model(conf)\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256,\n",
    "              epochs=50, callbacks=[tb_callback])\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save('../models/{0}_{1}.h5'.format(conf, curr_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### continues training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = tf.keras.models.load_model('../models/[32, 512, 0.1]_201953_12_56.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108800 samples, validate on 27200 samples\n",
      "Epoch 1/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.9533 - acc: 0.5728 - val_loss: 0.8804 - val_acc: 0.6037\n",
      "Epoch 2/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.8633 - acc: 0.6125 - val_loss: 0.8448 - val_acc: 0.6270\n",
      "Epoch 3/50\n",
      "108800/108800 [==============================] - 4s 35us/sample - loss: 0.8428 - acc: 0.6237 - val_loss: 0.8382 - val_acc: 0.6372\n",
      "Epoch 4/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8259 - acc: 0.6343 - val_loss: 0.8250 - val_acc: 0.6406\n",
      "Epoch 5/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8123 - acc: 0.6428 - val_loss: 0.8121 - val_acc: 0.6474\n",
      "Epoch 6/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.8077 - acc: 0.6449 - val_loss: 0.8207 - val_acc: 0.6395\n",
      "Epoch 7/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7951 - acc: 0.6513 - val_loss: 0.7967 - val_acc: 0.6546\n",
      "Epoch 8/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7880 - acc: 0.6566 - val_loss: 0.7901 - val_acc: 0.6597\n",
      "Epoch 9/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7831 - acc: 0.6574 - val_loss: 0.7818 - val_acc: 0.6629\n",
      "Epoch 10/50\n",
      "108800/108800 [==============================] - 4s 40us/sample - loss: 0.7834 - acc: 0.6570 - val_loss: 0.8114 - val_acc: 0.6393\n",
      "Epoch 11/50\n",
      "108800/108800 [==============================] - 4s 40us/sample - loss: 0.7759 - acc: 0.6616 - val_loss: 0.8109 - val_acc: 0.6441\n",
      "Epoch 12/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7735 - acc: 0.6634 - val_loss: 0.7842 - val_acc: 0.6635\n",
      "Epoch 13/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7687 - acc: 0.6654 - val_loss: 0.7988 - val_acc: 0.6469\n",
      "Epoch 14/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7667 - acc: 0.6675 - val_loss: 0.7736 - val_acc: 0.6702\n",
      "Epoch 15/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7620 - acc: 0.6713 - val_loss: 0.7719 - val_acc: 0.6681\n",
      "Epoch 16/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7605 - acc: 0.6715 - val_loss: 0.7724 - val_acc: 0.6681\n",
      "Epoch 17/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7571 - acc: 0.6725 - val_loss: 0.7759 - val_acc: 0.6672\n",
      "Epoch 18/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7527 - acc: 0.6744 - val_loss: 0.7653 - val_acc: 0.6707\n",
      "Epoch 19/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7520 - acc: 0.6736 - val_loss: 0.7712 - val_acc: 0.6673\n",
      "Epoch 20/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7497 - acc: 0.6755 - val_loss: 0.7593 - val_acc: 0.6749\n",
      "Epoch 21/50\n",
      "108800/108800 [==============================] - 4s 41us/sample - loss: 0.7469 - acc: 0.6775 - val_loss: 0.7533 - val_acc: 0.6785\n",
      "Epoch 22/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7466 - acc: 0.6771 - val_loss: 0.7613 - val_acc: 0.6717\n",
      "Epoch 23/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7399 - acc: 0.6807 - val_loss: 0.7572 - val_acc: 0.6757\n",
      "Epoch 24/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7435 - acc: 0.6790 - val_loss: 0.7628 - val_acc: 0.6739\n",
      "Epoch 25/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7370 - acc: 0.6821 - val_loss: 0.7538 - val_acc: 0.6794\n",
      "Epoch 26/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7389 - acc: 0.6811 - val_loss: 0.7552 - val_acc: 0.6761\n",
      "Epoch 27/50\n",
      "108800/108800 [==============================] - 4s 40us/sample - loss: 0.7327 - acc: 0.6840 - val_loss: 0.7598 - val_acc: 0.6718\n",
      "Epoch 28/50\n",
      "108800/108800 [==============================] - 5s 42us/sample - loss: 0.7339 - acc: 0.6837 - val_loss: 0.7482 - val_acc: 0.6826\n",
      "Epoch 29/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7314 - acc: 0.6853 - val_loss: 0.7791 - val_acc: 0.6643\n",
      "Epoch 30/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7272 - acc: 0.6871 - val_loss: 0.7527 - val_acc: 0.6800\n",
      "Epoch 31/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7302 - acc: 0.6842 - val_loss: 0.7570 - val_acc: 0.6764\n",
      "Epoch 32/50\n",
      "108800/108800 [==============================] - 4s 40us/sample - loss: 0.7274 - acc: 0.6870 - val_loss: 0.7723 - val_acc: 0.6673\n",
      "Epoch 33/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7285 - acc: 0.6873 - val_loss: 0.7525 - val_acc: 0.6787\n",
      "Epoch 34/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7225 - acc: 0.6901 - val_loss: 0.7474 - val_acc: 0.6800\n",
      "Epoch 35/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7215 - acc: 0.6894 - val_loss: 0.7562 - val_acc: 0.6786\n",
      "Epoch 36/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7189 - acc: 0.6902 - val_loss: 0.7636 - val_acc: 0.6690\n",
      "Epoch 37/50\n",
      "108800/108800 [==============================] - 4s 36us/sample - loss: 0.7215 - acc: 0.6898 - val_loss: 0.7663 - val_acc: 0.6725\n",
      "Epoch 38/50\n",
      "108800/108800 [==============================] - 4s 40us/sample - loss: 0.7191 - acc: 0.6907 - val_loss: 0.7460 - val_acc: 0.6797\n",
      "Epoch 39/50\n",
      "108800/108800 [==============================] - 5s 44us/sample - loss: 0.7152 - acc: 0.6915 - val_loss: 0.7463 - val_acc: 0.6796\n",
      "Epoch 40/50\n",
      "108800/108800 [==============================] - 5s 50us/sample - loss: 0.7145 - acc: 0.6927 - val_loss: 0.7654 - val_acc: 0.6740\n",
      "Epoch 41/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7165 - acc: 0.6909 - val_loss: 0.7397 - val_acc: 0.6865\n",
      "Epoch 42/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7144 - acc: 0.6930 - val_loss: 0.7412 - val_acc: 0.6842\n",
      "Epoch 43/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7135 - acc: 0.6926 - val_loss: 0.7520 - val_acc: 0.6783\n",
      "Epoch 44/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7111 - acc: 0.6950 - val_loss: 0.7364 - val_acc: 0.6866\n",
      "Epoch 45/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7095 - acc: 0.6947 - val_loss: 0.7483 - val_acc: 0.6853\n",
      "Epoch 46/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7090 - acc: 0.6946 - val_loss: 0.7447 - val_acc: 0.6838\n",
      "Epoch 47/50\n",
      "108800/108800 [==============================] - 4s 39us/sample - loss: 0.7078 - acc: 0.6953 - val_loss: 0.7563 - val_acc: 0.6780\n",
      "Epoch 48/50\n",
      "108800/108800 [==============================] - 4s 37us/sample - loss: 0.7116 - acc: 0.6932 - val_loss: 0.7551 - val_acc: 0.6820\n",
      "Epoch 49/50\n",
      "108800/108800 [==============================] - 4s 41us/sample - loss: 0.7105 - acc: 0.6956 - val_loss: 0.7501 - val_acc: 0.6801\n",
      "Epoch 50/50\n",
      "108800/108800 [==============================] - 4s 38us/sample - loss: 0.7052 - acc: 0.6981 - val_loss: 0.7825 - val_acc: 0.6661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ce83e10>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256,\n",
    "              epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27200/27200 [==============================] - 1s 46us/sample - loss: 0.7825 - acc: 0.6661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7825135770615409, 0.66610295]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/[32, 512, 0.2]_201953_12_51.h5\n",
      "27200/27200 [==============================] - 1s 54us/sample - loss: 0.7060 - acc: 0.7012\n",
      "../models/[32, 256, 0.2]_201953_12_54.h5\n",
      "27200/27200 [==============================] - 1s 44us/sample - loss: 0.7264 - acc: 0.6867\n",
      "../models/[32, 512, 0.1]_201953_12_56.h5\n",
      "27200/27200 [==============================] - 2s 59us/sample - loss: 0.6649 - acc: 0.7292\n",
      "../models/[32, 512, 0.2]_201953_12_46.h5\n",
      "27200/27200 [==============================] - 2s 61us/sample - loss: 0.7218 - acc: 0.6947\n"
     ]
    }
   ],
   "source": [
    "for model_path in glob.glob('../models/*.h5'):\n",
    "    print(model_path)\n",
    "    best_loaded = tf.keras.models.load_model(model_path)\n",
    "    best_loaded.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
