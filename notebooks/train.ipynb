{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['zeev', 'or', 'ron', 'aviya', 'felix']\n",
    "\n",
    "TRAIN_AND_VALIDATION_TEST_SPLIT = 0.3\n",
    "VALID_AND_TEST_SPLIT           = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified data\n",
    "x_train = [] \n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "x_test  = []\n",
    "y_test  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test):  \n",
    "    # for i, l in enumerate(labels):\n",
    "    for d in dates:\n",
    "        for i, l in enumerate(labels):\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "                x_data.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "                y_data.append(i)\n",
    "            x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "                             = train_test_split(x_data, y_data, test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "            x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "                         = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "            x_train.append(x_train_label)\n",
    "            y_train.append(y_train_label)\n",
    "            x_test.append(x_test_label)\n",
    "            y_test.append(y_test_label)\n",
    "            x_valid.append(x_valid_label)\n",
    "            y_valid.append(y_valid_label)\n",
    "\n",
    "    x_train = list(itertools.chain.from_iterable(x_train))\n",
    "    y_train = list(itertools.chain.from_iterable(y_train))\n",
    "    x_test = list(itertools.chain.from_iterable(x_test))\n",
    "    y_test = list(itertools.chain.from_iterable(y_test))\n",
    "    x_valid = list(itertools.chain.from_iterable(x_valid))\n",
    "    y_valid = list(itertools.chain.from_iterable(y_valid))\n",
    "\n",
    "    x_valid = np.asarray(x_valid)\n",
    "    y_valid = np.asarray(y_valid)\n",
    "    x_test  = np.asarray(x_test)\n",
    "    y_test  = np.asarray(y_test)\n",
    "    x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "\n",
    "    x_train= x_train / 255.0, \n",
    "    x_valid  = x_valid / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:03<00:00, 776.30it/s]\n",
      "100%|██████████| 3000/3000 [00:03<00:00, 777.43it/s]\n",
      "100%|██████████| 3000/3000 [00:03<00:00, 799.89it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:37<00:00, 791.20it/s] \n",
      "100%|██████████| 30000/30000 [00:39<00:00, 753.19it/s] \n",
      "100%|██████████| 30000/30000 [00:39<00:00, 757.54it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 22000/22000 [00:28<00:00, 767.30it/s] \n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 21000/21000 [00:29<00:00, 717.40it/s] \n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(idx):\n",
    "    plt.imshow(x_data[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if stratified\n",
    "\n",
    "# print(len(y_train),len(y_valid),len(y_test))\n",
    "\n",
    "# unique, counts = np.unique(y_valid, return_counts=True)\n",
    "# np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 527,365\n",
      "Trainable params: 527,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "#     [32, 512, 0.2],\n",
    "#     [32, 256, 0.2],\n",
    "    [32, 256, 0.4,128,0.4]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(config, model_weights=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(config[0], config[0])),\n",
    "        tf.keras.layers.Dense(config[1]),#, kernel_regularizer=keras.regularizers.l2(0.00001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(config[2]),\n",
    "        tf.keras.layers.Dense(config[3]),#,kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(config[4]),        \n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    if model_weights is not None:\n",
    "        print('loading pre-trained model')\n",
    "        model.load_weights(model_weights, by_name=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 8s 83us/sample - loss: 1.3570 - acc: 0.4526 - val_loss: 1.1141 - val_acc: 0.5467\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 9s 89us/sample - loss: 1.0930 - acc: 0.5440 - val_loss: 1.1250 - val_acc: 0.5143\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 7s 71us/sample - loss: 1.0458 - acc: 0.5677 - val_loss: 1.3360 - val_acc: 0.4726\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 6s 55us/sample - loss: 1.0196 - acc: 0.5817 - val_loss: 1.0893 - val_acc: 0.5463\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 7s 75us/sample - loss: 0.9990 - acc: 0.5917 - val_loss: 1.0771 - val_acc: 0.5569\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 6s 61us/sample - loss: 0.9788 - acc: 0.6008 - val_loss: 0.9822 - val_acc: 0.5968\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 7s 70us/sample - loss: 0.9639 - acc: 0.6082 - val_loss: 1.3368 - val_acc: 0.4823\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 5s 53us/sample - loss: 0.9488 - acc: 0.6148 - val_loss: 1.1838 - val_acc: 0.5336\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 5s 55us/sample - loss: 0.9301 - acc: 0.6240 - val_loss: 1.2715 - val_acc: 0.4781\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 5s 55us/sample - loss: 0.9151 - acc: 0.6310 - val_loss: 1.0152 - val_acc: 0.5808\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 5s 53us/sample - loss: 0.8951 - acc: 0.6410 - val_loss: 0.9986 - val_acc: 0.5932\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 5s 52us/sample - loss: 0.8740 - acc: 0.6488 - val_loss: 1.0410 - val_acc: 0.5756\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 5s 50us/sample - loss: 0.8592 - acc: 0.6568 - val_loss: 1.2934 - val_acc: 0.4949\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.8364 - acc: 0.6680 - val_loss: 1.3105 - val_acc: 0.4979\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.8181 - acc: 0.6764 - val_loss: 1.1915 - val_acc: 0.5381\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.7929 - acc: 0.6894 - val_loss: 0.9912 - val_acc: 0.5990\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.7745 - acc: 0.6969 - val_loss: 0.9805 - val_acc: 0.6144\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 6s 56us/sample - loss: 0.7528 - acc: 0.7063 - val_loss: 1.0853 - val_acc: 0.5905\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 5s 53us/sample - loss: 0.7323 - acc: 0.7153 - val_loss: 1.3576 - val_acc: 0.5134\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 5s 52us/sample - loss: 0.7119 - acc: 0.7261 - val_loss: 0.8378 - val_acc: 0.6729\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 5s 50us/sample - loss: 0.6956 - acc: 0.7313 - val_loss: 0.9541 - val_acc: 0.6213\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 5s 53us/sample - loss: 0.6827 - acc: 0.7377 - val_loss: 0.8443 - val_acc: 0.6675\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 5s 55us/sample - loss: 0.6655 - acc: 0.7443 - val_loss: 0.8916 - val_acc: 0.6500\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.6467 - acc: 0.7536 - val_loss: 0.9769 - val_acc: 0.6257\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 6s 56us/sample - loss: 0.6335 - acc: 0.7582 - val_loss: 1.3003 - val_acc: 0.5406\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 5s 54us/sample - loss: 0.6161 - acc: 0.7646 - val_loss: 1.0735 - val_acc: 0.6017\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 5s 54us/sample - loss: 0.6022 - acc: 0.7694 - val_loss: 1.0659 - val_acc: 0.6030\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 5s 51us/sample - loss: 0.5933 - acc: 0.7759 - val_loss: 0.8380 - val_acc: 0.6805\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 5s 55us/sample - loss: 0.5766 - acc: 0.7806 - val_loss: 0.9368 - val_acc: 0.6397\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 8s 78us/sample - loss: 0.5687 - acc: 0.7839 - val_loss: 1.5593 - val_acc: 0.4935\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 7s 72us/sample - loss: 0.5572 - acc: 0.7891 - val_loss: 0.9994 - val_acc: 0.6129\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 7s 68us/sample - loss: 0.5470 - acc: 0.7924 - val_loss: 0.7903 - val_acc: 0.6960\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 7s 74us/sample - loss: 0.5411 - acc: 0.7974 - val_loss: 1.5268 - val_acc: 0.5371\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 7s 72us/sample - loss: 0.5278 - acc: 0.8021 - val_loss: 0.9073 - val_acc: 0.6608\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 8s 76us/sample - loss: 0.5184 - acc: 0.8050 - val_loss: 1.1677 - val_acc: 0.5852\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 7s 73us/sample - loss: 0.5127 - acc: 0.8062 - val_loss: 1.1255 - val_acc: 0.6003\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 7s 73us/sample - loss: 0.5050 - acc: 0.8091 - val_loss: 1.2527 - val_acc: 0.5826\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 8s 78us/sample - loss: 0.4937 - acc: 0.8127 - val_loss: 0.7486 - val_acc: 0.7227\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 8s 83us/sample - loss: 0.4874 - acc: 0.8155 - val_loss: 0.9250 - val_acc: 0.6745\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 8s 83us/sample - loss: 0.4815 - acc: 0.8186 - val_loss: 0.8223 - val_acc: 0.6912\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 8s 75us/sample - loss: 0.4734 - acc: 0.8197 - val_loss: 0.9735 - val_acc: 0.6471\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 8s 78us/sample - loss: 0.4690 - acc: 0.8226 - val_loss: 0.9733 - val_acc: 0.6809\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 9s 86us/sample - loss: 0.4593 - acc: 0.8266 - val_loss: 1.0442 - val_acc: 0.6366\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 11s 112us/sample - loss: 0.4549 - acc: 0.8277 - val_loss: 1.4090 - val_acc: 0.5402\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 8s 85us/sample - loss: 0.4496 - acc: 0.8313 - val_loss: 0.7687 - val_acc: 0.7186\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 8s 81us/sample - loss: 0.4440 - acc: 0.8323 - val_loss: 0.9340 - val_acc: 0.6685\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 9s 89us/sample - loss: 0.4370 - acc: 0.8352 - val_loss: 0.9920 - val_acc: 0.6630\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 8s 81us/sample - loss: 0.4316 - acc: 0.8370 - val_loss: 0.7427 - val_acc: 0.7286\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 7s 67us/sample - loss: 0.4252 - acc: 0.8400 - val_loss: 0.8796 - val_acc: 0.6882\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 7s 69us/sample - loss: 0.4197 - acc: 0.8420 - val_loss: 1.0573 - val_acc: 0.6410\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 1s 63us/sample - loss: 1.0545 - acc: 0.6379\n",
      "Training time:331.528513908\n"
     ]
    }
   ],
   "source": [
    "def run_custom_training(conf_list, x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix=None, model_weights=None):\n",
    "    for conf in conf_list:\n",
    "        curr_dt = set_curr_time()\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "        model = custom_model(conf, model_weights)\n",
    "        tic = time.time()\n",
    "        model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=256,\n",
    "                  epochs=50, callbacks=[tb_callback])\n",
    "        toc = time.time()\n",
    "        print('---Test loss & accuracy---')\n",
    "        model.evaluate(x_test, y_test)\n",
    "        print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "#         if model_path_prefix is None:\n",
    "#             model.save('../models/{0}_{1}.h5'.format(conf, curr_dt))\n",
    "#         else:\n",
    "#             model.save('../models/{0}_{1}_{2}.h5'.format(model_path_prefix, conf, curr_dt))\n",
    "            \n",
    "run_custom_training(conf_list, x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix=None, model_weights=None)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['zeev', 'or', 'ron', 'aviya', 'felix']\n",
    "\n",
    "TRAIN_AND_VALIDATION_TEST_SPLIT = 0.3\n",
    "VALID_AND_TEST_SPLIT           = 0.5\n",
    "\n",
    "CLASSES = 5\n",
    "\n",
    "# stratified data\n",
    "x_train = [] \n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "x_test  = []\n",
    "y_test  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 6118.12it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 6826.37it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 6020.22it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8815.61it/s] \n",
      "100%|██████████| 30000/30000 [00:03<00:00, 9812.59it/s] \n",
      "100%|██████████| 30000/30000 [00:03<00:00, 9867.03it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 22000/22000 [00:02<00:00, 9872.20it/s] \n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 21000/21000 [00:02<00:00, 9505.11it/s] \n"
     ]
    }
   ],
   "source": [
    "def prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test):  \n",
    "    # for i, l in enumerate(labels):\n",
    "    for d in dates:\n",
    "        for i, l in enumerate(labels):\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "                x_data.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "                y_data.append(i)\n",
    "            x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "                             = train_test_split(x_data, y_data, test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "            x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "                         = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "            x_train.append(x_train_label)\n",
    "            y_train.append(y_train_label)\n",
    "            x_test.append(x_test_label)\n",
    "            y_test.append(y_test_label)\n",
    "            x_valid.append(x_valid_label)\n",
    "            y_valid.append(y_valid_label)\n",
    "\n",
    "    x_train = list(itertools.chain.from_iterable(x_train))\n",
    "    y_train = list(itertools.chain.from_iterable(y_train))\n",
    "    x_test = list(itertools.chain.from_iterable(x_test))\n",
    "    y_test = list(itertools.chain.from_iterable(y_test))\n",
    "    x_valid = list(itertools.chain.from_iterable(x_valid))\n",
    "    y_valid = list(itertools.chain.from_iterable(y_valid))\n",
    "\n",
    "    x_valid = np.asarray(x_valid)\n",
    "    y_valid = np.asarray(y_valid)\n",
    "    x_test  = np.asarray(x_test)\n",
    "    y_test  = np.asarray(y_test)\n",
    "    x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "\n",
    "    x_train= x_train / 255.0, \n",
    "    x_valid  = x_valid / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_valid = np.asarray(x_valid)\n",
    "y_valid = np.asarray(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99400, 32, 32, 1)\n",
      "(21300, 32, 32, 1)\n",
      "(21300, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_train2 = x_train.reshape(x_train.shape[1],x_train.shape[2],x_train.shape[3], 1)\n",
    "print(x_train2.shape)\n",
    "x_valid2 = x_valid.reshape(x_valid.shape[0],x_valid.shape[1],x_valid.shape[2], 1)\n",
    "print(x_valid2.shape)\n",
    "x_test2 = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2], 1)\n",
    "print(x_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "    #[32,3,2,0.4, 256, 0.4,128,0.4],\n",
    "    [64,3,2,0.4, 256, 0.4,128,0.4],\n",
    "    [32,3,2,0.3, 256, 0.3,128,0.3],\n",
    "    [64,5,2,0.4, 128, 0.4,64,0.4],\n",
    "    [64,5,2,0.4, 256, 0.4,128,0.4],\n",
    "    [128,3,2,0.4, 256, 0.4,128,0.4],\n",
    "    [32,3,2,0.2, 256, 0.2,128,0.2]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(config, model_weights=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    " #       tf.keras.layers.Flatten(input_shape=(config[0], config[0])),\n",
    "        tf.keras.layers.Conv2D(config[0],config[1]),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(config[2], config[2])),\n",
    "        tf.keras.layers.Dropout(config[3]),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(config[4]),#, kernel_regularizer=keras.regularizers.l2(0.00001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(config[5]),\n",
    "        tf.keras.layers.Dense(config[6]),#,kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(config[7]),        \n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    if model_weights is not None:\n",
    "        print('loading pre-trained model')\n",
    "        model.load_weights(model_weights, by_name=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 141s 1ms/sample - loss: 1.2211 - acc: 0.4882 - val_loss: 1.0139 - val_acc: 0.5929\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 160s 2ms/sample - loss: 0.9533 - acc: 0.6179 - val_loss: 0.9261 - val_acc: 0.6197\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 165s 2ms/sample - loss: 0.8589 - acc: 0.6605 - val_loss: 0.8916 - val_acc: 0.6393\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 146s 1ms/sample - loss: 0.7789 - acc: 0.6982 - val_loss: 0.7192 - val_acc: 0.7215\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 158s 2ms/sample - loss: 0.7160 - acc: 0.7242 - val_loss: 1.0614 - val_acc: 0.5702\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 149s 2ms/sample - loss: 0.6561 - acc: 0.7507 - val_loss: 0.7843 - val_acc: 0.7045\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 155s 2ms/sample - loss: 0.6065 - acc: 0.7699 - val_loss: 1.6804 - val_acc: 0.5257\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 170s 2ms/sample - loss: 0.5574 - acc: 0.7903 - val_loss: 0.7206 - val_acc: 0.7291\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 137s 1ms/sample - loss: 0.5236 - acc: 0.8039 - val_loss: 0.5709 - val_acc: 0.7910\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.4832 - acc: 0.8197 - val_loss: 0.6361 - val_acc: 0.7647\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 121s 1ms/sample - loss: 0.4535 - acc: 0.8312 - val_loss: 0.6507 - val_acc: 0.7644\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.4341 - acc: 0.8408 - val_loss: 0.5151 - val_acc: 0.8165\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.4074 - acc: 0.8500 - val_loss: 0.6755 - val_acc: 0.7612\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.3897 - acc: 0.8568 - val_loss: 0.6130 - val_acc: 0.7856\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.3737 - acc: 0.8615 - val_loss: 0.7024 - val_acc: 0.7638\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.3612 - acc: 0.8685 - val_loss: 0.6857 - val_acc: 0.7658\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.3481 - acc: 0.8722 - val_loss: 0.5508 - val_acc: 0.8102\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.3363 - acc: 0.8772 - val_loss: 0.6484 - val_acc: 0.7805\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.3264 - acc: 0.8812 - val_loss: 0.5271 - val_acc: 0.8210\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.3177 - acc: 0.8848 - val_loss: 0.5669 - val_acc: 0.8100\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.3054 - acc: 0.8897 - val_loss: 0.6009 - val_acc: 0.8044\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.3019 - acc: 0.8908 - val_loss: 0.5559 - val_acc: 0.8137\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2885 - acc: 0.8949 - val_loss: 0.5688 - val_acc: 0.8094\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 131s 1ms/sample - loss: 0.2886 - acc: 0.8947 - val_loss: 0.5515 - val_acc: 0.8132\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2809 - acc: 0.8985 - val_loss: 0.5198 - val_acc: 0.8283\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2712 - acc: 0.9030 - val_loss: 0.5036 - val_acc: 0.8338\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2651 - acc: 0.9040 - val_loss: 0.5300 - val_acc: 0.8235\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2630 - acc: 0.9053 - val_loss: 0.7359 - val_acc: 0.7709\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2552 - acc: 0.9079 - val_loss: 0.5753 - val_acc: 0.8127\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2500 - acc: 0.9108 - val_loss: 0.5156 - val_acc: 0.8303\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2473 - acc: 0.9115 - val_loss: 0.5242 - val_acc: 0.8233\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2438 - acc: 0.9132 - val_loss: 0.5131 - val_acc: 0.8293\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2426 - acc: 0.9122 - val_loss: 0.5332 - val_acc: 0.8303\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2362 - acc: 0.9157 - val_loss: 0.6519 - val_acc: 0.7959\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2340 - acc: 0.9160 - val_loss: 0.4722 - val_acc: 0.8413\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2305 - acc: 0.9168 - val_loss: 0.5425 - val_acc: 0.8252\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2246 - acc: 0.9192 - val_loss: 0.4927 - val_acc: 0.8352\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2234 - acc: 0.9198 - val_loss: 0.5200 - val_acc: 0.8331\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 134s 1ms/sample - loss: 0.2224 - acc: 0.9217 - val_loss: 0.5026 - val_acc: 0.8367\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2178 - acc: 0.9224 - val_loss: 0.9669 - val_acc: 0.7265\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2133 - acc: 0.9239 - val_loss: 0.7795 - val_acc: 0.7729\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.2167 - acc: 0.9223 - val_loss: 0.4862 - val_acc: 0.8438\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2073 - acc: 0.9265 - val_loss: 0.5861 - val_acc: 0.8215\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2057 - acc: 0.9271 - val_loss: 0.5133 - val_acc: 0.8339\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2039 - acc: 0.9265 - val_loss: 0.5319 - val_acc: 0.8339\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2033 - acc: 0.9279 - val_loss: 0.5567 - val_acc: 0.8300\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2007 - acc: 0.9289 - val_loss: 0.5298 - val_acc: 0.8324\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.2018 - acc: 0.9285 - val_loss: 0.5065 - val_acc: 0.8387\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 126s 1ms/sample - loss: 0.1964 - acc: 0.9297 - val_loss: 0.5318 - val_acc: 0.8347\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.1950 - acc: 0.9312 - val_loss: 0.5338 - val_acc: 0.8328\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 8s 375us/sample - loss: 0.5262 - acc: 0.8322\n",
      "Training time:6646.62375498\n",
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 75s 757us/sample - loss: 1.1866 - acc: 0.5049 - val_loss: 1.0327 - val_acc: 0.5714\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.9183 - acc: 0.6351 - val_loss: 1.0213 - val_acc: 0.5675\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 75s 753us/sample - loss: 0.8136 - acc: 0.6824 - val_loss: 0.7512 - val_acc: 0.7182\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 75s 755us/sample - loss: 0.7297 - acc: 0.7194 - val_loss: 0.9792 - val_acc: 0.6285\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 75s 753us/sample - loss: 0.6563 - acc: 0.7488 - val_loss: 0.6394 - val_acc: 0.7643\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.5923 - acc: 0.7758 - val_loss: 0.7566 - val_acc: 0.7169\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.5351 - acc: 0.7988 - val_loss: 0.7277 - val_acc: 0.7178\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 79s 792us/sample - loss: 0.4889 - acc: 0.8179 - val_loss: 0.8045 - val_acc: 0.7113\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 86s 862us/sample - loss: 0.4459 - acc: 0.8341 - val_loss: 0.6168 - val_acc: 0.7781\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.4162 - acc: 0.8438 - val_loss: 0.5948 - val_acc: 0.7873\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 74s 747us/sample - loss: 0.3840 - acc: 0.8584 - val_loss: 0.5288 - val_acc: 0.8131\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 74s 748us/sample - loss: 0.3658 - acc: 0.8653 - val_loss: 0.6812 - val_acc: 0.7615\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 82s 820us/sample - loss: 0.3431 - acc: 0.8735 - val_loss: 0.5482 - val_acc: 0.8049\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 90s 909us/sample - loss: 0.3214 - acc: 0.8820 - val_loss: 0.5802 - val_acc: 0.8013\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 94s 941us/sample - loss: 0.3080 - acc: 0.8879 - val_loss: 0.5893 - val_acc: 0.8050\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 82s 826us/sample - loss: 0.2970 - acc: 0.8912 - val_loss: 0.7540 - val_acc: 0.7471\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 81s 819us/sample - loss: 0.2882 - acc: 0.8956 - val_loss: 1.4001 - val_acc: 0.6297\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 85s 852us/sample - loss: 0.2745 - acc: 0.8993 - val_loss: 0.5439 - val_acc: 0.8152\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 81s 820us/sample - loss: 0.2619 - acc: 0.9053 - val_loss: 0.5342 - val_acc: 0.8220\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 81s 812us/sample - loss: 0.2559 - acc: 0.9074 - val_loss: 0.6800 - val_acc: 0.7862\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 78s 784us/sample - loss: 0.2495 - acc: 0.9092 - val_loss: 0.9306 - val_acc: 0.7357\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 78s 782us/sample - loss: 0.2418 - acc: 0.9132 - val_loss: 0.5564 - val_acc: 0.8207\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 77s 774us/sample - loss: 0.2359 - acc: 0.9150 - val_loss: 0.5703 - val_acc: 0.8185\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 77s 773us/sample - loss: 0.2323 - acc: 0.9157 - val_loss: 0.5630 - val_acc: 0.8188\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 77s 778us/sample - loss: 0.2252 - acc: 0.9186 - val_loss: 0.5483 - val_acc: 0.8241\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 78s 781us/sample - loss: 0.2223 - acc: 0.9199 - val_loss: 0.5391 - val_acc: 0.8260\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 77s 778us/sample - loss: 0.2164 - acc: 0.9212 - val_loss: 0.6317 - val_acc: 0.8005\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 78s 781us/sample - loss: 0.2139 - acc: 0.9226 - val_loss: 0.7177 - val_acc: 0.7874\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 77s 776us/sample - loss: 0.2070 - acc: 0.9256 - val_loss: 0.6093 - val_acc: 0.8108\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 77s 779us/sample - loss: 0.2065 - acc: 0.9263 - val_loss: 0.5707 - val_acc: 0.8212\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 77s 778us/sample - loss: 0.2022 - acc: 0.9281 - val_loss: 0.6387 - val_acc: 0.8049\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 77s 779us/sample - loss: 0.1961 - acc: 0.9301 - val_loss: 0.6487 - val_acc: 0.8036\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 77s 779us/sample - loss: 0.1959 - acc: 0.9300 - val_loss: 0.7156 - val_acc: 0.7885\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 78s 781us/sample - loss: 0.1909 - acc: 0.9331 - val_loss: 0.5484 - val_acc: 0.8292\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 88s 884us/sample - loss: 0.1852 - acc: 0.9341 - val_loss: 0.6059 - val_acc: 0.8129\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 92s 926us/sample - loss: 0.1888 - acc: 0.9323 - val_loss: 0.5558 - val_acc: 0.8300\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 79s 796us/sample - loss: 0.1833 - acc: 0.9356 - val_loss: 0.5742 - val_acc: 0.8208\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 81s 818us/sample - loss: 0.1789 - acc: 0.9356 - val_loss: 0.5582 - val_acc: 0.8292\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 80s 809us/sample - loss: 0.1729 - acc: 0.9377 - val_loss: 0.6605 - val_acc: 0.8100\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 78s 786us/sample - loss: 0.1797 - acc: 0.9359 - val_loss: 0.6719 - val_acc: 0.8016\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 77s 770us/sample - loss: 0.1704 - acc: 0.9396 - val_loss: 0.6190 - val_acc: 0.8191\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 77s 771us/sample - loss: 0.1712 - acc: 0.9388 - val_loss: 0.7907 - val_acc: 0.7855\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 80s 806us/sample - loss: 0.1706 - acc: 0.9389 - val_loss: 0.7489 - val_acc: 0.7932\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 80s 802us/sample - loss: 0.1689 - acc: 0.9401 - val_loss: 0.5625 - val_acc: 0.8310\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 81s 812us/sample - loss: 0.1658 - acc: 0.9415 - val_loss: 0.5652 - val_acc: 0.8319\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 86s 863us/sample - loss: 0.1582 - acc: 0.9438 - val_loss: 0.6288 - val_acc: 0.8177\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 94s 946us/sample - loss: 0.1623 - acc: 0.9427 - val_loss: 0.6816 - val_acc: 0.8063\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 80s 805us/sample - loss: 0.1585 - acc: 0.9439 - val_loss: 0.5727 - val_acc: 0.8287\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 80s 805us/sample - loss: 0.1615 - acc: 0.9422 - val_loss: 0.5976 - val_acc: 0.8234\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 79s 793us/sample - loss: 0.1595 - acc: 0.9440 - val_loss: 0.6657 - val_acc: 0.8092\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 6s 276us/sample - loss: 0.6591 - acc: 0.8098\n",
      "Training time:3985.04460907\n",
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 1.3417 - acc: 0.4210 - val_loss: 1.1848 - val_acc: 0.4880\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 1.0711 - acc: 0.5611 - val_loss: 1.3891 - val_acc: 0.4074\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 119s 1ms/sample - loss: 0.9760 - acc: 0.6087 - val_loss: 2.1800 - val_acc: 0.3637\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 120s 1ms/sample - loss: 0.9118 - acc: 0.6403 - val_loss: 0.8347 - val_acc: 0.6733\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 118s 1ms/sample - loss: 0.8617 - acc: 0.6641 - val_loss: 0.9147 - val_acc: 0.6378\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.8144 - acc: 0.6851 - val_loss: 0.7646 - val_acc: 0.7092\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.7702 - acc: 0.7054 - val_loss: 0.8275 - val_acc: 0.6826\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.7367 - acc: 0.7186 - val_loss: 1.6648 - val_acc: 0.4996\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.7003 - acc: 0.7345 - val_loss: 0.7089 - val_acc: 0.7303\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.6716 - acc: 0.7445 - val_loss: 0.9261 - val_acc: 0.6348\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.6425 - acc: 0.7580 - val_loss: 0.6871 - val_acc: 0.7485\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.6240 - acc: 0.7665 - val_loss: 1.1620 - val_acc: 0.5764\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.5975 - acc: 0.7769 - val_loss: 0.8240 - val_acc: 0.6781\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 111s 1ms/sample - loss: 0.5840 - acc: 0.7819 - val_loss: 0.7740 - val_acc: 0.7061\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 111s 1ms/sample - loss: 0.5658 - acc: 0.7896 - val_loss: 1.0127 - val_acc: 0.6015\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.5560 - acc: 0.7939 - val_loss: 0.8531 - val_acc: 0.6869\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.5375 - acc: 0.8012 - val_loss: 0.7999 - val_acc: 0.6990\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.5249 - acc: 0.8060 - val_loss: 0.6176 - val_acc: 0.7747\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.5154 - acc: 0.8110 - val_loss: 0.7466 - val_acc: 0.7313\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 111s 1ms/sample - loss: 0.5033 - acc: 0.8149 - val_loss: 0.7409 - val_acc: 0.7387\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 111s 1ms/sample - loss: 0.4968 - acc: 0.8176 - val_loss: 0.6946 - val_acc: 0.7411\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.4865 - acc: 0.8215 - val_loss: 0.8683 - val_acc: 0.6955\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4757 - acc: 0.8260 - val_loss: 0.6011 - val_acc: 0.7854\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.4724 - acc: 0.8270 - val_loss: 0.5515 - val_acc: 0.8009\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.4651 - acc: 0.8296 - val_loss: 0.6703 - val_acc: 0.7664\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 131s 1ms/sample - loss: 0.4562 - acc: 0.8323 - val_loss: 1.4682 - val_acc: 0.5877\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4534 - acc: 0.8341 - val_loss: 0.6589 - val_acc: 0.7706\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 121s 1ms/sample - loss: 0.4452 - acc: 0.8378 - val_loss: 0.6017 - val_acc: 0.7893\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4410 - acc: 0.8406 - val_loss: 0.7022 - val_acc: 0.7477\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 116s 1ms/sample - loss: 0.4344 - acc: 0.8426 - val_loss: 0.5873 - val_acc: 0.7872\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4291 - acc: 0.8431 - val_loss: 0.5604 - val_acc: 0.8007\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4259 - acc: 0.8453 - val_loss: 0.6258 - val_acc: 0.7882\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.4201 - acc: 0.8468 - val_loss: 0.5488 - val_acc: 0.8020\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4167 - acc: 0.8497 - val_loss: 0.5531 - val_acc: 0.8066\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 114s 1ms/sample - loss: 0.4117 - acc: 0.8501 - val_loss: 0.7428 - val_acc: 0.7418\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4075 - acc: 0.8523 - val_loss: 0.5615 - val_acc: 0.8049\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 115s 1ms/sample - loss: 0.4086 - acc: 0.8542 - val_loss: 0.5306 - val_acc: 0.8096\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.4054 - acc: 0.8535 - val_loss: 0.5458 - val_acc: 0.8112\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 115s 1ms/sample - loss: 0.4015 - acc: 0.8539 - val_loss: 1.1065 - val_acc: 0.6580\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.3878 - acc: 0.8586 - val_loss: 0.5832 - val_acc: 0.7902\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3942 - acc: 0.8580 - val_loss: 0.8266 - val_acc: 0.7257\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.3898 - acc: 0.8585 - val_loss: 0.6250 - val_acc: 0.7791\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3849 - acc: 0.8609 - val_loss: 0.5392 - val_acc: 0.8085\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3854 - acc: 0.8603 - val_loss: 0.6278 - val_acc: 0.7844\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3815 - acc: 0.8627 - val_loss: 0.9170 - val_acc: 0.7074\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3778 - acc: 0.8641 - val_loss: 0.6022 - val_acc: 0.7891\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3751 - acc: 0.8641 - val_loss: 0.6440 - val_acc: 0.7785\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3749 - acc: 0.8654 - val_loss: 0.6835 - val_acc: 0.7729\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 113s 1ms/sample - loss: 0.3734 - acc: 0.8654 - val_loss: 0.5689 - val_acc: 0.8021\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 112s 1ms/sample - loss: 0.3687 - acc: 0.8665 - val_loss: 0.6038 - val_acc: 0.7936\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 7s 322us/sample - loss: 0.5932 - acc: 0.7951\n",
      "Training time:5689.97189188\n",
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 124s 1ms/sample - loss: 1.2692 - acc: 0.4620 - val_loss: 1.1853 - val_acc: 0.4752\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 125s 1ms/sample - loss: 0.9951 - acc: 0.5978 - val_loss: 0.9885 - val_acc: 0.6023\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 130s 1ms/sample - loss: 0.8905 - acc: 0.6453 - val_loss: 1.0538 - val_acc: 0.5717\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 150s 2ms/sample - loss: 0.8121 - acc: 0.6835 - val_loss: 1.0276 - val_acc: 0.5902\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.7476 - acc: 0.7108 - val_loss: 0.7270 - val_acc: 0.7219\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 148s 1ms/sample - loss: 0.6854 - acc: 0.7375 - val_loss: 0.8307 - val_acc: 0.6694\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 139s 1ms/sample - loss: 0.6307 - acc: 0.7601 - val_loss: 0.7267 - val_acc: 0.7213\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 146s 1ms/sample - loss: 0.5853 - acc: 0.7800 - val_loss: 1.2816 - val_acc: 0.5673\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 148s 1ms/sample - loss: 0.5358 - acc: 0.7995 - val_loss: 0.6851 - val_acc: 0.7427\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 138s 1ms/sample - loss: 0.5035 - acc: 0.8133 - val_loss: 0.8399 - val_acc: 0.6909\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.4759 - acc: 0.8223 - val_loss: 0.7888 - val_acc: 0.7087\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.4487 - acc: 0.8340 - val_loss: 0.6222 - val_acc: 0.7762\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.4235 - acc: 0.8432 - val_loss: 0.5208 - val_acc: 0.8138\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 130s 1ms/sample - loss: 0.4041 - acc: 0.8518 - val_loss: 0.5157 - val_acc: 0.8165\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 130s 1ms/sample - loss: 0.3868 - acc: 0.8585 - val_loss: 0.5428 - val_acc: 0.8096\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 130s 1ms/sample - loss: 0.3696 - acc: 0.8643 - val_loss: 0.6305 - val_acc: 0.7815\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 130s 1ms/sample - loss: 0.3574 - acc: 0.8699 - val_loss: 0.6685 - val_acc: 0.7622\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 135s 1ms/sample - loss: 0.3446 - acc: 0.8746 - val_loss: 0.6290 - val_acc: 0.7828\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 151s 2ms/sample - loss: 0.3339 - acc: 0.8775 - val_loss: 0.7026 - val_acc: 0.7573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 148s 1ms/sample - loss: 0.3235 - acc: 0.8814 - val_loss: 0.5159 - val_acc: 0.8200\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 149s 1ms/sample - loss: 0.3157 - acc: 0.8846 - val_loss: 0.5405 - val_acc: 0.8181\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 146s 1ms/sample - loss: 0.3046 - acc: 0.8887 - val_loss: 0.5835 - val_acc: 0.8039\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.3004 - acc: 0.8899 - val_loss: 0.5688 - val_acc: 0.8059\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2947 - acc: 0.8934 - val_loss: 1.0241 - val_acc: 0.6756\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 142s 1ms/sample - loss: 0.2859 - acc: 0.8966 - val_loss: 0.5431 - val_acc: 0.8215\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2791 - acc: 0.8996 - val_loss: 1.0658 - val_acc: 0.6873\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 145s 1ms/sample - loss: 0.2727 - acc: 0.9011 - val_loss: 0.5287 - val_acc: 0.8204\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 144s 1ms/sample - loss: 0.2686 - acc: 0.9025 - val_loss: 1.6661 - val_acc: 0.6362\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2656 - acc: 0.9055 - val_loss: 0.6287 - val_acc: 0.7957\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2573 - acc: 0.9069 - val_loss: 0.6276 - val_acc: 0.7964\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2552 - acc: 0.9088 - val_loss: 0.6727 - val_acc: 0.7824\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 145s 1ms/sample - loss: 0.2531 - acc: 0.9098 - val_loss: 0.5029 - val_acc: 0.8347\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 146s 1ms/sample - loss: 0.2477 - acc: 0.9112 - val_loss: 0.7264 - val_acc: 0.7739\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 150s 2ms/sample - loss: 0.2437 - acc: 0.9131 - val_loss: 0.8985 - val_acc: 0.7376\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 152s 2ms/sample - loss: 0.2382 - acc: 0.9156 - val_loss: 0.7086 - val_acc: 0.7812\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 147s 1ms/sample - loss: 0.2332 - acc: 0.9163 - val_loss: 0.5396 - val_acc: 0.8273\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 150s 2ms/sample - loss: 0.2331 - acc: 0.9165 - val_loss: 0.5801 - val_acc: 0.8212\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 148s 1ms/sample - loss: 0.2319 - acc: 0.9165 - val_loss: 0.4998 - val_acc: 0.8371\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 151s 2ms/sample - loss: 0.2238 - acc: 0.9200 - val_loss: 0.5653 - val_acc: 0.8235\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 152s 2ms/sample - loss: 0.2238 - acc: 0.9205 - val_loss: 0.6430 - val_acc: 0.8039\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 150s 2ms/sample - loss: 0.2190 - acc: 0.9232 - val_loss: 0.6743 - val_acc: 0.7957\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 142s 1ms/sample - loss: 0.2166 - acc: 0.9236 - val_loss: 0.5924 - val_acc: 0.8143\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.2172 - acc: 0.9224 - val_loss: 0.5512 - val_acc: 0.8206\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 129s 1ms/sample - loss: 0.2116 - acc: 0.9247 - val_loss: 0.5700 - val_acc: 0.8220\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 137s 1ms/sample - loss: 0.2067 - acc: 0.9263 - val_loss: 0.5094 - val_acc: 0.8362\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 132s 1ms/sample - loss: 0.2035 - acc: 0.9283 - val_loss: 0.5335 - val_acc: 0.8329\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.2051 - acc: 0.9271 - val_loss: 0.5999 - val_acc: 0.8095\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 127s 1ms/sample - loss: 0.2028 - acc: 0.9278 - val_loss: 0.6266 - val_acc: 0.8090\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 135s 1ms/sample - loss: 0.2008 - acc: 0.9282 - val_loss: 0.6353 - val_acc: 0.8049\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 128s 1ms/sample - loss: 0.1949 - acc: 0.9311 - val_loss: 0.5043 - val_acc: 0.8407\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 9s 405us/sample - loss: 0.4987 - acc: 0.8418\n",
      "Training time:7019.18114614\n",
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 230s 2ms/sample - loss: 1.1837 - acc: 0.5094 - val_loss: 0.9911 - val_acc: 0.5865\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 230s 2ms/sample - loss: 0.9173 - acc: 0.6326 - val_loss: 1.1737 - val_acc: 0.5141\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 238s 2ms/sample - loss: 0.8108 - acc: 0.6822 - val_loss: 1.0507 - val_acc: 0.5717\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 251s 3ms/sample - loss: 0.7253 - acc: 0.7189 - val_loss: 0.7222 - val_acc: 0.7244\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 255s 3ms/sample - loss: 0.6526 - acc: 0.7508 - val_loss: 0.6541 - val_acc: 0.7583\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 253s 3ms/sample - loss: 0.5896 - acc: 0.7774 - val_loss: 0.5904 - val_acc: 0.7806\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 256s 3ms/sample - loss: 0.5287 - acc: 0.8015 - val_loss: 0.6451 - val_acc: 0.7580\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.4830 - acc: 0.8194 - val_loss: 0.6329 - val_acc: 0.7636\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 234s 2ms/sample - loss: 0.4408 - acc: 0.8364 - val_loss: 0.8176 - val_acc: 0.7069\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 234s 2ms/sample - loss: 0.4079 - acc: 0.8494 - val_loss: 1.0807 - val_acc: 0.6443\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 239s 2ms/sample - loss: 0.3813 - acc: 0.8605 - val_loss: 0.5445 - val_acc: 0.8045\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 243s 2ms/sample - loss: 0.3523 - acc: 0.8708 - val_loss: 0.5391 - val_acc: 0.8120\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 242s 2ms/sample - loss: 0.3365 - acc: 0.8761 - val_loss: 1.2293 - val_acc: 0.6462\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.3126 - acc: 0.8849 - val_loss: 0.5893 - val_acc: 0.8055\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.2985 - acc: 0.8913 - val_loss: 0.5416 - val_acc: 0.8191\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.2860 - acc: 0.8960 - val_loss: 0.5996 - val_acc: 0.7969\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.2769 - acc: 0.8999 - val_loss: 0.8107 - val_acc: 0.7499\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.2650 - acc: 0.9043 - val_loss: 0.7263 - val_acc: 0.7659\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.2534 - acc: 0.9081 - val_loss: 0.6034 - val_acc: 0.8138\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.2466 - acc: 0.9103 - val_loss: 0.8841 - val_acc: 0.7464\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.2344 - acc: 0.9160 - val_loss: 0.5772 - val_acc: 0.8143\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.2273 - acc: 0.9185 - val_loss: 0.7873 - val_acc: 0.7692\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.2237 - acc: 0.9208 - val_loss: 0.6479 - val_acc: 0.8049\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.2185 - acc: 0.9216 - val_loss: 0.5312 - val_acc: 0.8304\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 234s 2ms/sample - loss: 0.2092 - acc: 0.9249 - val_loss: 0.5835 - val_acc: 0.8191\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 235s 2ms/sample - loss: 0.2071 - acc: 0.9258 - val_loss: 0.6517 - val_acc: 0.8012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 234s 2ms/sample - loss: 0.2027 - acc: 0.9279 - val_loss: 0.6340 - val_acc: 0.8116\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1981 - acc: 0.9292 - val_loss: 0.5303 - val_acc: 0.8338\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1909 - acc: 0.9320 - val_loss: 0.6139 - val_acc: 0.8118\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1868 - acc: 0.9339 - val_loss: 0.5978 - val_acc: 0.8248\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.1852 - acc: 0.9338 - val_loss: 1.1453 - val_acc: 0.7102\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1806 - acc: 0.9358 - val_loss: 0.5884 - val_acc: 0.8281\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 230s 2ms/sample - loss: 0.1746 - acc: 0.9394 - val_loss: 0.6143 - val_acc: 0.8193\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1696 - acc: 0.9401 - val_loss: 0.5851 - val_acc: 0.8259\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.1719 - acc: 0.9392 - val_loss: 0.8642 - val_acc: 0.7692\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1694 - acc: 0.9400 - val_loss: 0.6445 - val_acc: 0.8138\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1661 - acc: 0.9411 - val_loss: 0.5212 - val_acc: 0.8414\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1657 - acc: 0.9413 - val_loss: 0.5687 - val_acc: 0.8338\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1580 - acc: 0.9440 - val_loss: 0.7267 - val_acc: 0.7986\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1589 - acc: 0.9439 - val_loss: 0.6347 - val_acc: 0.8224\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1553 - acc: 0.9454 - val_loss: 0.9028 - val_acc: 0.7685\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1518 - acc: 0.9463 - val_loss: 0.5932 - val_acc: 0.8312\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 228s 2ms/sample - loss: 0.1487 - acc: 0.9482 - val_loss: 0.5530 - val_acc: 0.8400\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1469 - acc: 0.9481 - val_loss: 0.6171 - val_acc: 0.8300\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1456 - acc: 0.9485 - val_loss: 0.6115 - val_acc: 0.8265\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.1461 - acc: 0.9489 - val_loss: 0.6998 - val_acc: 0.8072\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1398 - acc: 0.9510 - val_loss: 0.5515 - val_acc: 0.8422\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 232s 2ms/sample - loss: 0.1407 - acc: 0.9512 - val_loss: 0.6867 - val_acc: 0.8149\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 233s 2ms/sample - loss: 0.1378 - acc: 0.9518 - val_loss: 1.1419 - val_acc: 0.7267\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 231s 2ms/sample - loss: 0.1373 - acc: 0.9524 - val_loss: 1.0341 - val_acc: 0.7340\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 13s 590us/sample - loss: 1.0135 - acc: 0.7352\n",
      "Training time:11725.282985\n",
      "Train on 99400 samples, validate on 21300 samples\n",
      "Epoch 1/50\n",
      "99400/99400 [==============================] - 74s 748us/sample - loss: 1.0931 - acc: 0.5509 - val_loss: 0.9281 - val_acc: 0.6356\n",
      "Epoch 2/50\n",
      "99400/99400 [==============================] - 72s 728us/sample - loss: 0.8114 - acc: 0.6837 - val_loss: 0.8305 - val_acc: 0.6711\n",
      "Epoch 3/50\n",
      "99400/99400 [==============================] - 73s 734us/sample - loss: 0.6729 - acc: 0.7442 - val_loss: 0.7543 - val_acc: 0.7147\n",
      "Epoch 4/50\n",
      "99400/99400 [==============================] - 75s 757us/sample - loss: 0.5638 - acc: 0.7886 - val_loss: 1.0300 - val_acc: 0.6505\n",
      "Epoch 5/50\n",
      "99400/99400 [==============================] - 75s 753us/sample - loss: 0.4770 - acc: 0.8227 - val_loss: 0.6857 - val_acc: 0.7466\n",
      "Epoch 6/50\n",
      "99400/99400 [==============================] - 73s 736us/sample - loss: 0.4020 - acc: 0.8507 - val_loss: 0.7060 - val_acc: 0.7466\n",
      "Epoch 7/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.3510 - acc: 0.8707 - val_loss: 0.9517 - val_acc: 0.6969\n",
      "Epoch 8/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.3037 - acc: 0.8871 - val_loss: 0.5631 - val_acc: 0.8037\n",
      "Epoch 9/50\n",
      "99400/99400 [==============================] - 74s 742us/sample - loss: 0.2762 - acc: 0.8986 - val_loss: 1.3915 - val_acc: 0.6646\n",
      "Epoch 10/50\n",
      "99400/99400 [==============================] - 74s 745us/sample - loss: 0.2496 - acc: 0.9089 - val_loss: 0.5879 - val_acc: 0.8025\n",
      "Epoch 11/50\n",
      "99400/99400 [==============================] - 74s 748us/sample - loss: 0.2305 - acc: 0.9153 - val_loss: 0.5513 - val_acc: 0.8214\n",
      "Epoch 12/50\n",
      "99400/99400 [==============================] - 74s 744us/sample - loss: 0.2114 - acc: 0.9236 - val_loss: 0.7042 - val_acc: 0.7770\n",
      "Epoch 13/50\n",
      "99400/99400 [==============================] - 74s 744us/sample - loss: 0.1973 - acc: 0.9292 - val_loss: 0.6902 - val_acc: 0.7918\n",
      "Epoch 14/50\n",
      "99400/99400 [==============================] - 75s 754us/sample - loss: 0.1850 - acc: 0.9328 - val_loss: 0.6937 - val_acc: 0.7962\n",
      "Epoch 15/50\n",
      "99400/99400 [==============================] - 74s 745us/sample - loss: 0.1751 - acc: 0.9373 - val_loss: 0.7598 - val_acc: 0.7877\n",
      "Epoch 16/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.1652 - acc: 0.9404 - val_loss: 0.8915 - val_acc: 0.7457\n",
      "Epoch 17/50\n",
      "99400/99400 [==============================] - 76s 760us/sample - loss: 0.1551 - acc: 0.9446 - val_loss: 0.6871 - val_acc: 0.7893\n",
      "Epoch 18/50\n",
      "99400/99400 [==============================] - 74s 743us/sample - loss: 0.1505 - acc: 0.9460 - val_loss: 0.6766 - val_acc: 0.8080\n",
      "Epoch 19/50\n",
      "99400/99400 [==============================] - 74s 748us/sample - loss: 0.1443 - acc: 0.9481 - val_loss: 0.6857 - val_acc: 0.8029\n",
      "Epoch 20/50\n",
      "99400/99400 [==============================] - 75s 755us/sample - loss: 0.1375 - acc: 0.9506 - val_loss: 0.6839 - val_acc: 0.8101\n",
      "Epoch 21/50\n",
      "99400/99400 [==============================] - 74s 747us/sample - loss: 0.1359 - acc: 0.9511 - val_loss: 0.9212 - val_acc: 0.7623\n",
      "Epoch 22/50\n",
      "99400/99400 [==============================] - 74s 749us/sample - loss: 0.1310 - acc: 0.9530 - val_loss: 0.7391 - val_acc: 0.7976\n",
      "Epoch 23/50\n",
      "99400/99400 [==============================] - 75s 751us/sample - loss: 0.1236 - acc: 0.9562 - val_loss: 0.8539 - val_acc: 0.7770\n",
      "Epoch 24/50\n",
      "99400/99400 [==============================] - 73s 738us/sample - loss: 0.1214 - acc: 0.9570 - val_loss: 0.7557 - val_acc: 0.7875\n",
      "Epoch 25/50\n",
      "99400/99400 [==============================] - 72s 723us/sample - loss: 0.1206 - acc: 0.9570 - val_loss: 1.7644 - val_acc: 0.6737\n",
      "Epoch 26/50\n",
      "99400/99400 [==============================] - 74s 742us/sample - loss: 0.1154 - acc: 0.9589 - val_loss: 0.7449 - val_acc: 0.8042\n",
      "Epoch 27/50\n",
      "99400/99400 [==============================] - 75s 755us/sample - loss: 0.1115 - acc: 0.9604 - val_loss: 0.8571 - val_acc: 0.7857\n",
      "Epoch 28/50\n",
      "99400/99400 [==============================] - 75s 754us/sample - loss: 0.1081 - acc: 0.9620 - val_loss: 0.7683 - val_acc: 0.8052\n",
      "Epoch 29/50\n",
      "99400/99400 [==============================] - 75s 752us/sample - loss: 0.1066 - acc: 0.9620 - val_loss: 0.7253 - val_acc: 0.8075\n",
      "Epoch 30/50\n",
      "99400/99400 [==============================] - 75s 754us/sample - loss: 0.1022 - acc: 0.9640 - val_loss: 0.6551 - val_acc: 0.8282\n",
      "Epoch 31/50\n",
      "99400/99400 [==============================] - 74s 743us/sample - loss: 0.1026 - acc: 0.9641 - val_loss: 0.7614 - val_acc: 0.8090\n",
      "Epoch 32/50\n",
      "99400/99400 [==============================] - 74s 746us/sample - loss: 0.1004 - acc: 0.9653 - val_loss: 0.8537 - val_acc: 0.7972\n",
      "Epoch 33/50\n",
      "99400/99400 [==============================] - 72s 729us/sample - loss: 0.0965 - acc: 0.9661 - val_loss: 1.4880 - val_acc: 0.7077\n",
      "Epoch 34/50\n",
      "99400/99400 [==============================] - 73s 734us/sample - loss: 0.0949 - acc: 0.9667 - val_loss: 0.8081 - val_acc: 0.8023\n",
      "Epoch 35/50\n",
      "99400/99400 [==============================] - 75s 750us/sample - loss: 0.0928 - acc: 0.9675 - val_loss: 0.8458 - val_acc: 0.7973\n",
      "Epoch 36/50\n",
      "99400/99400 [==============================] - 75s 752us/sample - loss: 0.0923 - acc: 0.9676 - val_loss: 0.7561 - val_acc: 0.8150\n",
      "Epoch 37/50\n",
      "99400/99400 [==============================] - 74s 741us/sample - loss: 0.0902 - acc: 0.9683 - val_loss: 1.0677 - val_acc: 0.7585\n",
      "Epoch 38/50\n",
      "99400/99400 [==============================] - 74s 749us/sample - loss: 0.0881 - acc: 0.9696 - val_loss: 1.1251 - val_acc: 0.7597\n",
      "Epoch 39/50\n",
      "99400/99400 [==============================] - 73s 731us/sample - loss: 0.0853 - acc: 0.9697 - val_loss: 0.8022 - val_acc: 0.8101\n",
      "Epoch 40/50\n",
      "99400/99400 [==============================] - 73s 737us/sample - loss: 0.0859 - acc: 0.9700 - val_loss: 0.8233 - val_acc: 0.8038\n",
      "Epoch 41/50\n",
      "99400/99400 [==============================] - 74s 748us/sample - loss: 0.0826 - acc: 0.9715 - val_loss: 1.0267 - val_acc: 0.7697\n",
      "Epoch 42/50\n",
      "99400/99400 [==============================] - 73s 734us/sample - loss: 0.0820 - acc: 0.9712 - val_loss: 0.7270 - val_acc: 0.8195\n",
      "Epoch 43/50\n",
      "99400/99400 [==============================] - 74s 744us/sample - loss: 0.0818 - acc: 0.9714 - val_loss: 0.8547 - val_acc: 0.7972\n",
      "Epoch 44/50\n",
      "99400/99400 [==============================] - 75s 752us/sample - loss: 0.0793 - acc: 0.9725 - val_loss: 0.7419 - val_acc: 0.8172\n",
      "Epoch 45/50\n",
      "99400/99400 [==============================] - 75s 752us/sample - loss: 0.0771 - acc: 0.9734 - val_loss: 1.0418 - val_acc: 0.7651\n",
      "Epoch 46/50\n",
      "99400/99400 [==============================] - 73s 737us/sample - loss: 0.0768 - acc: 0.9730 - val_loss: 0.8226 - val_acc: 0.8077\n",
      "Epoch 47/50\n",
      "99400/99400 [==============================] - 74s 745us/sample - loss: 0.0778 - acc: 0.9730 - val_loss: 0.9797 - val_acc: 0.7835\n",
      "Epoch 48/50\n",
      "99400/99400 [==============================] - 74s 740us/sample - loss: 0.0747 - acc: 0.9741 - val_loss: 0.7267 - val_acc: 0.8290\n",
      "Epoch 49/50\n",
      "99400/99400 [==============================] - 73s 732us/sample - loss: 0.0741 - acc: 0.9746 - val_loss: 1.1332 - val_acc: 0.7580\n",
      "Epoch 50/50\n",
      "99400/99400 [==============================] - 74s 746us/sample - loss: 0.0744 - acc: 0.9742 - val_loss: 0.9531 - val_acc: 0.7891\n",
      "---Test loss & accuracy---\n",
      "21300/21300 [==============================] - 5s 257us/sample - loss: 0.9635 - acc: 0.7873\n",
      "Training time:3705.26048899\n"
     ]
    }
   ],
   "source": [
    "def run_custom_training(conf_list, x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix=None, model_weights=None):\n",
    "    for conf in conf_list:\n",
    "        curr_dt = set_curr_time()\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "        model = custom_model(conf, model_weights)\n",
    "        tic = time.time()\n",
    "        model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=256,\n",
    "                  epochs=50, callbacks=[tb_callback])\n",
    "        toc = time.time()\n",
    "        print('---Test loss & accuracy---')\n",
    "        model.evaluate(x_test, y_test)\n",
    "        print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "#         if model_path_prefix is None:\n",
    "#             model.save('../models/{0}_{1}.h5'.format(conf, curr_dt))\n",
    "#         else:\n",
    "#             model.save('../models/{0}_{1}_{2}.h5'.format(model_path_prefix, conf, curr_dt))\n",
    "            \n",
    "run_custom_training(conf_list, x_train2, y_train, x_valid2, y_valid, x_test2, y_test, model_path_prefix=None, model_weights=None)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/network.pyc\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \"\"\"\n\u001b[1;32m   1503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1505\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet 50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 5\n",
    "\n",
    "# stratified data\n",
    "x_train = [] \n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "x_test  = []\n",
    "y_test  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:04<00:00, 604.92it/s]\n",
      "100%|██████████| 3000/3000 [00:05<00:00, 589.21it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:49<00:00, 604.78it/s]\n",
      "100%|██████████| 30000/30000 [03:55<00:00, 16.68it/s] \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b5153f61582e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b5153f61582e>\u001b[0m in \u001b[0;36mprep_data\u001b[0;34m(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mx_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0my_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test):  \n",
    "    # for i, l in enumerate(labels):\n",
    "    for d in dates:\n",
    "        for i, l in enumerate(labels):\n",
    "            x_data = []\n",
    "            y_data = []\n",
    "            for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "                img = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "                f = cv2.resize(img, (224,224))\n",
    "                f = preprocess_input(f)\n",
    "#                 img = cv2.resize(cv2.imread(f, cv2.IMREAD_GRAYSCALE), (224,224))\n",
    "#                 x = preprocess_input(cv2.resize(cv2.imread(f, cv2.IMREAD_GRAYSCALE), (224,224)))\n",
    "#                 print(img)\n",
    "#                x_data.append(preprocess_input(cv2.resize(cv2.imread(f, cv2.IMREAD_GRAYSCALE), (224,224))))\n",
    "                x_data.append(f)\n",
    "\n",
    "                y_data.append(i)\n",
    "            x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "                             = train_test_split(x_data, y_data, test_size=TRAIN_AND_VALIDATION_TEST_SPLIT)\n",
    "            x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "                         = train_test_split(xx_test_label, yy_test_label, test_size=VALID_AND_TEST_SPLIT)  \n",
    "\n",
    "            x_train.append(x_train_label)\n",
    "            y_train.append(y_train_label)\n",
    "            x_test.append(x_test_label)\n",
    "            y_test.append(y_test_label)\n",
    "            x_valid.append(x_valid_label)\n",
    "            y_valid.append(y_valid_label)\n",
    "\n",
    "    x_train = list(itertools.chain.from_iterable(x_train))\n",
    "    y_train = list(itertools.chain.from_iterable(y_train))\n",
    "    x_test = list(itertools.chain.from_iterable(x_test))\n",
    "    y_test = list(itertools.chain.from_iterable(y_test))\n",
    "    x_valid = list(itertools.chain.from_iterable(x_valid))\n",
    "    y_valid = list(itertools.chain.from_iterable(y_valid))\n",
    "\n",
    "    x_valid = np.asarray(x_valid)\n",
    "    y_valid = np.asarray(y_valid)\n",
    "    x_test  = np.asarray(x_test)\n",
    "    y_test  = np.asarray(y_test)\n",
    "    x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "\n",
    "    x_train= x_train / 255.0, \n",
    "    x_valid  = x_valid / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "    return x_train, y_train, x_valid, y_valipd, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = prep_data(dates, labels, x_train, y_train, x_valid, y_valid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 99400, 32, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = preprocess_input(x_train)\n",
    "# x_train.shape\n",
    "# x_train_mod = x_train[0][:, :, :, np.newaxis]\n",
    "# x_train_mod2= np.repeat(x_train_mod, 3, axis=0)\n",
    "x_train2 = np.stack((x_train[0],x_train[0], x_train[0]), axis=3)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/or/dev/speckles-classification/notebooks'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('/home/or/dev/speckles-classification/data/frames/24032019/or',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 batch_size=10,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-08f25e2953c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m model.fit_generator(generator=train_generator,\n\u001b[1;32m     16\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                    epochs=10)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# model.fit(x=x_train[0], y=y_train, batch_size=32, epochs=50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/or/.virtualenvs/speckles/local/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 2 with size 1"
     ]
    }
   ],
   "source": [
    "CLASSES = 5\n",
    "\n",
    "base_model = ResNet50(weights=None, include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=10,\n",
    "                   epochs=10)\n",
    "# model.fit(x=x_train[0], y=y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'set_curr_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0219d53884bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#             model.save('../models/{0}_{1}_{2}.h5'.format(model_path_prefix, conf, curr_dt))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrun_custom_training\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-0219d53884bb>\u001b[0m in \u001b[0;36mrun_custom_training\u001b[0;34m(x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_custom_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mcurr_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_curr_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtb_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../logs/{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'set_curr_time' is not defined"
     ]
    }
   ],
   "source": [
    "def run_custom_training(x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix=None):\n",
    "        curr_dt = set_curr_time()\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir='../logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True)\n",
    "        tic = time.time()\n",
    "        model.fit(x_train, y_train, batch_size=256, epochs=50, callbacks=[tb_callback])\n",
    "        toc = time.time()\n",
    "        print('---Test loss & accuracy---')\n",
    "        model.evaluate(x_test, y_test)\n",
    "        print('Training time:{}'.format(toc-tic))\n",
    "\n",
    "#         if model_path_prefix is None:\n",
    "#             model.save('../models/{0}_{1}.h5'.format(conf, curr_dt))\n",
    "#         else:\n",
    "#             model.save('../models/{0}_{1}_{2}.h5'.format(model_path_prefix, conf, curr_dt))\n",
    "            \n",
    "run_custom_training( x_train, y_train, x_valid, y_valid, x_test, y_test, model_path_prefix=None)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_model = tf.keras.models.load_model('../models/[32, 512, 0.1]_201953_12_56.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256,\n",
    "#               epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "# for model_path in glob.glob('../models/*.h5'):\n",
    "#     print(model_path)\n",
    "#     best_loaded = tf.keras.models.load_model(model_path)\n",
    "#     best_loaded.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loaded = tf.keras.models.load_model('../models/[32, 512, 0.1]_201953_12_56.h5')\n",
    "test_predictions = best_loaded.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1217,    0,    0,    0,    0,    0,    0],\n",
       "       [   0, 3174,  309,  879,    0,  645,    0],\n",
       "       [   0,  177, 5386,  443,    0,  630,    0],\n",
       "       [   0,  569,  666, 4133,    0, 1290,    0],\n",
       "       [   0,    0,    0,    0, 1153,    0,    0],\n",
       "       [   0,  289,  546,  924,    0, 4137,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  633]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6051240>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(confusion, labels, labels)\n",
    "plt.figure(figsize = (12, 9))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, fmt='.5g', annot_kws={\"size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yafim</th>\n",
       "      <th>zeev</th>\n",
       "      <th>or</th>\n",
       "      <th>ron</th>\n",
       "      <th>sergey</th>\n",
       "      <th>aviya</th>\n",
       "      <th>elnatan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yafim</th>\n",
       "      <td>1217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeev</th>\n",
       "      <td>0</td>\n",
       "      <td>3174</td>\n",
       "      <td>309</td>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>5386</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ron</th>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "      <td>666</td>\n",
       "      <td>4133</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sergey</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aviya</th>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>546</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>4137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elnatan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         yafim  zeev    or   ron  sergey  aviya  elnatan\n",
       "yafim     1217     0     0     0       0      0        0\n",
       "zeev         0  3174   309   879       0    645        0\n",
       "or           0   177  5386   443       0    630        0\n",
       "ron          0   569   666  4133       0   1290        0\n",
       "sergey       0     0     0     0    1153      0        0\n",
       "aviya        0   289   546   924       0   4137        0\n",
       "elnatan      0     0     0     0       0      0      633"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
