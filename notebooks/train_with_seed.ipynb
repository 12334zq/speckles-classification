{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['zeev', 'or', 'ron', 'aviya', 'felix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87 99]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.randint(0, 100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 12560.44it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 11963.25it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 12748.48it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12394.86it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12650.47it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12232.48it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 22000/22000 [00:01<00:00, 12565.49it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 21000/21000 [00:01<00:00, 12023.84it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = prep_data_train_val_test(dates, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_sample(x_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 2500]\n",
      " [   1 3300]\n",
      " [   2 3300]\n",
      " [   3 3000]\n",
      " [   4 2100]]\n"
     ]
    }
   ],
   "source": [
    "print_unique_data(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "prev_best_loaded = tf.keras.models.load_model('../models/5_lbls_relu_[32, 300, 100, 0.4]_2019518_1_23.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               307500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 339,705\n",
      "Trainable params: 338,905\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prev_best_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model (due to previous notebooks result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "    [32, 300, 100, 0.2],\n",
    "    [32, 300, 100, 0.4],\n",
    "    [32, 512, 256, 0.4],\n",
    "    [32, 512, 256, 0.2],\n",
    "    [32, 256, 128, 0.4],\n",
    "    [32, 256, 128, 0.2],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 5s 42us/sample - loss: 1.1709 - acc: 0.5141 - val_loss: 1.4613 - val_acc: 0.4366\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.9660 - acc: 0.6062 - val_loss: 1.4220 - val_acc: 0.4620\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.8912 - acc: 0.6411 - val_loss: 1.2503 - val_acc: 0.5254\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.8360 - acc: 0.6670 - val_loss: 1.6371 - val_acc: 0.5299\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7857 - acc: 0.6889 - val_loss: 1.4620 - val_acc: 0.5420\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.7393 - acc: 0.7101 - val_loss: 2.7696 - val_acc: 0.4480\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.7036 - acc: 0.7272 - val_loss: 1.1625 - val_acc: 0.5939\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.6709 - acc: 0.7400 - val_loss: 2.2765 - val_acc: 0.4557\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.6503 - acc: 0.7486 - val_loss: 1.3049 - val_acc: 0.5828\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 4s 39us/sample - loss: 0.6215 - acc: 0.7612 - val_loss: 1.1122 - val_acc: 0.6327\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.5990 - acc: 0.7695 - val_loss: 1.3122 - val_acc: 0.5943\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 5s 40us/sample - loss: 0.5740 - acc: 0.7804 - val_loss: 1.0883 - val_acc: 0.6127\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 4s 39us/sample - loss: 0.5571 - acc: 0.7868 - val_loss: 1.1754 - val_acc: 0.6236\n",
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 5s 40us/sample - loss: 0.5416 - acc: 0.7935 - val_loss: 1.4014 - val_acc: 0.6044\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 4s 39us/sample - loss: 0.5292 - acc: 0.7988 - val_loss: 1.7632 - val_acc: 0.5259\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 5s 43us/sample - loss: 0.5178 - acc: 0.8021 - val_loss: 1.0625 - val_acc: 0.6613\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 4s 39us/sample - loss: 0.5045 - acc: 0.8082 - val_loss: 1.4164 - val_acc: 0.5982\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 5s 41us/sample - loss: 0.4931 - acc: 0.8124 - val_loss: 1.1750 - val_acc: 0.6369\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 5s 48us/sample - loss: 0.4775 - acc: 0.8183 - val_loss: 1.5485 - val_acc: 0.5936\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 5s 45us/sample - loss: 0.4711 - acc: 0.8204 - val_loss: 1.9893 - val_acc: 0.5468\n",
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 5s 41us/sample - loss: 0.4586 - acc: 0.8254 - val_loss: 1.2697 - val_acc: 0.6246\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.4497 - acc: 0.8292 - val_loss: 1.3210 - val_acc: 0.6376\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.4432 - acc: 0.8313 - val_loss: 1.2818 - val_acc: 0.6316\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4370 - acc: 0.8332 - val_loss: 1.1684 - val_acc: 0.6385\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4261 - acc: 0.8382 - val_loss: 1.3471 - val_acc: 0.6418\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4218 - acc: 0.8405 - val_loss: 1.0670 - val_acc: 0.6694\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4167 - acc: 0.8424 - val_loss: 1.1782 - val_acc: 0.6582\n",
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4084 - acc: 0.8454 - val_loss: 1.2948 - val_acc: 0.6446\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.4084 - acc: 0.8450 - val_loss: 1.4239 - val_acc: 0.6185\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.3985 - acc: 0.8488 - val_loss: 1.3822 - val_acc: 0.6491\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3921 - acc: 0.8507 - val_loss: 1.1084 - val_acc: 0.6813\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3925 - acc: 0.8518 - val_loss: 2.0381 - val_acc: 0.5875\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3833 - acc: 0.8554 - val_loss: 1.5532 - val_acc: 0.6463\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3794 - acc: 0.8553 - val_loss: 1.1759 - val_acc: 0.6735\n",
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3751 - acc: 0.8579 - val_loss: 1.3672 - val_acc: 0.6361\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3702 - acc: 0.8594 - val_loss: 1.3462 - val_acc: 0.6659\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3666 - acc: 0.8606 - val_loss: 1.3103 - val_acc: 0.6448\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3650 - acc: 0.8621 - val_loss: 1.5074 - val_acc: 0.6440\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.3608 - acc: 0.8631 - val_loss: 1.4122 - val_acc: 0.6537\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3571 - acc: 0.8652 - val_loss: 1.3190 - val_acc: 0.6749\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3523 - acc: 0.8667 - val_loss: 1.4201 - val_acc: 0.6417\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3500 - acc: 0.8670 - val_loss: 1.9034 - val_acc: 0.5883\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3466 - acc: 0.8692 - val_loss: 1.2555 - val_acc: 0.6757\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3424 - acc: 0.8704 - val_loss: 1.4216 - val_acc: 0.6470\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.3413 - acc: 0.8702 - val_loss: 1.4570 - val_acc: 0.6525\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3406 - acc: 0.8729 - val_loss: 1.1457 - val_acc: 0.6801\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3413 - acc: 0.8708 - val_loss: 1.7001 - val_acc: 0.6363\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3351 - acc: 0.8731 - val_loss: 1.2663 - val_acc: 0.6561\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.3313 - acc: 0.8747 - val_loss: 1.5190 - val_acc: 0.6539\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.3321 - acc: 0.8749 - val_loss: 1.5104 - val_acc: 0.6486\n",
      "14200/14200 [==============================] - 0s 33us/sample - loss: 1.5104 - acc: 0.6486\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 5s 41us/sample - loss: 1.2513 - acc: 0.4898 - val_loss: 1.0587 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 1.0131 - acc: 0.5802 - val_loss: 1.1328 - val_acc: 0.5321\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.9544 - acc: 0.6081 - val_loss: 1.2685 - val_acc: 0.4980\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.9143 - acc: 0.6265 - val_loss: 1.6682 - val_acc: 0.4552\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.8867 - acc: 0.6410 - val_loss: 1.1579 - val_acc: 0.5397\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.8638 - acc: 0.6510 - val_loss: 1.2685 - val_acc: 0.5570\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.8418 - acc: 0.6609 - val_loss: 1.1302 - val_acc: 0.5659\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 4s 38us/sample - loss: 0.8173 - acc: 0.6728 - val_loss: 1.0123 - val_acc: 0.6063\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.8052 - acc: 0.6789 - val_loss: 1.2651 - val_acc: 0.5437\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7853 - acc: 0.6867 - val_loss: 1.0769 - val_acc: 0.5894\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7657 - acc: 0.6954 - val_loss: 1.1751 - val_acc: 0.5785\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7497 - acc: 0.7036 - val_loss: 1.2123 - val_acc: 0.5892\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7331 - acc: 0.7099 - val_loss: 1.1935 - val_acc: 0.5794\n",
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.7206 - acc: 0.7160 - val_loss: 1.0672 - val_acc: 0.6237\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.7104 - acc: 0.7182 - val_loss: 1.1404 - val_acc: 0.6065\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.6991 - acc: 0.7227 - val_loss: 1.6416 - val_acc: 0.5514\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.6868 - acc: 0.7294 - val_loss: 1.5494 - val_acc: 0.5527\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6787 - acc: 0.7305 - val_loss: 1.2183 - val_acc: 0.6013\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6717 - acc: 0.7339 - val_loss: 1.2647 - val_acc: 0.5889\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6576 - acc: 0.7412 - val_loss: 1.1060 - val_acc: 0.6282\n",
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6518 - acc: 0.7408 - val_loss: 1.0239 - val_acc: 0.6422\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6423 - acc: 0.7474 - val_loss: 1.0445 - val_acc: 0.6532\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6373 - acc: 0.7477 - val_loss: 1.8459 - val_acc: 0.5377\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.6312 - acc: 0.7512 - val_loss: 1.1010 - val_acc: 0.6304\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.6231 - acc: 0.7546 - val_loss: 1.4710 - val_acc: 0.5925\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6238 - acc: 0.7541 - val_loss: 0.9797 - val_acc: 0.6591\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6177 - acc: 0.7562 - val_loss: 0.9249 - val_acc: 0.6578\n",
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.6076 - acc: 0.7613 - val_loss: 0.9595 - val_acc: 0.6781\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.6027 - acc: 0.7616 - val_loss: 0.9318 - val_acc: 0.6580\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.6000 - acc: 0.7631 - val_loss: 1.0336 - val_acc: 0.6527\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5955 - acc: 0.7647 - val_loss: 0.9685 - val_acc: 0.6757\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5910 - acc: 0.7667 - val_loss: 1.3660 - val_acc: 0.6299\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.5836 - acc: 0.7691 - val_loss: 0.9089 - val_acc: 0.6701\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5843 - acc: 0.7687 - val_loss: 1.0013 - val_acc: 0.6741\n",
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5792 - acc: 0.7715 - val_loss: 1.0859 - val_acc: 0.6610\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5739 - acc: 0.7743 - val_loss: 1.0699 - val_acc: 0.6391\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5673 - acc: 0.7738 - val_loss: 1.2474 - val_acc: 0.6204\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5665 - acc: 0.7753 - val_loss: 1.2857 - val_acc: 0.6315\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5658 - acc: 0.7749 - val_loss: 1.1431 - val_acc: 0.6523\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5586 - acc: 0.7784 - val_loss: 1.1653 - val_acc: 0.6346\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5544 - acc: 0.7791 - val_loss: 0.9623 - val_acc: 0.6825\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5522 - acc: 0.7813 - val_loss: 0.9287 - val_acc: 0.6789\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5509 - acc: 0.7805 - val_loss: 1.1274 - val_acc: 0.6599\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5479 - acc: 0.7825 - val_loss: 1.1186 - val_acc: 0.6504\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5465 - acc: 0.7840 - val_loss: 1.2889 - val_acc: 0.6262\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5454 - acc: 0.7826 - val_loss: 0.9392 - val_acc: 0.6646\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5366 - acc: 0.7868 - val_loss: 1.0081 - val_acc: 0.6854\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 0.5371 - acc: 0.7866 - val_loss: 1.0184 - val_acc: 0.6467\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 4s 37us/sample - loss: 0.5325 - acc: 0.7876 - val_loss: 1.2058 - val_acc: 0.6494\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.5308 - acc: 0.7890 - val_loss: 1.0119 - val_acc: 0.6605\n",
      "14200/14200 [==============================] - 0s 35us/sample - loss: 1.0119 - acc: 0.6605\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 7s 60us/sample - loss: 1.2232 - acc: 0.5076 - val_loss: 1.1652 - val_acc: 0.5240\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.9709 - acc: 0.6031 - val_loss: 1.1875 - val_acc: 0.5157\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.9164 - acc: 0.6286 - val_loss: 1.1546 - val_acc: 0.5420\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 6s 57us/sample - loss: 0.8665 - acc: 0.6524 - val_loss: 1.7598 - val_acc: 0.4805\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.8256 - acc: 0.6710 - val_loss: 2.3624 - val_acc: 0.4476\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.7875 - acc: 0.6871 - val_loss: 6.8477 - val_acc: 0.3321\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.7501 - acc: 0.7056 - val_loss: 2.1721 - val_acc: 0.4794\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.7206 - acc: 0.7175 - val_loss: 1.3936 - val_acc: 0.5805\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6918 - acc: 0.7298 - val_loss: 2.3921 - val_acc: 0.4908\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6607 - acc: 0.7429 - val_loss: 3.7430 - val_acc: 0.4514\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6416 - acc: 0.7512 - val_loss: 1.2009 - val_acc: 0.5956\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6214 - acc: 0.7609 - val_loss: 1.5248 - val_acc: 0.5749\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.5986 - acc: 0.7699 - val_loss: 1.2515 - val_acc: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5811 - acc: 0.7768 - val_loss: 1.4006 - val_acc: 0.6039\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5605 - acc: 0.7857 - val_loss: 1.0340 - val_acc: 0.6643\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5503 - acc: 0.7900 - val_loss: 1.9626 - val_acc: 0.5437\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5351 - acc: 0.7955 - val_loss: 2.0941 - val_acc: 0.5556\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5230 - acc: 0.8010 - val_loss: 2.2754 - val_acc: 0.5459\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.5190 - acc: 0.8028 - val_loss: 1.4486 - val_acc: 0.5985\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 6s 57us/sample - loss: 0.5073 - acc: 0.8079 - val_loss: 2.5793 - val_acc: 0.5207\n",
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.4941 - acc: 0.8116 - val_loss: 1.7970 - val_acc: 0.5595\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4800 - acc: 0.8189 - val_loss: 1.4739 - val_acc: 0.6178\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.4751 - acc: 0.8191 - val_loss: 1.4616 - val_acc: 0.6210\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4662 - acc: 0.8221 - val_loss: 1.0781 - val_acc: 0.6702\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4611 - acc: 0.8255 - val_loss: 1.2891 - val_acc: 0.6473\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4511 - acc: 0.8290 - val_loss: 1.2906 - val_acc: 0.6419\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.4488 - acc: 0.8300 - val_loss: 1.3953 - val_acc: 0.6205\n",
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4380 - acc: 0.8343 - val_loss: 1.5516 - val_acc: 0.6315\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4323 - acc: 0.8367 - val_loss: 1.2876 - val_acc: 0.6689\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4296 - acc: 0.8378 - val_loss: 1.4172 - val_acc: 0.6435\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.4205 - acc: 0.8407 - val_loss: 1.5798 - val_acc: 0.6248\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4175 - acc: 0.8434 - val_loss: 1.0330 - val_acc: 0.6919\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4111 - acc: 0.8453 - val_loss: 1.6882 - val_acc: 0.5528\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.4068 - acc: 0.8455 - val_loss: 1.1990 - val_acc: 0.6825\n",
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.4048 - acc: 0.8465 - val_loss: 1.6550 - val_acc: 0.6446\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3998 - acc: 0.8482 - val_loss: 1.5880 - val_acc: 0.6587\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3935 - acc: 0.8519 - val_loss: 1.3134 - val_acc: 0.6585\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3898 - acc: 0.8528 - val_loss: 1.2081 - val_acc: 0.6867\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3897 - acc: 0.8526 - val_loss: 1.4385 - val_acc: 0.6438\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3858 - acc: 0.8544 - val_loss: 1.0510 - val_acc: 0.6849\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3811 - acc: 0.8550 - val_loss: 1.3368 - val_acc: 0.6581\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3760 - acc: 0.8585 - val_loss: 1.1812 - val_acc: 0.7026\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3778 - acc: 0.8568 - val_loss: 1.3641 - val_acc: 0.6734\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3743 - acc: 0.8585 - val_loss: 1.6637 - val_acc: 0.6374\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3716 - acc: 0.8595 - val_loss: 1.2460 - val_acc: 0.6704\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3673 - acc: 0.8621 - val_loss: 1.4103 - val_acc: 0.6735\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3659 - acc: 0.8623 - val_loss: 1.6351 - val_acc: 0.6465\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3620 - acc: 0.8625 - val_loss: 1.3522 - val_acc: 0.6586\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3560 - acc: 0.8653 - val_loss: 1.3608 - val_acc: 0.6582\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3582 - acc: 0.8655 - val_loss: 1.0377 - val_acc: 0.6991\n",
      "14200/14200 [==============================] - 1s 51us/sample - loss: 1.0377 - acc: 0.6991\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 7s 59us/sample - loss: 1.1535 - acc: 0.5274 - val_loss: 1.3620 - val_acc: 0.4779\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.9363 - acc: 0.6213 - val_loss: 1.0769 - val_acc: 0.5557\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.8478 - acc: 0.6637 - val_loss: 1.8112 - val_acc: 0.4276\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.7822 - acc: 0.6935 - val_loss: 2.7741 - val_acc: 0.4439\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.7205 - acc: 0.7196 - val_loss: 2.4482 - val_acc: 0.4572\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6637 - acc: 0.7432 - val_loss: 1.8764 - val_acc: 0.5181\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.6049 - acc: 0.7685 - val_loss: 1.4882 - val_acc: 0.5540\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.5558 - acc: 0.7894 - val_loss: 2.8615 - val_acc: 0.4440\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.5264 - acc: 0.8007 - val_loss: 1.7033 - val_acc: 0.5409\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.4903 - acc: 0.8164 - val_loss: 2.0862 - val_acc: 0.5063\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.4576 - acc: 0.8275 - val_loss: 1.6769 - val_acc: 0.5868\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.4319 - acc: 0.8379 - val_loss: 1.5039 - val_acc: 0.6155\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.4131 - acc: 0.8454 - val_loss: 1.5267 - val_acc: 0.6052\n",
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3905 - acc: 0.8543 - val_loss: 2.0562 - val_acc: 0.5819\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3734 - acc: 0.8609 - val_loss: 1.6014 - val_acc: 0.6213\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3575 - acc: 0.8662 - val_loss: 1.3795 - val_acc: 0.6639\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3444 - acc: 0.8716 - val_loss: 1.4732 - val_acc: 0.6554\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3306 - acc: 0.8768 - val_loss: 1.3316 - val_acc: 0.6587\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.3196 - acc: 0.8807 - val_loss: 1.4916 - val_acc: 0.6758\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.3069 - acc: 0.8855 - val_loss: 1.8322 - val_acc: 0.5959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.3014 - acc: 0.8876 - val_loss: 1.6767 - val_acc: 0.6346\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2915 - acc: 0.8915 - val_loss: 1.4056 - val_acc: 0.6703\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2846 - acc: 0.8945 - val_loss: 1.5678 - val_acc: 0.6718\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2763 - acc: 0.8975 - val_loss: 1.6004 - val_acc: 0.6282\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2702 - acc: 0.8997 - val_loss: 1.4101 - val_acc: 0.6772\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2652 - acc: 0.9014 - val_loss: 1.1116 - val_acc: 0.7165\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.2537 - acc: 0.9059 - val_loss: 1.5875 - val_acc: 0.6877\n",
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2534 - acc: 0.9069 - val_loss: 1.3933 - val_acc: 0.6602\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2462 - acc: 0.9093 - val_loss: 1.3420 - val_acc: 0.6948\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2432 - acc: 0.9112 - val_loss: 1.1364 - val_acc: 0.7196\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.2381 - acc: 0.9129 - val_loss: 2.1073 - val_acc: 0.5934\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.2336 - acc: 0.9131 - val_loss: 1.4896 - val_acc: 0.6691\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.2317 - acc: 0.9150 - val_loss: 1.9519 - val_acc: 0.6489\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2280 - acc: 0.9166 - val_loss: 1.6840 - val_acc: 0.6601\n",
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2232 - acc: 0.9178 - val_loss: 1.8257 - val_acc: 0.6510\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2201 - acc: 0.9184 - val_loss: 1.9101 - val_acc: 0.6549\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 6s 54us/sample - loss: 0.2160 - acc: 0.9203 - val_loss: 1.3918 - val_acc: 0.6723\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2131 - acc: 0.9219 - val_loss: 1.4773 - val_acc: 0.6849\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.2090 - acc: 0.9236 - val_loss: 1.5560 - val_acc: 0.6823\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.2065 - acc: 0.9242 - val_loss: 2.2351 - val_acc: 0.6549\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2070 - acc: 0.9238 - val_loss: 1.4538 - val_acc: 0.6891\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.2024 - acc: 0.9254 - val_loss: 1.7525 - val_acc: 0.6655\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.2010 - acc: 0.9265 - val_loss: 1.5074 - val_acc: 0.6901\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.1983 - acc: 0.9272 - val_loss: 1.9781 - val_acc: 0.6266\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.1905 - acc: 0.9299 - val_loss: 1.7542 - val_acc: 0.6623\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.1937 - acc: 0.9286 - val_loss: 1.2564 - val_acc: 0.7165\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.1957 - acc: 0.9280 - val_loss: 1.3248 - val_acc: 0.7222\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.1979 - acc: 0.9276 - val_loss: 1.6179 - val_acc: 0.6868\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 6s 56us/sample - loss: 0.1908 - acc: 0.9309 - val_loss: 1.2288 - val_acc: 0.7175\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 6s 55us/sample - loss: 0.1917 - acc: 0.9298 - val_loss: 1.4564 - val_acc: 0.7113\n",
      "14200/14200 [==============================] - 1s 51us/sample - loss: 1.4564 - acc: 0.7113\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 4s 34us/sample - loss: 1.2620 - acc: 0.4860 - val_loss: 1.2722 - val_acc: 0.4625\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 1.0109 - acc: 0.5823 - val_loss: 1.4887 - val_acc: 0.4260\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.9537 - acc: 0.6109 - val_loss: 1.0430 - val_acc: 0.5714\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.9117 - acc: 0.6307 - val_loss: 1.3006 - val_acc: 0.4944\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8786 - acc: 0.6449 - val_loss: 1.5069 - val_acc: 0.4987\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8531 - acc: 0.6561 - val_loss: 1.2233 - val_acc: 0.5265\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8273 - acc: 0.6685 - val_loss: 1.2579 - val_acc: 0.5623\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8046 - acc: 0.6799 - val_loss: 1.1074 - val_acc: 0.5688\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7798 - acc: 0.6912 - val_loss: 1.1509 - val_acc: 0.5850\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7581 - acc: 0.7005 - val_loss: 1.4196 - val_acc: 0.5194\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7388 - acc: 0.7096 - val_loss: 1.3444 - val_acc: 0.5336\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7216 - acc: 0.7156 - val_loss: 1.6982 - val_acc: 0.4896\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7090 - acc: 0.7216 - val_loss: 1.0495 - val_acc: 0.6213\n",
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6912 - acc: 0.7287 - val_loss: 0.9257 - val_acc: 0.6435\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6808 - acc: 0.7343 - val_loss: 0.9355 - val_acc: 0.6538\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6715 - acc: 0.7371 - val_loss: 1.3224 - val_acc: 0.5861\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.6592 - acc: 0.7421 - val_loss: 1.4178 - val_acc: 0.5852\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.6494 - acc: 0.7448 - val_loss: 1.1063 - val_acc: 0.6308\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.6340 - acc: 0.7529 - val_loss: 1.5606 - val_acc: 0.5606\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.6314 - acc: 0.7536 - val_loss: 1.1059 - val_acc: 0.6490\n",
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.6189 - acc: 0.7583 - val_loss: 1.1605 - val_acc: 0.6196\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.6143 - acc: 0.7610 - val_loss: 1.1242 - val_acc: 0.6206\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6050 - acc: 0.7641 - val_loss: 1.2275 - val_acc: 0.6172\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5996 - acc: 0.7655 - val_loss: 1.0467 - val_acc: 0.6558\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5931 - acc: 0.7689 - val_loss: 0.9781 - val_acc: 0.6715\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5855 - acc: 0.7718 - val_loss: 1.1244 - val_acc: 0.6436\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5814 - acc: 0.7730 - val_loss: 1.4519 - val_acc: 0.5928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.5788 - acc: 0.7741 - val_loss: 0.9143 - val_acc: 0.6905\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5697 - acc: 0.7779 - val_loss: 1.1024 - val_acc: 0.6641\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5645 - acc: 0.7812 - val_loss: 1.1601 - val_acc: 0.6539\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5604 - acc: 0.7826 - val_loss: 1.1430 - val_acc: 0.6499\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5549 - acc: 0.7846 - val_loss: 1.1151 - val_acc: 0.6435\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5521 - acc: 0.7855 - val_loss: 1.0734 - val_acc: 0.6609\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5430 - acc: 0.7895 - val_loss: 1.1709 - val_acc: 0.6019\n",
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5433 - acc: 0.7879 - val_loss: 1.3036 - val_acc: 0.6289\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5371 - acc: 0.7913 - val_loss: 1.3411 - val_acc: 0.6130\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5355 - acc: 0.7923 - val_loss: 1.1423 - val_acc: 0.6689\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5309 - acc: 0.7941 - val_loss: 1.0949 - val_acc: 0.6621\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5282 - acc: 0.7945 - val_loss: 1.1879 - val_acc: 0.6447\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5273 - acc: 0.7948 - val_loss: 1.3963 - val_acc: 0.6006\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5213 - acc: 0.7974 - val_loss: 1.1112 - val_acc: 0.6716\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5206 - acc: 0.7979 - val_loss: 1.2032 - val_acc: 0.6219\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5169 - acc: 0.8008 - val_loss: 1.5300 - val_acc: 0.6127\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5157 - acc: 0.8003 - val_loss: 1.1379 - val_acc: 0.6704\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5095 - acc: 0.8024 - val_loss: 1.1492 - val_acc: 0.6638\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5113 - acc: 0.8008 - val_loss: 1.1066 - val_acc: 0.6551\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.5099 - acc: 0.8002 - val_loss: 1.2227 - val_acc: 0.6644\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5027 - acc: 0.8032 - val_loss: 1.0948 - val_acc: 0.6622\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5015 - acc: 0.8045 - val_loss: 1.2265 - val_acc: 0.6680\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5015 - acc: 0.8041 - val_loss: 1.0495 - val_acc: 0.6810\n",
      "14200/14200 [==============================] - 0s 34us/sample - loss: 1.0495 - acc: 0.6810\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/50\n",
      "113600/113600 [==============================] - 4s 35us/sample - loss: 1.1785 - acc: 0.5122 - val_loss: 1.4149 - val_acc: 0.4113\n",
      "Epoch 2/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.9683 - acc: 0.6058 - val_loss: 1.4056 - val_acc: 0.4577\n",
      "Epoch 3/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8847 - acc: 0.6458 - val_loss: 1.1357 - val_acc: 0.5477\n",
      "Epoch 4/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8198 - acc: 0.6738 - val_loss: 1.6829 - val_acc: 0.4823\n",
      "Epoch 5/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7693 - acc: 0.6978 - val_loss: 2.2461 - val_acc: 0.4543\n",
      "Epoch 6/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.7200 - acc: 0.7201 - val_loss: 2.1425 - val_acc: 0.4952\n",
      "Epoch 7/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6728 - acc: 0.7399 - val_loss: 1.2326 - val_acc: 0.5887\n",
      "Epoch 8/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6325 - acc: 0.7573 - val_loss: 1.1313 - val_acc: 0.6073\n",
      "Epoch 9/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5973 - acc: 0.7721 - val_loss: 1.1821 - val_acc: 0.6104\n",
      "Epoch 10/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5707 - acc: 0.7821 - val_loss: 1.2143 - val_acc: 0.6223\n",
      "Epoch 11/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5457 - acc: 0.7937 - val_loss: 1.0704 - val_acc: 0.6584\n",
      "Epoch 12/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5241 - acc: 0.8011 - val_loss: 1.6669 - val_acc: 0.5606\n",
      "Epoch 13/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5078 - acc: 0.8066 - val_loss: 1.7182 - val_acc: 0.5749\n",
      "Epoch 14/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.4885 - acc: 0.8139 - val_loss: 1.4179 - val_acc: 0.6386\n",
      "Epoch 15/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.4702 - acc: 0.8212 - val_loss: 1.4012 - val_acc: 0.5989\n",
      "Epoch 16/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.4597 - acc: 0.8259 - val_loss: 1.6107 - val_acc: 0.6220\n",
      "Epoch 17/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.4453 - acc: 0.8310 - val_loss: 1.0390 - val_acc: 0.6677\n",
      "Epoch 18/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.4311 - acc: 0.8365 - val_loss: 1.4231 - val_acc: 0.6183\n",
      "Epoch 19/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.4226 - acc: 0.8394 - val_loss: 2.5748 - val_acc: 0.5161\n",
      "Epoch 20/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.4100 - acc: 0.8452 - val_loss: 1.4509 - val_acc: 0.6366\n",
      "Epoch 21/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.4007 - acc: 0.8483 - val_loss: 2.2341 - val_acc: 0.5804\n",
      "Epoch 22/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3916 - acc: 0.8521 - val_loss: 1.4355 - val_acc: 0.6412\n",
      "Epoch 23/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.3838 - acc: 0.8542 - val_loss: 1.1457 - val_acc: 0.6796\n",
      "Epoch 24/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3765 - acc: 0.8573 - val_loss: 1.2272 - val_acc: 0.6744\n",
      "Epoch 25/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3686 - acc: 0.8606 - val_loss: 1.1547 - val_acc: 0.6961\n",
      "Epoch 26/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3609 - acc: 0.8628 - val_loss: 1.3344 - val_acc: 0.6650\n",
      "Epoch 27/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3559 - acc: 0.8664 - val_loss: 1.2428 - val_acc: 0.6617\n",
      "Epoch 28/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3529 - acc: 0.8664 - val_loss: 1.3512 - val_acc: 0.6554\n",
      "Epoch 29/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3447 - acc: 0.8702 - val_loss: 1.3300 - val_acc: 0.6468\n",
      "Epoch 30/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3413 - acc: 0.8712 - val_loss: 1.5108 - val_acc: 0.6412\n",
      "Epoch 31/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3366 - acc: 0.8728 - val_loss: 1.1441 - val_acc: 0.6916\n",
      "Epoch 32/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3295 - acc: 0.8763 - val_loss: 1.4788 - val_acc: 0.6575\n",
      "Epoch 33/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3231 - acc: 0.8776 - val_loss: 1.5949 - val_acc: 0.6465\n",
      "Epoch 34/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3237 - acc: 0.8770 - val_loss: 1.4731 - val_acc: 0.6618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3149 - acc: 0.8805 - val_loss: 1.3828 - val_acc: 0.6665\n",
      "Epoch 36/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3165 - acc: 0.8819 - val_loss: 1.3243 - val_acc: 0.6506\n",
      "Epoch 37/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3139 - acc: 0.8812 - val_loss: 1.5168 - val_acc: 0.6551\n",
      "Epoch 38/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3069 - acc: 0.8831 - val_loss: 1.2681 - val_acc: 0.6773\n",
      "Epoch 39/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3035 - acc: 0.8858 - val_loss: 1.3974 - val_acc: 0.6835\n",
      "Epoch 40/50\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.3008 - acc: 0.8871 - val_loss: 1.3470 - val_acc: 0.6708\n",
      "Epoch 41/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2939 - acc: 0.8891 - val_loss: 1.2034 - val_acc: 0.6987\n",
      "Epoch 42/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2955 - acc: 0.8887 - val_loss: 1.6845 - val_acc: 0.6463\n",
      "Epoch 43/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2916 - acc: 0.8903 - val_loss: 1.4686 - val_acc: 0.6628\n",
      "Epoch 44/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2893 - acc: 0.8907 - val_loss: 1.2525 - val_acc: 0.6967\n",
      "Epoch 45/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2861 - acc: 0.8917 - val_loss: 1.7234 - val_acc: 0.6408\n",
      "Epoch 46/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2824 - acc: 0.8943 - val_loss: 1.6907 - val_acc: 0.6296\n",
      "Epoch 47/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2800 - acc: 0.8940 - val_loss: 1.6701 - val_acc: 0.6246\n",
      "Epoch 48/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2820 - acc: 0.8944 - val_loss: 1.2357 - val_acc: 0.6957\n",
      "Epoch 49/50\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2782 - acc: 0.8955 - val_loss: 1.2503 - val_acc: 0.6963\n",
      "Epoch 50/50\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2745 - acc: 0.8970 - val_loss: 1.3558 - val_acc: 0.6878\n",
      "14200/14200 [==============================] - 1s 36us/sample - loss: 1.3558 - acc: 0.6878\n"
     ]
    }
   ],
   "source": [
    "run_custom_training(conf_list, labels, x_train, y_train, x_valid, y_valid, model_path_prefix='5_lbls_relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 July 2019:\n",
    "1. chosen model path: '../models/5_lbls_relu_[32, 512, 256, 0.2]_201978_11_6.h5'\n",
    "2. tensorboard log:   'notebooks/logs/[32, 512, 256, 0.2]_201978_11_6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
