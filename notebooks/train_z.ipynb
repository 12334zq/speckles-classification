{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['yafim', 'zeev', 'or', 'ron', 'sergey', 'aviya', 'elnatan', 'felix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(dates, labels, x_data=[], y_data=[]):\n",
    "    for d in dates:\n",
    "        for i, l in enumerate(labels):\n",
    "            for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "                x_data.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "                y_data.append(i)                \n",
    "    \n",
    "    x_data = np.asarray(x_data)\n",
    "    y_data = np.asarray(y_data)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(x_data, idx):\n",
    "    plt.imshow(x_data[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fc58093bba7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_curr_time():\n",
    "    dt = datetime.datetime.now()\n",
    "    curr_dt = '{0}{1}{2}_{3}_{4}'.format(datetime.datetime.now().year, datetime.datetime.now().month,\n",
    "                                       datetime.datetime.now().day, datetime.datetime.now().hour,\n",
    "                                      datetime.datetime.now().minute)\n",
    "    return curr_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/{0}'.format(curr_dt), histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256, epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "    [32, 512, 0.2],\n",
    "    [32, 256, 0.2],\n",
    "    [32, 512, 0.1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(config, model_weights=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(conf[0], conf[0])),\n",
    "        tf.keras.layers.Dense(conf[1], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(conf[2]),\n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    if model_weights is not None:\n",
    "        print('loading pre-trained model')\n",
    "        model.load_weights(model_weights, by_name=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_training(conf_list, x_train, y_train, x_test, y_test, n_epochs=50, n_batch_size=256, model_path_prefix=None, model_weights=None):\n",
    "    for conf in conf_list:\n",
    "        curr_dt = set_curr_time()\n",
    "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/{0}_{1}'.format(conf, curr_dt),\n",
    "                                                     histogram_freq=0, write_graph=True)\n",
    "        model = custom_model(conf, model_weights)\n",
    "        model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=n_batch_size,\n",
    "                  epochs=n_epochs, callbacks=[tb_callback])\n",
    "        model.evaluate(x_test, y_test)\n",
    "        if model_path_prefix is None:\n",
    "            model.save('../models/{0}_{1}.h5'.format(conf, curr_dt))\n",
    "        else:\n",
    "            model.save('../models/{0}_{1}_{2}.h5'.format(model_path_prefix, conf, curr_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### continues training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = tf.keras.models.load_model('../models/[32, 512, 0.1]_201953_12_56.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256,\n",
    "              epochs=50, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in glob.glob('../models/*.h5'):\n",
    "    print(model_path)\n",
    "    best_loaded = tf.keras.models.load_model(model_path)\n",
    "    best_loaded.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loaded = tf.keras.models.load_model('../models/[32, 512, 0.1]_201953_12_56.h5')\n",
    "test_predictions = best_loaded.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, np.argmax(test_predictions,axis=1))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(confusion, labels, labels)\n",
    "plt.figure(figsize = (12, 9))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, fmt='.5g', annot_kws={\"size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### devided images (biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2999/2999 [00:01<00:00, 2715.17it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 6088.23it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 5432.37it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 6046.65it/s]\n",
      "100%|██████████| 2999/2999 [00:01<00:00, 2657.02it/s]\n",
      "100%|██████████| 29999/29999 [00:05<00:00, 5973.70it/s]\n",
      "100%|██████████| 29999/29999 [00:05<00:00, 5894.58it/s]\n",
      "100%|██████████| 29999/29999 [00:05<00:00, 5878.58it/s]\n",
      "100%|██████████| 2999/2999 [00:01<00:00, 2730.84it/s]\n",
      " 47%|████▋     | 10341/21999 [00:01<00:02, 5740.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-05fce79ef513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/{1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}/{1}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in dates:\n",
    "    for l_idx, l in enumerate(labels):\n",
    "        f_path = '../data/frames/{0}/{1}/32'.format(d, l)\n",
    "        if os.path.exists(f_path):\n",
    "            f_list = os.listdir(f_path)\n",
    "            for i in tqdm(range(0, len(f_list) - 1)):\n",
    "                img1 = cv2.imread('{0}/{1}'.format(f_path, f_list[i]), cv2.IMREAD_GRAYSCALE)\n",
    "                img2 = cv2.imread('{0}/{1}'.format(f_path, f_list[i+1]), cv2.IMREAD_GRAYSCALE)\n",
    "                img = img1 - img2\n",
    "                x_data.append(img)\n",
    "                y_data.append(l_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.asarray(x_data)\n",
    "y_data = np.asarray(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in conf_list:\n",
    "    curr_dt = set_curr_time()\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/sub_imgs_{0}_{1}'.format(conf, curr_dt),\n",
    "                                                 histogram_freq=0, write_graph=True)\n",
    "    model = custom_model(conf)\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=256,\n",
    "              epochs=50, callbacks=[tb_callback])\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save('../models/sub_imgs_{0}_{1}.h5'.format(conf, curr_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 labels (a lot of data for each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['zeev', 'or', 'ron', 'aviya', 'felix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 12098.44it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 11942.92it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 12978.14it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12354.87it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12546.12it/s]\n",
      "100%|██████████| 30000/30000 [00:02<00:00, 12673.26it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 22000/22000 [00:01<00:00, 12512.38it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 21000/21000 [00:01<00:00, 11962.42it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prep_data(dates, labels, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "show_sample() missing 1 required positional argument: 'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46dfed3da2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: show_sample() missing 1 required positional argument: 'idx'"
     ]
    }
   ],
   "source": [
    "show_sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_custom_training(conf_list, x_train, y_train, x_test, y_test,\n",
    "                    model_path_prefix='5_lbls', model_weights='../models/[32, 512, 0.1]_201953_12_56.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF core model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['24032019', '17042019', '01052019']\n",
    "labels = ['zeev', 'or', 'ron', 'aviya', 'felix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 32 * 32\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "\n",
    "n_outputs = len(labels)\n",
    "batch_norm_momentum = 0.9\n",
    "learning_rate = 0.001\n",
    "TRAIN_PERCENT_SPLIT = 0.8\n",
    "VALID_PERCENT_SPLIT = 0.5\n",
    "VALID_AND_TEST = 1 - TRAIN_PERCENT_SPLIT\n",
    "\n",
    "n_epochs = 15\n",
    "batch_size = 256\n",
    "\n",
    "model_path_prefix='tf_core'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prep_data(dates, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 7755.85it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 6754.87it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8200.41it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8109.77it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8534.40it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 8129.14it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 22000/22000 [00:02<00:00, 8481.26it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 21000/21000 [00:02<00:00, 8250.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# stratified data\n",
    "x_train = [] \n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "x_test  = []\n",
    "y_test  = []\n",
    "\n",
    "\n",
    "# for i, l in enumerate(labels):\n",
    "for d in dates:\n",
    "    for i, l in enumerate(labels):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for f in tqdm(glob.glob('../data/frames/{0}/{1}/32/*.png'.format(d, l))):\n",
    "            x_data.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "            y_data.append(i)\n",
    "        x_train_label, xx_test_label, y_train_label, yy_test_label \\\n",
    "                         = train_test_split(x_data, y_data, test_size=VALID_AND_TEST)\n",
    "        x_valid_label, x_test_label, y_valid_label, y_test_label \\\n",
    "                     = train_test_split(xx_test_label, yy_test_label, test_size=VALID_PERCENT_SPLIT)  \n",
    "\n",
    "        x_train.append(x_train_label)\n",
    "        y_train.append(y_train_label)\n",
    "        x_test.append(x_test_label)\n",
    "        y_test.append(y_test_label)\n",
    "        x_valid.append(x_valid_label)\n",
    "        y_valid.append(y_valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "x_train = list(itertools.chain.from_iterable(x_train))\n",
    "y_train = list(itertools.chain.from_iterable(y_train))\n",
    "x_test = list(itertools.chain.from_iterable(x_test))\n",
    "y_test = list(itertools.chain.from_iterable(y_test))\n",
    "x_valid = list(itertools.chain.from_iterable(x_valid))\n",
    "y_valid = list(itertools.chain.from_iterable(y_valid))\n",
    "\n",
    "x_valid = np.asarray(x_valid)\n",
    "y_valid = np.asarray(y_valid)\n",
    "x_test  = np.asarray(x_test)\n",
    "y_test  = np.asarray(y_test)\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_sample(x_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    if (len(X) / batch_size) % 10 is 0:\n",
    "        n_batches = (len(X) // batch_size)\n",
    "    else:\n",
    "        n_batches = (len(X) // batch_size) + 1\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        X_batch = X_batch.reshape(batch_size, n_inputs)\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt = set_curr_time()\n",
    "logdir='./logs/{0}_{1}'.format(model_path_prefix, curr_dt)\n",
    "ce_summary = tf.summary.scalar('cross-entropy', loss)\n",
    "acc_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train) // batch_size)\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "i =0\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in tqdm(shuffle_batch(x_train, y_train, batch_size)):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                                 feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "            summary_str = ce_summary.eval(feed_dict={training: False, X: x_train.reshape(-1, n_inputs), y: y_train})\n",
    "            file_writer.add_summary(summary_str, i)\n",
    "            i += 1\n",
    "        accuracy_val = accuracy.eval(feed_dict={training: False, X: x_test.reshape(-1, n_inputs), y: y_test})\n",
    "        accuracy_val_str = acc_summary.eval(feed_dict={training: False, X: x_test.reshape(-1, n_inputs), y: y_test})\n",
    "        file_writer.add_summary(accuracy_val_str, i)\n",
    "        summary_str = ce_summary.eval(feed_dict={training: False, X: x_test.reshape(-1, n_inputs), y: y_test})\n",
    "        file_writer.add_summary(summary_str, i)\n",
    "\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, '../models/{0}_{1}.ckpt'.format(model_path_prefix, curr_dt))\n",
    "file_writer.flush()\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF core model 2 keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [\n",
    "    [32, 300, 100, 0.4],\n",
    "    [32, 300, 100, 0.2],\n",
    "#     [32, 256, 0.2],\n",
    "#     [32, 512, 0.1],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### acctivation elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(conf, model_weights=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(conf[0], conf[0])),\n",
    "        tf.keras.layers.Dense(conf[1], activation=tf.nn.elu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(conf[2], activation=tf.nn.elu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(conf[3]),\n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    if model_weights is not None:\n",
    "        print('loading pre-trained model')\n",
    "        model.load_weights(model_weights, by_name=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "WARNING:tensorflow:From /Users/zeevkalyuzhner/.virtualenvs/speckles-ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 1.3181 - acc: 0.4675 - val_loss: 1.2267 - val_acc: 0.4735\n",
      "Epoch 2/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 1.0406 - acc: 0.5675 - val_loss: 1.2050 - val_acc: 0.4975\n",
      "Epoch 3/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.9788 - acc: 0.5994 - val_loss: 1.3946 - val_acc: 0.4408\n",
      "Epoch 4/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.9338 - acc: 0.6191 - val_loss: 1.1491 - val_acc: 0.5128\n",
      "Epoch 5/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.8963 - acc: 0.6367 - val_loss: 1.0464 - val_acc: 0.5727\n",
      "Epoch 6/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.8657 - acc: 0.6501 - val_loss: 1.0319 - val_acc: 0.5926\n",
      "Epoch 7/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.8398 - acc: 0.6636 - val_loss: 2.0348 - val_acc: 0.4660\n",
      "Epoch 8/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.8167 - acc: 0.6728 - val_loss: 1.4179 - val_acc: 0.5001\n",
      "Epoch 9/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.7897 - acc: 0.6837 - val_loss: 1.1775 - val_acc: 0.5620\n",
      "Epoch 10/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.7700 - acc: 0.6928 - val_loss: 2.0114 - val_acc: 0.5072\n",
      "Epoch 11/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.7494 - acc: 0.7038 - val_loss: 1.1169 - val_acc: 0.6076\n",
      "Epoch 12/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.7308 - acc: 0.7107 - val_loss: 1.0170 - val_acc: 0.6280\n",
      "Epoch 13/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.7181 - acc: 0.7157 - val_loss: 1.8448 - val_acc: 0.5279\n",
      "Epoch 14/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6989 - acc: 0.7238 - val_loss: 1.3105 - val_acc: 0.5856\n",
      "Epoch 15/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6881 - acc: 0.7284 - val_loss: 2.1549 - val_acc: 0.5268\n",
      "Epoch 16/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6750 - acc: 0.7331 - val_loss: 1.7032 - val_acc: 0.5529\n",
      "Epoch 17/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6629 - acc: 0.7380 - val_loss: 1.3488 - val_acc: 0.5680\n",
      "Epoch 18/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6536 - acc: 0.7429 - val_loss: 1.4785 - val_acc: 0.5762\n",
      "Epoch 19/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.6372 - acc: 0.7493 - val_loss: 1.3169 - val_acc: 0.5896\n",
      "Epoch 20/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6354 - acc: 0.7512 - val_loss: 1.2520 - val_acc: 0.6125\n",
      "Epoch 21/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6202 - acc: 0.7576 - val_loss: 1.3285 - val_acc: 0.6231\n",
      "Epoch 22/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6145 - acc: 0.7589 - val_loss: 1.2128 - val_acc: 0.6237\n",
      "Epoch 23/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6028 - acc: 0.7626 - val_loss: 1.0094 - val_acc: 0.6708\n",
      "Epoch 24/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.5919 - acc: 0.7668 - val_loss: 1.2979 - val_acc: 0.6120\n",
      "Epoch 25/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5837 - acc: 0.7697 - val_loss: 1.0287 - val_acc: 0.6738\n",
      "Epoch 26/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5764 - acc: 0.7735 - val_loss: 1.1007 - val_acc: 0.6282\n",
      "Epoch 27/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.5736 - acc: 0.7737 - val_loss: 1.0907 - val_acc: 0.6533\n",
      "Epoch 28/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5662 - acc: 0.7756 - val_loss: 1.0927 - val_acc: 0.6381\n",
      "Epoch 29/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.5612 - acc: 0.7785 - val_loss: 1.0728 - val_acc: 0.6558\n",
      "Epoch 30/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5530 - acc: 0.7820 - val_loss: 1.3853 - val_acc: 0.6175\n",
      "Epoch 31/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5494 - acc: 0.7834 - val_loss: 1.2988 - val_acc: 0.6093\n",
      "Epoch 32/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5419 - acc: 0.7855 - val_loss: 1.2435 - val_acc: 0.6232\n",
      "Epoch 33/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.5385 - acc: 0.7869 - val_loss: 1.2967 - val_acc: 0.6192\n",
      "Epoch 34/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5345 - acc: 0.7904 - val_loss: 0.9810 - val_acc: 0.6789\n",
      "Epoch 35/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5260 - acc: 0.7914 - val_loss: 0.9997 - val_acc: 0.6805\n",
      "Epoch 36/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5215 - acc: 0.7946 - val_loss: 1.0032 - val_acc: 0.6770\n",
      "Epoch 37/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5152 - acc: 0.7956 - val_loss: 0.9667 - val_acc: 0.6830\n",
      "Epoch 38/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5150 - acc: 0.7946 - val_loss: 1.0052 - val_acc: 0.6720\n",
      "Epoch 39/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5129 - acc: 0.7968 - val_loss: 1.1877 - val_acc: 0.6409\n",
      "Epoch 40/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5083 - acc: 0.7978 - val_loss: 0.9675 - val_acc: 0.6825\n",
      "Epoch 41/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5024 - acc: 0.8020 - val_loss: 1.1294 - val_acc: 0.6581\n",
      "Epoch 42/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4982 - acc: 0.8032 - val_loss: 1.2025 - val_acc: 0.6508\n",
      "Epoch 43/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4982 - acc: 0.8032 - val_loss: 1.0700 - val_acc: 0.6809\n",
      "Epoch 44/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4922 - acc: 0.8048 - val_loss: 1.3200 - val_acc: 0.6497\n",
      "Epoch 45/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4900 - acc: 0.8051 - val_loss: 1.3074 - val_acc: 0.6632\n",
      "Epoch 46/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4901 - acc: 0.8051 - val_loss: 2.0417 - val_acc: 0.5818\n",
      "Epoch 47/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4827 - acc: 0.8082 - val_loss: 1.5719 - val_acc: 0.6127\n",
      "Epoch 48/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4822 - acc: 0.8086 - val_loss: 1.0430 - val_acc: 0.6755\n",
      "Epoch 49/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4773 - acc: 0.8110 - val_loss: 1.0405 - val_acc: 0.6914\n",
      "Epoch 50/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4731 - acc: 0.8114 - val_loss: 1.0541 - val_acc: 0.6732\n",
      "Epoch 51/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4724 - acc: 0.8122 - val_loss: 0.9185 - val_acc: 0.6940\n",
      "Epoch 52/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4706 - acc: 0.8130 - val_loss: 1.6354 - val_acc: 0.6203\n",
      "Epoch 53/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4674 - acc: 0.8134 - val_loss: 1.0863 - val_acc: 0.6696\n",
      "Epoch 54/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4673 - acc: 0.8139 - val_loss: 1.2489 - val_acc: 0.6384\n",
      "Epoch 55/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4632 - acc: 0.8148 - val_loss: 1.0570 - val_acc: 0.6856\n",
      "Epoch 56/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4582 - acc: 0.8168 - val_loss: 1.1789 - val_acc: 0.6695\n",
      "Epoch 57/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4552 - acc: 0.8184 - val_loss: 1.1339 - val_acc: 0.6798\n",
      "Epoch 58/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4564 - acc: 0.8181 - val_loss: 1.2335 - val_acc: 0.6504\n",
      "Epoch 59/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4554 - acc: 0.8189 - val_loss: 1.1690 - val_acc: 0.6759\n",
      "Epoch 60/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4506 - acc: 0.8215 - val_loss: 1.0359 - val_acc: 0.6959\n",
      "Epoch 61/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4503 - acc: 0.8213 - val_loss: 1.1217 - val_acc: 0.6753\n",
      "Epoch 62/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4495 - acc: 0.8209 - val_loss: 1.4880 - val_acc: 0.6445\n",
      "Epoch 63/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4447 - acc: 0.8226 - val_loss: 1.3937 - val_acc: 0.6782\n",
      "Epoch 64/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4439 - acc: 0.8229 - val_loss: 1.0446 - val_acc: 0.6971\n",
      "Epoch 65/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4377 - acc: 0.8244 - val_loss: 1.0887 - val_acc: 0.6988\n",
      "Epoch 66/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4383 - acc: 0.8252 - val_loss: 1.3416 - val_acc: 0.6627\n",
      "Epoch 67/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4371 - acc: 0.8251 - val_loss: 1.2113 - val_acc: 0.6620\n",
      "Epoch 68/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4329 - acc: 0.8280 - val_loss: 1.3701 - val_acc: 0.6760\n",
      "Epoch 69/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4310 - acc: 0.8288 - val_loss: 1.2439 - val_acc: 0.6764\n",
      "Epoch 70/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4318 - acc: 0.8277 - val_loss: 1.2143 - val_acc: 0.6839\n",
      "Epoch 71/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4309 - acc: 0.8278 - val_loss: 1.3116 - val_acc: 0.6699\n",
      "Epoch 72/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4307 - acc: 0.8294 - val_loss: 1.1803 - val_acc: 0.6605\n",
      "Epoch 73/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4268 - acc: 0.8290 - val_loss: 1.3238 - val_acc: 0.6605\n",
      "Epoch 74/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4277 - acc: 0.8297 - val_loss: 1.0362 - val_acc: 0.7016\n",
      "Epoch 75/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4219 - acc: 0.8309 - val_loss: 1.2254 - val_acc: 0.6915\n",
      "Epoch 76/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4259 - acc: 0.8305 - val_loss: 1.7273 - val_acc: 0.6466\n",
      "Epoch 77/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4180 - acc: 0.8332 - val_loss: 1.1394 - val_acc: 0.6820\n",
      "Epoch 78/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4196 - acc: 0.8322 - val_loss: 1.3534 - val_acc: 0.6523\n",
      "Epoch 79/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4211 - acc: 0.8325 - val_loss: 1.0648 - val_acc: 0.7057\n",
      "Epoch 80/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4185 - acc: 0.8323 - val_loss: 1.1447 - val_acc: 0.6831\n",
      "Epoch 81/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4144 - acc: 0.8341 - val_loss: 1.4393 - val_acc: 0.6622\n",
      "Epoch 82/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4129 - acc: 0.8346 - val_loss: 1.3389 - val_acc: 0.6787\n",
      "Epoch 83/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4140 - acc: 0.8330 - val_loss: 1.2038 - val_acc: 0.6803\n",
      "Epoch 84/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4083 - acc: 0.8368 - val_loss: 1.0377 - val_acc: 0.7061\n",
      "Epoch 85/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4107 - acc: 0.8359 - val_loss: 1.2310 - val_acc: 0.6970\n",
      "Epoch 86/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4079 - acc: 0.8360 - val_loss: 1.5791 - val_acc: 0.6577\n",
      "Epoch 87/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4076 - acc: 0.8365 - val_loss: 1.2391 - val_acc: 0.6935\n",
      "Epoch 88/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4075 - acc: 0.8372 - val_loss: 1.2851 - val_acc: 0.6865\n",
      "Epoch 89/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4022 - acc: 0.8392 - val_loss: 1.1115 - val_acc: 0.6852\n",
      "Epoch 90/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4035 - acc: 0.8381 - val_loss: 1.2411 - val_acc: 0.6935\n",
      "Epoch 91/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4036 - acc: 0.8368 - val_loss: 1.7391 - val_acc: 0.6470\n",
      "Epoch 92/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4013 - acc: 0.8388 - val_loss: 1.3607 - val_acc: 0.6565\n",
      "Epoch 93/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4003 - acc: 0.8396 - val_loss: 1.5075 - val_acc: 0.6482\n",
      "Epoch 94/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3987 - acc: 0.8401 - val_loss: 1.5513 - val_acc: 0.6658\n",
      "Epoch 95/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3977 - acc: 0.8411 - val_loss: 1.1713 - val_acc: 0.6904\n",
      "Epoch 96/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3990 - acc: 0.8399 - val_loss: 1.1740 - val_acc: 0.6995\n",
      "Epoch 97/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3954 - acc: 0.8418 - val_loss: 1.4129 - val_acc: 0.6867\n",
      "Epoch 98/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3924 - acc: 0.8426 - val_loss: 1.1789 - val_acc: 0.7020\n",
      "Epoch 99/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3921 - acc: 0.8416 - val_loss: 1.3455 - val_acc: 0.6807\n",
      "Epoch 100/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3933 - acc: 0.8417 - val_loss: 1.2796 - val_acc: 0.6961\n",
      "Epoch 101/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3915 - acc: 0.8422 - val_loss: 1.1663 - val_acc: 0.7042\n",
      "Epoch 102/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3938 - acc: 0.8419 - val_loss: 1.1815 - val_acc: 0.6914\n",
      "Epoch 103/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3900 - acc: 0.8432 - val_loss: 1.2667 - val_acc: 0.7029\n",
      "Epoch 104/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3891 - acc: 0.8431 - val_loss: 1.3900 - val_acc: 0.6746\n",
      "Epoch 105/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3876 - acc: 0.8443 - val_loss: 1.3679 - val_acc: 0.6605\n",
      "Epoch 106/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3813 - acc: 0.8468 - val_loss: 1.1100 - val_acc: 0.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3856 - acc: 0.8451 - val_loss: 1.3109 - val_acc: 0.6994\n",
      "Epoch 108/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3877 - acc: 0.8447 - val_loss: 1.3872 - val_acc: 0.6777\n",
      "Epoch 109/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3913 - acc: 0.8428 - val_loss: 1.2290 - val_acc: 0.6709\n",
      "Epoch 110/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3816 - acc: 0.8473 - val_loss: 1.1801 - val_acc: 0.7023\n",
      "Epoch 111/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3832 - acc: 0.8451 - val_loss: 1.3175 - val_acc: 0.6799\n",
      "Epoch 112/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3867 - acc: 0.8447 - val_loss: 1.1664 - val_acc: 0.7087\n",
      "Epoch 113/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3789 - acc: 0.8488 - val_loss: 1.1470 - val_acc: 0.6876\n",
      "Epoch 114/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3835 - acc: 0.8463 - val_loss: 1.2969 - val_acc: 0.6713\n",
      "Epoch 115/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3787 - acc: 0.8476 - val_loss: 1.2878 - val_acc: 0.7033\n",
      "Epoch 116/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3806 - acc: 0.8468 - val_loss: 1.5821 - val_acc: 0.6549\n",
      "Epoch 117/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3771 - acc: 0.8479 - val_loss: 1.2539 - val_acc: 0.6982\n",
      "Epoch 118/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3748 - acc: 0.8489 - val_loss: 1.2255 - val_acc: 0.6846\n",
      "Epoch 119/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3753 - acc: 0.8477 - val_loss: 1.2319 - val_acc: 0.7018\n",
      "Epoch 120/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3743 - acc: 0.8495 - val_loss: 1.4706 - val_acc: 0.6656\n",
      "Epoch 121/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3733 - acc: 0.8488 - val_loss: 1.2762 - val_acc: 0.7050\n",
      "Epoch 122/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3714 - acc: 0.8505 - val_loss: 1.4186 - val_acc: 0.6914\n",
      "Epoch 123/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3749 - acc: 0.8499 - val_loss: 1.2843 - val_acc: 0.6964\n",
      "Epoch 124/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3715 - acc: 0.8508 - val_loss: 1.5606 - val_acc: 0.6901\n",
      "Epoch 125/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3699 - acc: 0.8510 - val_loss: 1.4050 - val_acc: 0.6858\n",
      "Epoch 126/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3710 - acc: 0.8503 - val_loss: 1.3426 - val_acc: 0.6900\n",
      "Epoch 127/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3701 - acc: 0.8513 - val_loss: 1.3662 - val_acc: 0.6873\n",
      "Epoch 128/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3683 - acc: 0.8527 - val_loss: 1.3398 - val_acc: 0.6711\n",
      "Epoch 129/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3686 - acc: 0.8518 - val_loss: 1.2565 - val_acc: 0.7002\n",
      "Epoch 130/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3663 - acc: 0.8525 - val_loss: 1.1276 - val_acc: 0.7019\n",
      "Epoch 131/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3660 - acc: 0.8519 - val_loss: 1.2381 - val_acc: 0.6919\n",
      "Epoch 132/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3671 - acc: 0.8523 - val_loss: 1.3559 - val_acc: 0.6886\n",
      "Epoch 133/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3666 - acc: 0.8518 - val_loss: 1.5457 - val_acc: 0.6722\n",
      "Epoch 134/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3644 - acc: 0.8523 - val_loss: 1.1568 - val_acc: 0.7049\n",
      "Epoch 135/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3618 - acc: 0.8542 - val_loss: 1.2972 - val_acc: 0.6923\n",
      "Epoch 136/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3628 - acc: 0.8531 - val_loss: 1.3126 - val_acc: 0.6868\n",
      "Epoch 137/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3621 - acc: 0.8550 - val_loss: 1.2462 - val_acc: 0.7092\n",
      "Epoch 138/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3602 - acc: 0.8533 - val_loss: 1.2073 - val_acc: 0.7082\n",
      "Epoch 139/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3579 - acc: 0.8563 - val_loss: 1.4211 - val_acc: 0.6762\n",
      "Epoch 140/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3603 - acc: 0.8543 - val_loss: 1.2433 - val_acc: 0.6854\n",
      "Epoch 141/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3635 - acc: 0.8533 - val_loss: 1.1605 - val_acc: 0.7004\n",
      "Epoch 142/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3560 - acc: 0.8562 - val_loss: 1.4626 - val_acc: 0.6750\n",
      "Epoch 143/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3565 - acc: 0.8564 - val_loss: 1.2635 - val_acc: 0.7023\n",
      "Epoch 144/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3555 - acc: 0.8566 - val_loss: 1.4675 - val_acc: 0.7032\n",
      "Epoch 145/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3536 - acc: 0.8568 - val_loss: 1.6010 - val_acc: 0.6758\n",
      "Epoch 146/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3569 - acc: 0.8562 - val_loss: 1.7224 - val_acc: 0.6708\n",
      "Epoch 147/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3537 - acc: 0.8564 - val_loss: 1.2872 - val_acc: 0.6905\n",
      "Epoch 148/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3544 - acc: 0.8570 - val_loss: 1.3397 - val_acc: 0.7096\n",
      "Epoch 149/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3569 - acc: 0.8561 - val_loss: 1.2527 - val_acc: 0.7096\n",
      "Epoch 150/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3562 - acc: 0.8560 - val_loss: 1.5672 - val_acc: 0.6909\n",
      "Epoch 151/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3520 - acc: 0.8582 - val_loss: 1.2515 - val_acc: 0.7010\n",
      "Epoch 152/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3545 - acc: 0.8569 - val_loss: 1.1713 - val_acc: 0.6992\n",
      "Epoch 153/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3501 - acc: 0.8587 - val_loss: 1.5872 - val_acc: 0.6749\n",
      "Epoch 154/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3509 - acc: 0.8582 - val_loss: 1.1527 - val_acc: 0.7257\n",
      "Epoch 155/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3516 - acc: 0.8580 - val_loss: 1.2390 - val_acc: 0.7155\n",
      "Epoch 156/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3522 - acc: 0.8573 - val_loss: 1.5106 - val_acc: 0.6771\n",
      "Epoch 157/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3493 - acc: 0.8585 - val_loss: 1.3397 - val_acc: 0.6844\n",
      "Epoch 158/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3484 - acc: 0.8598 - val_loss: 1.4362 - val_acc: 0.6910\n",
      "Epoch 159/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3471 - acc: 0.8601 - val_loss: 1.4558 - val_acc: 0.6982\n",
      "Epoch 160/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3458 - acc: 0.8608 - val_loss: 1.2871 - val_acc: 0.7027\n",
      "Epoch 161/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3496 - acc: 0.8587 - val_loss: 1.2975 - val_acc: 0.7004\n",
      "Epoch 162/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3460 - acc: 0.8609 - val_loss: 1.4432 - val_acc: 0.6940\n",
      "Epoch 163/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3471 - acc: 0.8608 - val_loss: 1.2641 - val_acc: 0.7028\n",
      "Epoch 164/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3478 - acc: 0.8599 - val_loss: 1.1857 - val_acc: 0.7132\n",
      "Epoch 165/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3460 - acc: 0.8603 - val_loss: 1.5935 - val_acc: 0.6754\n",
      "Epoch 166/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3458 - acc: 0.8593 - val_loss: 1.2652 - val_acc: 0.7131\n",
      "Epoch 167/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3439 - acc: 0.8610 - val_loss: 1.3682 - val_acc: 0.7015\n",
      "Epoch 168/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3412 - acc: 0.8628 - val_loss: 1.5024 - val_acc: 0.6872\n",
      "Epoch 169/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3427 - acc: 0.8625 - val_loss: 1.3175 - val_acc: 0.6928\n",
      "Epoch 170/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3433 - acc: 0.8611 - val_loss: 1.3050 - val_acc: 0.7022\n",
      "Epoch 171/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3431 - acc: 0.8616 - val_loss: 1.3658 - val_acc: 0.6883\n",
      "Epoch 172/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3402 - acc: 0.8624 - val_loss: 1.2079 - val_acc: 0.7063\n",
      "Epoch 173/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3429 - acc: 0.8617 - val_loss: 1.1976 - val_acc: 0.7125\n",
      "Epoch 174/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3396 - acc: 0.8638 - val_loss: 1.3352 - val_acc: 0.7045\n",
      "Epoch 175/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3386 - acc: 0.8628 - val_loss: 1.5298 - val_acc: 0.6867\n",
      "Epoch 176/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3342 - acc: 0.8651 - val_loss: 1.2264 - val_acc: 0.7111\n",
      "Epoch 177/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3353 - acc: 0.8632 - val_loss: 1.2706 - val_acc: 0.7079\n",
      "Epoch 178/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3413 - acc: 0.8615 - val_loss: 1.1102 - val_acc: 0.7178\n",
      "Epoch 179/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3403 - acc: 0.8625 - val_loss: 1.5072 - val_acc: 0.6744\n",
      "Epoch 180/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3349 - acc: 0.8652 - val_loss: 1.2847 - val_acc: 0.6954\n",
      "Epoch 181/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3370 - acc: 0.8632 - val_loss: 1.3292 - val_acc: 0.7128\n",
      "Epoch 182/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3376 - acc: 0.8640 - val_loss: 1.3236 - val_acc: 0.7047\n",
      "Epoch 183/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3377 - acc: 0.8637 - val_loss: 1.3671 - val_acc: 0.6946\n",
      "Epoch 184/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3372 - acc: 0.8643 - val_loss: 1.3792 - val_acc: 0.7070\n",
      "Epoch 185/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3354 - acc: 0.8635 - val_loss: 1.2918 - val_acc: 0.7087\n",
      "Epoch 186/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3324 - acc: 0.8660 - val_loss: 1.4754 - val_acc: 0.6831\n",
      "Epoch 187/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3368 - acc: 0.8637 - val_loss: 1.4079 - val_acc: 0.6904\n",
      "Epoch 188/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3338 - acc: 0.8658 - val_loss: 1.9879 - val_acc: 0.6443\n",
      "Epoch 189/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3322 - acc: 0.8661 - val_loss: 1.3811 - val_acc: 0.6930\n",
      "Epoch 190/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3335 - acc: 0.8653 - val_loss: 1.1228 - val_acc: 0.7105\n",
      "Epoch 191/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3320 - acc: 0.8656 - val_loss: 1.3746 - val_acc: 0.7084\n",
      "Epoch 192/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3310 - acc: 0.8664 - val_loss: 1.3956 - val_acc: 0.6911\n",
      "Epoch 193/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3324 - acc: 0.8656 - val_loss: 1.4713 - val_acc: 0.6988\n",
      "Epoch 194/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3343 - acc: 0.8659 - val_loss: 1.3263 - val_acc: 0.7013\n",
      "Epoch 195/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3345 - acc: 0.8651 - val_loss: 1.3642 - val_acc: 0.7025\n",
      "Epoch 196/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3304 - acc: 0.8665 - val_loss: 1.2186 - val_acc: 0.7211\n",
      "Epoch 197/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3310 - acc: 0.8651 - val_loss: 1.3683 - val_acc: 0.7095\n",
      "Epoch 198/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3259 - acc: 0.8682 - val_loss: 1.1660 - val_acc: 0.7280\n",
      "Epoch 199/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3329 - acc: 0.8650 - val_loss: 1.4156 - val_acc: 0.7046\n",
      "Epoch 200/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3315 - acc: 0.8659 - val_loss: 1.2706 - val_acc: 0.7112\n",
      "Epoch 201/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3283 - acc: 0.8673 - val_loss: 1.2027 - val_acc: 0.7063\n",
      "Epoch 202/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3307 - acc: 0.8668 - val_loss: 1.3295 - val_acc: 0.7061\n",
      "Epoch 203/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3262 - acc: 0.8681 - val_loss: 1.4194 - val_acc: 0.6970\n",
      "Epoch 204/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3270 - acc: 0.8679 - val_loss: 1.5220 - val_acc: 0.6965\n",
      "Epoch 205/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3284 - acc: 0.8672 - val_loss: 1.7452 - val_acc: 0.6737\n",
      "Epoch 206/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3263 - acc: 0.8676 - val_loss: 1.5499 - val_acc: 0.6810\n",
      "Epoch 207/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3272 - acc: 0.8674 - val_loss: 1.7489 - val_acc: 0.6798\n",
      "Epoch 208/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3241 - acc: 0.8685 - val_loss: 1.1542 - val_acc: 0.7311\n",
      "Epoch 209/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3298 - acc: 0.8680 - val_loss: 1.1635 - val_acc: 0.7148\n",
      "Epoch 210/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3241 - acc: 0.8688 - val_loss: 1.2340 - val_acc: 0.7213\n",
      "Epoch 211/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3252 - acc: 0.8690 - val_loss: 1.4220 - val_acc: 0.6911\n",
      "Epoch 212/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3238 - acc: 0.8688 - val_loss: 1.4552 - val_acc: 0.6949\n",
      "Epoch 213/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3215 - acc: 0.8699 - val_loss: 1.3229 - val_acc: 0.7211\n",
      "Epoch 214/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3252 - acc: 0.8682 - val_loss: 1.3414 - val_acc: 0.7057\n",
      "Epoch 215/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3243 - acc: 0.8685 - val_loss: 1.3001 - val_acc: 0.7044\n",
      "Epoch 216/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3235 - acc: 0.8683 - val_loss: 1.1460 - val_acc: 0.7257\n",
      "Epoch 217/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3236 - acc: 0.8702 - val_loss: 1.4021 - val_acc: 0.7035\n",
      "Epoch 218/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3215 - acc: 0.8693 - val_loss: 1.3087 - val_acc: 0.7063\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3199 - acc: 0.8707 - val_loss: 1.4723 - val_acc: 0.6993\n",
      "Epoch 220/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3212 - acc: 0.8706 - val_loss: 1.2375 - val_acc: 0.7119\n",
      "Epoch 221/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3194 - acc: 0.8708 - val_loss: 1.4463 - val_acc: 0.7096\n",
      "Epoch 222/1000\n",
      "113600/113600 [==============================] - 638s 6ms/sample - loss: 0.3204 - acc: 0.8693 - val_loss: 1.5194 - val_acc: 0.6943\n",
      "Epoch 223/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3212 - acc: 0.8714 - val_loss: 1.4345 - val_acc: 0.7025\n",
      "Epoch 224/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3194 - acc: 0.8703 - val_loss: 1.5497 - val_acc: 0.6842\n",
      "Epoch 225/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3211 - acc: 0.8698 - val_loss: 1.3120 - val_acc: 0.7079\n",
      "Epoch 226/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3167 - acc: 0.8717 - val_loss: 1.3810 - val_acc: 0.7074\n",
      "Epoch 227/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3166 - acc: 0.8718 - val_loss: 1.3079 - val_acc: 0.6986\n",
      "Epoch 228/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3188 - acc: 0.8712 - val_loss: 1.3859 - val_acc: 0.7023\n",
      "Epoch 229/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3182 - acc: 0.8715 - val_loss: 1.2920 - val_acc: 0.6979\n",
      "Epoch 230/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3160 - acc: 0.8726 - val_loss: 1.2601 - val_acc: 0.7195\n",
      "Epoch 231/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3165 - acc: 0.8716 - val_loss: 1.2289 - val_acc: 0.7052\n",
      "Epoch 232/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3159 - acc: 0.8720 - val_loss: 1.3361 - val_acc: 0.7015\n",
      "Epoch 233/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3137 - acc: 0.8722 - val_loss: 1.3862 - val_acc: 0.7083\n",
      "Epoch 234/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3139 - acc: 0.8733 - val_loss: 1.6024 - val_acc: 0.6811\n",
      "Epoch 235/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3148 - acc: 0.8736 - val_loss: 1.4954 - val_acc: 0.6942\n",
      "Epoch 236/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3165 - acc: 0.8714 - val_loss: 1.2195 - val_acc: 0.7154\n",
      "Epoch 237/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3139 - acc: 0.8730 - val_loss: 1.5947 - val_acc: 0.6886\n",
      "Epoch 238/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3140 - acc: 0.8732 - val_loss: 1.4783 - val_acc: 0.7031\n",
      "Epoch 239/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3131 - acc: 0.8732 - val_loss: 1.4503 - val_acc: 0.7009\n",
      "Epoch 240/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3126 - acc: 0.8728 - val_loss: 1.4169 - val_acc: 0.7004\n",
      "Epoch 241/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3154 - acc: 0.8729 - val_loss: 1.3136 - val_acc: 0.7131\n",
      "Epoch 242/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3139 - acc: 0.8724 - val_loss: 1.5919 - val_acc: 0.6877\n",
      "Epoch 243/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3147 - acc: 0.8728 - val_loss: 1.2285 - val_acc: 0.7238\n",
      "Epoch 244/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3135 - acc: 0.8729 - val_loss: 1.3088 - val_acc: 0.7055\n",
      "Epoch 245/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3116 - acc: 0.8736 - val_loss: 1.6766 - val_acc: 0.6970\n",
      "Epoch 246/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3119 - acc: 0.8740 - val_loss: 1.3941 - val_acc: 0.6941\n",
      "Epoch 247/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3127 - acc: 0.8736 - val_loss: 1.3698 - val_acc: 0.6978\n",
      "Epoch 248/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3125 - acc: 0.8736 - val_loss: 1.3518 - val_acc: 0.7086\n",
      "Epoch 249/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3097 - acc: 0.8742 - val_loss: 1.6774 - val_acc: 0.6877\n",
      "Epoch 250/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3082 - acc: 0.8757 - val_loss: 1.3576 - val_acc: 0.7077\n",
      "Epoch 251/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3107 - acc: 0.8747 - val_loss: 1.3493 - val_acc: 0.7100\n",
      "Epoch 252/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3110 - acc: 0.8741 - val_loss: 1.1583 - val_acc: 0.7191\n",
      "Epoch 253/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3076 - acc: 0.8757 - val_loss: 1.3085 - val_acc: 0.7140\n",
      "Epoch 254/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3120 - acc: 0.8743 - val_loss: 1.4191 - val_acc: 0.7010\n",
      "Epoch 255/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3070 - acc: 0.8758 - val_loss: 1.1945 - val_acc: 0.7199\n",
      "Epoch 256/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3061 - acc: 0.8766 - val_loss: 1.3663 - val_acc: 0.7163\n",
      "Epoch 257/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3080 - acc: 0.8759 - val_loss: 1.2631 - val_acc: 0.7128\n",
      "Epoch 258/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3074 - acc: 0.8763 - val_loss: 1.2801 - val_acc: 0.7017\n",
      "Epoch 259/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3077 - acc: 0.8755 - val_loss: 1.3383 - val_acc: 0.7151\n",
      "Epoch 260/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3090 - acc: 0.8738 - val_loss: 1.1869 - val_acc: 0.7192\n",
      "Epoch 261/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3066 - acc: 0.8759 - val_loss: 1.6006 - val_acc: 0.6886\n",
      "Epoch 262/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3050 - acc: 0.8761 - val_loss: 1.4151 - val_acc: 0.7056\n",
      "Epoch 263/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3088 - acc: 0.8751 - val_loss: 1.4105 - val_acc: 0.7020\n",
      "Epoch 264/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3068 - acc: 0.8761 - val_loss: 1.3558 - val_acc: 0.6982\n",
      "Epoch 265/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3066 - acc: 0.8759 - val_loss: 1.5458 - val_acc: 0.6857\n",
      "Epoch 266/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3055 - acc: 0.8765 - val_loss: 1.2518 - val_acc: 0.7114\n",
      "Epoch 267/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.3055 - acc: 0.8773 - val_loss: 1.4021 - val_acc: 0.7169\n",
      "Epoch 268/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3051 - acc: 0.8762 - val_loss: 1.5043 - val_acc: 0.7000\n",
      "Epoch 269/1000\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.3043 - acc: 0.8764 - val_loss: 1.4529 - val_acc: 0.7028\n",
      "Epoch 270/1000\n",
      "113600/113600 [==============================] - 4s 33us/sample - loss: 0.3040 - acc: 0.8771 - val_loss: 1.3376 - val_acc: 0.7159\n",
      "Epoch 271/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.3043 - acc: 0.8764 - val_loss: 1.3061 - val_acc: 0.7145\n",
      "Epoch 272/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.3017 - acc: 0.8781 - val_loss: 1.4118 - val_acc: 0.7090\n",
      "Epoch 273/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.3015 - acc: 0.8778 - val_loss: 1.3958 - val_acc: 0.7011\n",
      "Epoch 274/1000\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.3026 - acc: 0.8776 - val_loss: 1.3786 - val_acc: 0.7123\n",
      "Epoch 275/1000\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.3039 - acc: 0.8769 - val_loss: 1.4269 - val_acc: 0.7045\n",
      "Epoch 276/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.3059 - acc: 0.8753 - val_loss: 1.2942 - val_acc: 0.7142\n",
      "Epoch 277/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3024 - acc: 0.8787 - val_loss: 1.7006 - val_acc: 0.6811\n",
      "Epoch 278/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.3047 - acc: 0.8760 - val_loss: 1.3387 - val_acc: 0.7140\n",
      "Epoch 279/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3000 - acc: 0.8778 - val_loss: 1.3256 - val_acc: 0.7117\n",
      "Epoch 280/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3027 - acc: 0.8777 - val_loss: 1.3556 - val_acc: 0.6992\n",
      "Epoch 281/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3008 - acc: 0.8788 - val_loss: 1.2456 - val_acc: 0.7162\n",
      "Epoch 282/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3001 - acc: 0.8790 - val_loss: 1.4197 - val_acc: 0.7094\n",
      "Epoch 283/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3015 - acc: 0.8785 - val_loss: 1.3773 - val_acc: 0.7008\n",
      "Epoch 284/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2972 - acc: 0.8793 - val_loss: 1.3361 - val_acc: 0.7194\n",
      "Epoch 285/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2973 - acc: 0.8793 - val_loss: 1.5987 - val_acc: 0.6939\n",
      "Epoch 286/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.3016 - acc: 0.8782 - val_loss: 1.2317 - val_acc: 0.7256\n",
      "Epoch 287/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2995 - acc: 0.8800 - val_loss: 1.4539 - val_acc: 0.7072\n",
      "Epoch 288/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2995 - acc: 0.8782 - val_loss: 1.3360 - val_acc: 0.7129\n",
      "Epoch 289/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2993 - acc: 0.8787 - val_loss: 1.6501 - val_acc: 0.6881\n",
      "Epoch 290/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2987 - acc: 0.8785 - val_loss: 1.5654 - val_acc: 0.6975\n",
      "Epoch 291/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2967 - acc: 0.8802 - val_loss: 1.1615 - val_acc: 0.7225\n",
      "Epoch 292/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2973 - acc: 0.8793 - val_loss: 1.3981 - val_acc: 0.7183\n",
      "Epoch 293/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2960 - acc: 0.8799 - val_loss: 1.3307 - val_acc: 0.7122\n",
      "Epoch 294/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2946 - acc: 0.8809 - val_loss: 1.4087 - val_acc: 0.7034\n",
      "Epoch 295/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2928 - acc: 0.8814 - val_loss: 1.2153 - val_acc: 0.7264\n",
      "Epoch 296/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2992 - acc: 0.8799 - val_loss: 1.2450 - val_acc: 0.7134\n",
      "Epoch 297/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2984 - acc: 0.8787 - val_loss: 1.3072 - val_acc: 0.7195\n",
      "Epoch 298/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2961 - acc: 0.8812 - val_loss: 1.2918 - val_acc: 0.7164\n",
      "Epoch 299/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2953 - acc: 0.8800 - val_loss: 1.3387 - val_acc: 0.7089\n",
      "Epoch 300/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2936 - acc: 0.8817 - val_loss: 1.3096 - val_acc: 0.7217\n",
      "Epoch 301/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2935 - acc: 0.8816 - val_loss: 1.4752 - val_acc: 0.7087\n",
      "Epoch 302/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2941 - acc: 0.8820 - val_loss: 1.5510 - val_acc: 0.6899\n",
      "Epoch 303/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2925 - acc: 0.8819 - val_loss: 1.2966 - val_acc: 0.7049\n",
      "Epoch 304/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2969 - acc: 0.8793 - val_loss: 1.2910 - val_acc: 0.7068\n",
      "Epoch 305/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2950 - acc: 0.8802 - val_loss: 1.3328 - val_acc: 0.7104\n",
      "Epoch 306/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.2969 - acc: 0.8797 - val_loss: 1.2934 - val_acc: 0.7144\n",
      "Epoch 307/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2935 - acc: 0.8816 - val_loss: 1.6560 - val_acc: 0.6935\n",
      "Epoch 308/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2928 - acc: 0.8797 - val_loss: 1.3275 - val_acc: 0.7073\n",
      "Epoch 309/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2935 - acc: 0.8815 - val_loss: 1.4766 - val_acc: 0.7054\n",
      "Epoch 310/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2920 - acc: 0.8830 - val_loss: 1.3556 - val_acc: 0.7126\n",
      "Epoch 311/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2917 - acc: 0.8804 - val_loss: 1.4141 - val_acc: 0.7072\n",
      "Epoch 312/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2963 - acc: 0.8798 - val_loss: 1.3839 - val_acc: 0.7132\n",
      "Epoch 313/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2927 - acc: 0.8809 - val_loss: 1.5325 - val_acc: 0.7057\n",
      "Epoch 314/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2954 - acc: 0.8811 - val_loss: 1.2434 - val_acc: 0.7200\n",
      "Epoch 315/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2926 - acc: 0.8815 - val_loss: 1.2927 - val_acc: 0.7077\n",
      "Epoch 316/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2933 - acc: 0.8806 - val_loss: 1.3810 - val_acc: 0.7199\n",
      "Epoch 317/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2965 - acc: 0.8804 - val_loss: 1.2834 - val_acc: 0.7175\n",
      "Epoch 318/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2896 - acc: 0.8829 - val_loss: 1.2871 - val_acc: 0.7181\n",
      "Epoch 319/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2913 - acc: 0.8819 - val_loss: 1.3532 - val_acc: 0.7020\n",
      "Epoch 320/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2899 - acc: 0.8826 - val_loss: 1.5344 - val_acc: 0.7130\n",
      "Epoch 321/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2910 - acc: 0.8823 - val_loss: 1.3612 - val_acc: 0.7067\n",
      "Epoch 322/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2908 - acc: 0.8823 - val_loss: 1.3393 - val_acc: 0.7073\n",
      "Epoch 323/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2844 - acc: 0.8852 - val_loss: 1.3434 - val_acc: 0.7184\n",
      "Epoch 324/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2917 - acc: 0.8811 - val_loss: 1.4569 - val_acc: 0.7085\n",
      "Epoch 325/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2918 - acc: 0.8819 - val_loss: 1.4333 - val_acc: 0.6976\n",
      "Epoch 326/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2873 - acc: 0.8838 - val_loss: 1.6177 - val_acc: 0.6949\n",
      "Epoch 327/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2873 - acc: 0.8831 - val_loss: 1.3345 - val_acc: 0.7207\n",
      "Epoch 328/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2892 - acc: 0.8827 - val_loss: 1.4734 - val_acc: 0.6977\n",
      "Epoch 329/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2863 - acc: 0.8833 - val_loss: 1.5384 - val_acc: 0.7085\n",
      "Epoch 330/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2844 - acc: 0.8845 - val_loss: 1.4277 - val_acc: 0.7103\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2865 - acc: 0.8843 - val_loss: 1.2738 - val_acc: 0.7226\n",
      "Epoch 332/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2889 - acc: 0.8836 - val_loss: 1.5413 - val_acc: 0.7028\n",
      "Epoch 333/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2889 - acc: 0.8825 - val_loss: 1.4094 - val_acc: 0.7120\n",
      "Epoch 334/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2893 - acc: 0.8819 - val_loss: 1.5746 - val_acc: 0.7035\n",
      "Epoch 335/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2855 - acc: 0.8839 - val_loss: 1.4800 - val_acc: 0.7111\n",
      "Epoch 336/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2890 - acc: 0.8827 - val_loss: 1.4682 - val_acc: 0.6989\n",
      "Epoch 337/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2846 - acc: 0.8836 - val_loss: 1.3064 - val_acc: 0.7254\n",
      "Epoch 338/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2868 - acc: 0.8839 - val_loss: 1.3912 - val_acc: 0.7156\n",
      "Epoch 339/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2863 - acc: 0.8838 - val_loss: 1.6113 - val_acc: 0.6949\n",
      "Epoch 340/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2883 - acc: 0.8829 - val_loss: 1.3290 - val_acc: 0.7158\n",
      "Epoch 341/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2866 - acc: 0.8830 - val_loss: 1.4974 - val_acc: 0.7070\n",
      "Epoch 342/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2870 - acc: 0.8857 - val_loss: 1.3566 - val_acc: 0.7056\n",
      "Epoch 343/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2839 - acc: 0.8854 - val_loss: 1.4960 - val_acc: 0.7099\n",
      "Epoch 344/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2852 - acc: 0.8848 - val_loss: 1.5948 - val_acc: 0.7026\n",
      "Epoch 345/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2836 - acc: 0.8849 - val_loss: 1.4963 - val_acc: 0.7071\n",
      "Epoch 346/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2853 - acc: 0.8842 - val_loss: 1.3895 - val_acc: 0.7119\n",
      "Epoch 347/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2861 - acc: 0.8850 - val_loss: 1.4037 - val_acc: 0.7158\n",
      "Epoch 348/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2853 - acc: 0.8846 - val_loss: 1.4042 - val_acc: 0.7146\n",
      "Epoch 349/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2838 - acc: 0.8849 - val_loss: 1.5871 - val_acc: 0.7039\n",
      "Epoch 350/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2847 - acc: 0.8847 - val_loss: 1.5618 - val_acc: 0.7033\n",
      "Epoch 351/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2845 - acc: 0.8850 - val_loss: 1.4321 - val_acc: 0.7067\n",
      "Epoch 352/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2853 - acc: 0.8843 - val_loss: 1.3115 - val_acc: 0.7207\n",
      "Epoch 353/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2862 - acc: 0.8851 - val_loss: 1.5023 - val_acc: 0.7056\n",
      "Epoch 354/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2797 - acc: 0.8870 - val_loss: 1.5501 - val_acc: 0.7094\n",
      "Epoch 355/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2816 - acc: 0.8859 - val_loss: 1.4077 - val_acc: 0.7109\n",
      "Epoch 356/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2834 - acc: 0.8847 - val_loss: 1.3577 - val_acc: 0.7159\n",
      "Epoch 357/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2805 - acc: 0.8859 - val_loss: 1.4989 - val_acc: 0.7150\n",
      "Epoch 358/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2827 - acc: 0.8859 - val_loss: 1.4369 - val_acc: 0.7096\n",
      "Epoch 359/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2859 - acc: 0.8843 - val_loss: 1.3301 - val_acc: 0.7225\n",
      "Epoch 360/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2783 - acc: 0.8875 - val_loss: 1.3913 - val_acc: 0.7213\n",
      "Epoch 361/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2834 - acc: 0.8858 - val_loss: 1.3444 - val_acc: 0.7143\n",
      "Epoch 362/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2797 - acc: 0.8860 - val_loss: 1.5727 - val_acc: 0.7042\n",
      "Epoch 363/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2781 - acc: 0.8880 - val_loss: 1.5037 - val_acc: 0.7043\n",
      "Epoch 364/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2805 - acc: 0.8868 - val_loss: 1.8117 - val_acc: 0.6811\n",
      "Epoch 365/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2835 - acc: 0.8840 - val_loss: 1.2928 - val_acc: 0.7152\n",
      "Epoch 366/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2819 - acc: 0.8860 - val_loss: 1.4521 - val_acc: 0.7166\n",
      "Epoch 367/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2784 - acc: 0.8872 - val_loss: 1.4562 - val_acc: 0.7135\n",
      "Epoch 368/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2780 - acc: 0.8878 - val_loss: 1.4064 - val_acc: 0.7080\n",
      "Epoch 369/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2821 - acc: 0.8850 - val_loss: 1.7382 - val_acc: 0.6885\n",
      "Epoch 370/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2796 - acc: 0.8864 - val_loss: 1.4405 - val_acc: 0.7254\n",
      "Epoch 371/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2810 - acc: 0.8863 - val_loss: 1.3007 - val_acc: 0.7277\n",
      "Epoch 372/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2788 - acc: 0.8866 - val_loss: 1.4135 - val_acc: 0.7173\n",
      "Epoch 373/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2781 - acc: 0.8877 - val_loss: 1.4640 - val_acc: 0.7116\n",
      "Epoch 374/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2761 - acc: 0.8887 - val_loss: 1.5335 - val_acc: 0.6963\n",
      "Epoch 375/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2800 - acc: 0.8864 - val_loss: 1.3689 - val_acc: 0.7163\n",
      "Epoch 376/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2787 - acc: 0.8867 - val_loss: 1.5541 - val_acc: 0.7084\n",
      "Epoch 377/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2776 - acc: 0.8874 - val_loss: 1.4241 - val_acc: 0.7144\n",
      "Epoch 378/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2798 - acc: 0.8865 - val_loss: 1.3058 - val_acc: 0.7116\n",
      "Epoch 379/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2769 - acc: 0.8882 - val_loss: 1.4770 - val_acc: 0.6998\n",
      "Epoch 380/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2758 - acc: 0.8881 - val_loss: 1.3972 - val_acc: 0.7167\n",
      "Epoch 381/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2764 - acc: 0.8874 - val_loss: 1.5337 - val_acc: 0.7090\n",
      "Epoch 382/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2773 - acc: 0.8876 - val_loss: 1.7145 - val_acc: 0.6994\n",
      "Epoch 383/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2767 - acc: 0.8886 - val_loss: 1.7104 - val_acc: 0.6879\n",
      "Epoch 384/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2766 - acc: 0.8881 - val_loss: 1.4801 - val_acc: 0.7174\n",
      "Epoch 385/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2768 - acc: 0.8880 - val_loss: 1.5773 - val_acc: 0.6962\n",
      "Epoch 386/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2765 - acc: 0.8877 - val_loss: 1.3844 - val_acc: 0.7102\n",
      "Epoch 387/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2743 - acc: 0.8896 - val_loss: 1.3857 - val_acc: 0.7141\n",
      "Epoch 388/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2761 - acc: 0.8879 - val_loss: 1.3086 - val_acc: 0.7234\n",
      "Epoch 389/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2761 - acc: 0.8872 - val_loss: 1.8684 - val_acc: 0.6911\n",
      "Epoch 390/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2771 - acc: 0.8878 - val_loss: 1.4948 - val_acc: 0.7216\n",
      "Epoch 391/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2751 - acc: 0.8881 - val_loss: 1.4996 - val_acc: 0.7049\n",
      "Epoch 392/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2763 - acc: 0.8877 - val_loss: 1.4747 - val_acc: 0.7145\n",
      "Epoch 393/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2748 - acc: 0.8891 - val_loss: 1.4732 - val_acc: 0.7172\n",
      "Epoch 394/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2757 - acc: 0.8884 - val_loss: 1.6264 - val_acc: 0.7016\n",
      "Epoch 395/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2769 - acc: 0.8881 - val_loss: 1.6048 - val_acc: 0.7015\n",
      "Epoch 396/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2729 - acc: 0.8889 - val_loss: 1.4861 - val_acc: 0.6934\n",
      "Epoch 397/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2729 - acc: 0.8901 - val_loss: 1.4459 - val_acc: 0.7109\n",
      "Epoch 398/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2760 - acc: 0.8891 - val_loss: 1.6959 - val_acc: 0.6935\n",
      "Epoch 399/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2764 - acc: 0.8888 - val_loss: 1.4930 - val_acc: 0.6985\n",
      "Epoch 400/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2710 - acc: 0.8901 - val_loss: 1.4169 - val_acc: 0.7194\n",
      "Epoch 401/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2737 - acc: 0.8890 - val_loss: 1.4453 - val_acc: 0.7043\n",
      "Epoch 402/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2745 - acc: 0.8886 - val_loss: 1.4411 - val_acc: 0.7112\n",
      "Epoch 403/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2724 - acc: 0.8900 - val_loss: 1.4745 - val_acc: 0.7056\n",
      "Epoch 404/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2747 - acc: 0.8885 - val_loss: 1.4720 - val_acc: 0.7153\n",
      "Epoch 405/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2703 - acc: 0.8896 - val_loss: 1.5634 - val_acc: 0.6955\n",
      "Epoch 406/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2721 - acc: 0.8892 - val_loss: 1.2937 - val_acc: 0.7268\n",
      "Epoch 407/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2712 - acc: 0.8899 - val_loss: 1.5013 - val_acc: 0.7213\n",
      "Epoch 408/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2712 - acc: 0.8893 - val_loss: 1.4555 - val_acc: 0.7076\n",
      "Epoch 409/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2690 - acc: 0.8902 - val_loss: 1.3962 - val_acc: 0.7158\n",
      "Epoch 410/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2714 - acc: 0.8901 - val_loss: 1.4676 - val_acc: 0.7065\n",
      "Epoch 411/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2692 - acc: 0.8915 - val_loss: 1.4139 - val_acc: 0.7213\n",
      "Epoch 412/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2716 - acc: 0.8897 - val_loss: 1.4036 - val_acc: 0.7150\n",
      "Epoch 413/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2674 - acc: 0.8917 - val_loss: 1.2812 - val_acc: 0.7316\n",
      "Epoch 414/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2717 - acc: 0.8913 - val_loss: 1.5278 - val_acc: 0.7095\n",
      "Epoch 415/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2702 - acc: 0.8910 - val_loss: 1.3920 - val_acc: 0.7242\n",
      "Epoch 416/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2726 - acc: 0.8889 - val_loss: 1.3342 - val_acc: 0.7257\n",
      "Epoch 417/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2706 - acc: 0.8901 - val_loss: 1.4367 - val_acc: 0.7185\n",
      "Epoch 418/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2712 - acc: 0.8906 - val_loss: 1.4583 - val_acc: 0.7118\n",
      "Epoch 419/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2727 - acc: 0.8902 - val_loss: 1.3398 - val_acc: 0.7247\n",
      "Epoch 420/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2698 - acc: 0.8904 - val_loss: 1.5232 - val_acc: 0.7201\n",
      "Epoch 421/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2712 - acc: 0.8898 - val_loss: 1.4812 - val_acc: 0.6988\n",
      "Epoch 422/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2716 - acc: 0.8910 - val_loss: 1.4882 - val_acc: 0.7127\n",
      "Epoch 423/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2691 - acc: 0.8921 - val_loss: 1.7936 - val_acc: 0.6915\n",
      "Epoch 424/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2672 - acc: 0.8925 - val_loss: 1.5353 - val_acc: 0.7142\n",
      "Epoch 425/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2684 - acc: 0.8918 - val_loss: 1.3786 - val_acc: 0.7351\n",
      "Epoch 426/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2690 - acc: 0.8907 - val_loss: 1.4745 - val_acc: 0.7126\n",
      "Epoch 427/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2697 - acc: 0.8909 - val_loss: 1.3756 - val_acc: 0.7258\n",
      "Epoch 428/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2660 - acc: 0.8921 - val_loss: 1.8359 - val_acc: 0.6999\n",
      "Epoch 429/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2731 - acc: 0.8909 - val_loss: 1.5675 - val_acc: 0.7040\n",
      "Epoch 430/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2699 - acc: 0.8907 - val_loss: 1.6157 - val_acc: 0.7073\n",
      "Epoch 431/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2676 - acc: 0.8913 - val_loss: 1.5137 - val_acc: 0.7075\n",
      "Epoch 432/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2682 - acc: 0.8917 - val_loss: 1.6496 - val_acc: 0.7073\n",
      "Epoch 433/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2683 - acc: 0.8918 - val_loss: 1.4325 - val_acc: 0.7237\n",
      "Epoch 434/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2653 - acc: 0.8933 - val_loss: 1.5545 - val_acc: 0.7064\n",
      "Epoch 435/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2707 - acc: 0.8917 - val_loss: 1.4251 - val_acc: 0.7101\n",
      "Epoch 436/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2649 - acc: 0.8933 - val_loss: 1.5442 - val_acc: 0.7068\n",
      "Epoch 437/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2673 - acc: 0.8918 - val_loss: 1.4864 - val_acc: 0.7192\n",
      "Epoch 438/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2664 - acc: 0.8919 - val_loss: 1.6259 - val_acc: 0.7059\n",
      "Epoch 439/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2694 - acc: 0.8907 - val_loss: 1.3152 - val_acc: 0.7227\n",
      "Epoch 440/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2692 - acc: 0.8908 - val_loss: 1.4377 - val_acc: 0.7211\n",
      "Epoch 441/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2660 - acc: 0.8929 - val_loss: 1.5605 - val_acc: 0.7121\n",
      "Epoch 442/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2697 - acc: 0.8906 - val_loss: 1.4984 - val_acc: 0.7072\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2668 - acc: 0.8923 - val_loss: 1.4028 - val_acc: 0.7225\n",
      "Epoch 444/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2646 - acc: 0.8930 - val_loss: 1.3903 - val_acc: 0.7318\n",
      "Epoch 445/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2635 - acc: 0.8933 - val_loss: 1.3542 - val_acc: 0.7060\n",
      "Epoch 446/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2654 - acc: 0.8931 - val_loss: 1.3338 - val_acc: 0.7220\n",
      "Epoch 447/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2651 - acc: 0.8931 - val_loss: 1.4609 - val_acc: 0.7112\n",
      "Epoch 448/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2675 - acc: 0.8908 - val_loss: 1.5520 - val_acc: 0.7090\n",
      "Epoch 449/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2653 - acc: 0.8927 - val_loss: 1.4900 - val_acc: 0.7131\n",
      "Epoch 450/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2649 - acc: 0.8928 - val_loss: 1.3470 - val_acc: 0.7174\n",
      "Epoch 451/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2625 - acc: 0.8930 - val_loss: 1.5109 - val_acc: 0.7169\n",
      "Epoch 452/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2631 - acc: 0.8943 - val_loss: 1.4614 - val_acc: 0.7103\n",
      "Epoch 453/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2639 - acc: 0.8936 - val_loss: 1.4217 - val_acc: 0.7221\n",
      "Epoch 454/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2647 - acc: 0.8925 - val_loss: 1.5775 - val_acc: 0.7151\n",
      "Epoch 455/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2648 - acc: 0.8927 - val_loss: 1.5259 - val_acc: 0.7149\n",
      "Epoch 456/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2638 - acc: 0.8919 - val_loss: 1.4470 - val_acc: 0.7101\n",
      "Epoch 457/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2646 - acc: 0.8934 - val_loss: 1.2716 - val_acc: 0.7292\n",
      "Epoch 458/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2635 - acc: 0.8936 - val_loss: 1.4684 - val_acc: 0.7275\n",
      "Epoch 459/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2661 - acc: 0.8924 - val_loss: 1.4073 - val_acc: 0.7230\n",
      "Epoch 460/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2652 - acc: 0.8926 - val_loss: 1.5595 - val_acc: 0.7037\n",
      "Epoch 461/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2658 - acc: 0.8919 - val_loss: 1.4765 - val_acc: 0.7082\n",
      "Epoch 462/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2640 - acc: 0.8932 - val_loss: 1.5292 - val_acc: 0.7114\n",
      "Epoch 463/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2606 - acc: 0.8942 - val_loss: 1.3533 - val_acc: 0.7237\n",
      "Epoch 464/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2647 - acc: 0.8941 - val_loss: 1.4821 - val_acc: 0.6984\n",
      "Epoch 465/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2660 - acc: 0.8921 - val_loss: 1.4009 - val_acc: 0.7165\n",
      "Epoch 466/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2610 - acc: 0.8939 - val_loss: 1.4415 - val_acc: 0.7199\n",
      "Epoch 467/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2602 - acc: 0.8959 - val_loss: 1.5541 - val_acc: 0.7191\n",
      "Epoch 468/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2624 - acc: 0.8944 - val_loss: 1.5625 - val_acc: 0.7150\n",
      "Epoch 469/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2605 - acc: 0.8946 - val_loss: 1.3876 - val_acc: 0.7201\n",
      "Epoch 470/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2596 - acc: 0.8954 - val_loss: 1.2791 - val_acc: 0.7327\n",
      "Epoch 471/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2628 - acc: 0.8948 - val_loss: 1.4981 - val_acc: 0.7192\n",
      "Epoch 472/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2601 - acc: 0.8939 - val_loss: 1.3518 - val_acc: 0.7249\n",
      "Epoch 473/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2586 - acc: 0.8953 - val_loss: 1.2707 - val_acc: 0.7286\n",
      "Epoch 474/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2624 - acc: 0.8933 - val_loss: 1.5720 - val_acc: 0.7090\n",
      "Epoch 475/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2633 - acc: 0.8938 - val_loss: 1.5396 - val_acc: 0.7124\n",
      "Epoch 476/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2642 - acc: 0.8932 - val_loss: 1.4331 - val_acc: 0.7202\n",
      "Epoch 477/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2629 - acc: 0.8939 - val_loss: 1.3616 - val_acc: 0.7225\n",
      "Epoch 478/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2606 - acc: 0.8941 - val_loss: 1.5387 - val_acc: 0.7210\n",
      "Epoch 479/1000\n",
      "113600/113600 [==============================] - 106s 932us/sample - loss: 0.2613 - acc: 0.8954 - val_loss: 1.4916 - val_acc: 0.7071\n",
      "Epoch 480/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2612 - acc: 0.8959 - val_loss: 1.3799 - val_acc: 0.7190\n",
      "Epoch 481/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2594 - acc: 0.8953 - val_loss: 1.5513 - val_acc: 0.7216\n",
      "Epoch 482/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2615 - acc: 0.8936 - val_loss: 1.6324 - val_acc: 0.7064\n",
      "Epoch 483/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2592 - acc: 0.8966 - val_loss: 1.4204 - val_acc: 0.7146\n",
      "Epoch 484/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2603 - acc: 0.8941 - val_loss: 1.5563 - val_acc: 0.7119\n",
      "Epoch 485/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2582 - acc: 0.8948 - val_loss: 1.8009 - val_acc: 0.6880\n",
      "Epoch 486/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2590 - acc: 0.8956 - val_loss: 1.4677 - val_acc: 0.7199\n",
      "Epoch 487/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2601 - acc: 0.8941 - val_loss: 1.7088 - val_acc: 0.6926\n",
      "Epoch 488/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2587 - acc: 0.8954 - val_loss: 1.4893 - val_acc: 0.7175\n",
      "Epoch 489/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.2584 - acc: 0.8967 - val_loss: 1.5940 - val_acc: 0.7104\n",
      "Epoch 490/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2592 - acc: 0.8950 - val_loss: 1.3437 - val_acc: 0.7222\n",
      "Epoch 491/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2584 - acc: 0.8957 - val_loss: 1.4045 - val_acc: 0.7225\n",
      "Epoch 492/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2625 - acc: 0.8942 - val_loss: 1.5981 - val_acc: 0.7149\n",
      "Epoch 493/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.2574 - acc: 0.8964 - val_loss: 1.6472 - val_acc: 0.6892\n",
      "Epoch 494/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2585 - acc: 0.8953 - val_loss: 1.4085 - val_acc: 0.7163\n",
      "Epoch 495/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.2567 - acc: 0.8960 - val_loss: 1.5902 - val_acc: 0.7194\n",
      "Epoch 496/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2556 - acc: 0.8967 - val_loss: 1.4657 - val_acc: 0.7125\n",
      "Epoch 497/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.2565 - acc: 0.8975 - val_loss: 1.5549 - val_acc: 0.7192\n",
      "Epoch 498/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2638 - acc: 0.8931 - val_loss: 1.3510 - val_acc: 0.7245\n",
      "Epoch 499/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2591 - acc: 0.8954 - val_loss: 1.6307 - val_acc: 0.7083\n",
      "Epoch 500/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2569 - acc: 0.8962 - val_loss: 1.5101 - val_acc: 0.7073\n",
      "Epoch 501/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2581 - acc: 0.8964 - val_loss: 1.5923 - val_acc: 0.6975\n",
      "Epoch 502/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2576 - acc: 0.8957 - val_loss: 1.5196 - val_acc: 0.7134\n",
      "Epoch 503/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2588 - acc: 0.8958 - val_loss: 1.4650 - val_acc: 0.7158\n",
      "Epoch 504/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2607 - acc: 0.8945 - val_loss: 1.3493 - val_acc: 0.7275\n",
      "Epoch 505/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2578 - acc: 0.8957 - val_loss: 1.3964 - val_acc: 0.7307\n",
      "Epoch 506/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2564 - acc: 0.8970 - val_loss: 1.4323 - val_acc: 0.7273\n",
      "Epoch 507/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2549 - acc: 0.8969 - val_loss: 1.3595 - val_acc: 0.7221\n",
      "Epoch 508/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2566 - acc: 0.8963 - val_loss: 1.6767 - val_acc: 0.6987\n",
      "Epoch 509/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2545 - acc: 0.8979 - val_loss: 1.3705 - val_acc: 0.7295\n",
      "Epoch 510/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2544 - acc: 0.8969 - val_loss: 1.5198 - val_acc: 0.7186\n",
      "Epoch 511/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2560 - acc: 0.8971 - val_loss: 1.5635 - val_acc: 0.7065\n",
      "Epoch 512/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2564 - acc: 0.8966 - val_loss: 1.4131 - val_acc: 0.7254\n",
      "Epoch 513/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2577 - acc: 0.8966 - val_loss: 1.4864 - val_acc: 0.7176\n",
      "Epoch 514/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2539 - acc: 0.8970 - val_loss: 1.4852 - val_acc: 0.7177\n",
      "Epoch 515/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2541 - acc: 0.8964 - val_loss: 1.4873 - val_acc: 0.7037\n",
      "Epoch 516/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2548 - acc: 0.8975 - val_loss: 1.4745 - val_acc: 0.7228\n",
      "Epoch 517/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2544 - acc: 0.8972 - val_loss: 1.2822 - val_acc: 0.7381\n",
      "Epoch 518/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2562 - acc: 0.8960 - val_loss: 1.4430 - val_acc: 0.7268\n",
      "Epoch 519/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2537 - acc: 0.8972 - val_loss: 1.4315 - val_acc: 0.7244\n",
      "Epoch 520/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.2541 - acc: 0.8972 - val_loss: 1.4942 - val_acc: 0.7159\n",
      "Epoch 521/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2550 - acc: 0.8970 - val_loss: 1.4764 - val_acc: 0.7213\n",
      "Epoch 522/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2527 - acc: 0.8985 - val_loss: 1.3563 - val_acc: 0.7247\n",
      "Epoch 523/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2531 - acc: 0.8970 - val_loss: 1.5601 - val_acc: 0.7211\n",
      "Epoch 524/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2550 - acc: 0.8982 - val_loss: 1.5201 - val_acc: 0.7098\n",
      "Epoch 525/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2554 - acc: 0.8971 - val_loss: 1.4340 - val_acc: 0.7192\n",
      "Epoch 526/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2550 - acc: 0.8962 - val_loss: 1.5188 - val_acc: 0.7084\n",
      "Epoch 527/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2508 - acc: 0.8988 - val_loss: 1.6271 - val_acc: 0.7013\n",
      "Epoch 528/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2525 - acc: 0.8981 - val_loss: 1.5245 - val_acc: 0.7098\n",
      "Epoch 529/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2520 - acc: 0.8987 - val_loss: 1.4536 - val_acc: 0.7184\n",
      "Epoch 530/1000\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.2539 - acc: 0.8977 - val_loss: 1.5918 - val_acc: 0.6975\n",
      "Epoch 531/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.2549 - acc: 0.8972 - val_loss: 1.3743 - val_acc: 0.7254\n",
      "Epoch 532/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2526 - acc: 0.8982 - val_loss: 1.4678 - val_acc: 0.7237\n",
      "Epoch 533/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2533 - acc: 0.8979 - val_loss: 1.5842 - val_acc: 0.7190\n",
      "Epoch 534/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2515 - acc: 0.8986 - val_loss: 1.5438 - val_acc: 0.7051\n",
      "Epoch 535/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2538 - acc: 0.8973 - val_loss: 1.4725 - val_acc: 0.7169\n",
      "Epoch 536/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2494 - acc: 0.8990 - val_loss: 1.4755 - val_acc: 0.6915\n",
      "Epoch 537/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2538 - acc: 0.8970 - val_loss: 1.6196 - val_acc: 0.6985\n",
      "Epoch 538/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2551 - acc: 0.8970 - val_loss: 1.6085 - val_acc: 0.7202\n",
      "Epoch 539/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2494 - acc: 0.8995 - val_loss: 1.5071 - val_acc: 0.7262\n",
      "Epoch 540/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2560 - acc: 0.8976 - val_loss: 1.5437 - val_acc: 0.7151\n",
      "Epoch 541/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2503 - acc: 0.8983 - val_loss: 1.5756 - val_acc: 0.7085\n",
      "Epoch 542/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2514 - acc: 0.8979 - val_loss: 1.3346 - val_acc: 0.7187\n",
      "Epoch 543/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.2518 - acc: 0.8982 - val_loss: 1.6548 - val_acc: 0.6870\n",
      "Epoch 544/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2524 - acc: 0.8978 - val_loss: 1.3697 - val_acc: 0.7256\n",
      "Epoch 545/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2516 - acc: 0.8988 - val_loss: 1.7938 - val_acc: 0.6960\n",
      "Epoch 546/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2483 - acc: 0.8997 - val_loss: 1.4504 - val_acc: 0.7116\n",
      "Epoch 547/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2513 - acc: 0.8980 - val_loss: 1.3939 - val_acc: 0.7227\n",
      "Epoch 548/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2515 - acc: 0.8984 - val_loss: 1.4698 - val_acc: 0.7186\n",
      "Epoch 549/1000\n",
      "113600/113600 [==============================] - 4s 31us/sample - loss: 0.2522 - acc: 0.8982 - val_loss: 1.3851 - val_acc: 0.7206\n",
      "Epoch 550/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2548 - acc: 0.8973 - val_loss: 1.5922 - val_acc: 0.7061\n",
      "Epoch 551/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2480 - acc: 0.8995 - val_loss: 1.5651 - val_acc: 0.7166\n",
      "Epoch 552/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2508 - acc: 0.8983 - val_loss: 1.3893 - val_acc: 0.7296\n",
      "Epoch 553/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2502 - acc: 0.8988 - val_loss: 1.5458 - val_acc: 0.6973\n",
      "Epoch 554/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2511 - acc: 0.8984 - val_loss: 1.5325 - val_acc: 0.7206\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2492 - acc: 0.8986 - val_loss: 1.3254 - val_acc: 0.7289\n",
      "Epoch 556/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2475 - acc: 0.8993 - val_loss: 1.3941 - val_acc: 0.7242\n",
      "Epoch 557/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2451 - acc: 0.9014 - val_loss: 1.4435 - val_acc: 0.7154\n",
      "Epoch 558/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2523 - acc: 0.8980 - val_loss: 1.4868 - val_acc: 0.7199\n",
      "Epoch 559/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2506 - acc: 0.8988 - val_loss: 1.7724 - val_acc: 0.7073\n",
      "Epoch 560/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2500 - acc: 0.8993 - val_loss: 1.6118 - val_acc: 0.7247\n",
      "Epoch 561/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2517 - acc: 0.8979 - val_loss: 1.4187 - val_acc: 0.7244\n",
      "Epoch 562/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2505 - acc: 0.8986 - val_loss: 1.4257 - val_acc: 0.7277\n",
      "Epoch 563/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2511 - acc: 0.8979 - val_loss: 1.3594 - val_acc: 0.7258\n",
      "Epoch 564/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2491 - acc: 0.8998 - val_loss: 1.5569 - val_acc: 0.7151\n",
      "Epoch 565/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2527 - acc: 0.8982 - val_loss: 1.5648 - val_acc: 0.7182\n",
      "Epoch 566/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2481 - acc: 0.8996 - val_loss: 1.4569 - val_acc: 0.7249\n",
      "Epoch 567/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2481 - acc: 0.8995 - val_loss: 1.6086 - val_acc: 0.7009\n",
      "Epoch 568/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2493 - acc: 0.8993 - val_loss: 1.6537 - val_acc: 0.6982\n",
      "Epoch 569/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2528 - acc: 0.8978 - val_loss: 1.5221 - val_acc: 0.7272\n",
      "Epoch 570/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2473 - acc: 0.9008 - val_loss: 1.4767 - val_acc: 0.7200\n",
      "Epoch 571/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2469 - acc: 0.9003 - val_loss: 1.5770 - val_acc: 0.7115\n",
      "Epoch 572/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2471 - acc: 0.8999 - val_loss: 1.4237 - val_acc: 0.7301\n",
      "Epoch 573/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2535 - acc: 0.8983 - val_loss: 1.6008 - val_acc: 0.7094\n",
      "Epoch 574/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2489 - acc: 0.8989 - val_loss: 1.3845 - val_acc: 0.7234\n",
      "Epoch 575/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2495 - acc: 0.8989 - val_loss: 1.4022 - val_acc: 0.7202\n",
      "Epoch 576/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2489 - acc: 0.8994 - val_loss: 1.4081 - val_acc: 0.7286\n",
      "Epoch 577/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2453 - acc: 0.9009 - val_loss: 1.4068 - val_acc: 0.7235\n",
      "Epoch 578/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2474 - acc: 0.9003 - val_loss: 1.5971 - val_acc: 0.6980\n",
      "Epoch 579/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2487 - acc: 0.9005 - val_loss: 1.6318 - val_acc: 0.7056\n",
      "Epoch 580/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2463 - acc: 0.9004 - val_loss: 1.4104 - val_acc: 0.7339\n",
      "Epoch 581/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2477 - acc: 0.8998 - val_loss: 1.6245 - val_acc: 0.7197\n",
      "Epoch 582/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2453 - acc: 0.9014 - val_loss: 1.5509 - val_acc: 0.7073\n",
      "Epoch 583/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2468 - acc: 0.9007 - val_loss: 1.4997 - val_acc: 0.7253\n",
      "Epoch 584/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2477 - acc: 0.8995 - val_loss: 1.5179 - val_acc: 0.7273\n",
      "Epoch 585/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2504 - acc: 0.8995 - val_loss: 1.5822 - val_acc: 0.7114\n",
      "Epoch 586/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2449 - acc: 0.9011 - val_loss: 1.5110 - val_acc: 0.7204\n",
      "Epoch 587/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2446 - acc: 0.9014 - val_loss: 1.6001 - val_acc: 0.6942\n",
      "Epoch 588/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2442 - acc: 0.9016 - val_loss: 1.4921 - val_acc: 0.7162\n",
      "Epoch 589/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2505 - acc: 0.8989 - val_loss: 1.4074 - val_acc: 0.7216\n",
      "Epoch 590/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2487 - acc: 0.8995 - val_loss: 1.5577 - val_acc: 0.7018\n",
      "Epoch 591/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2483 - acc: 0.9000 - val_loss: 1.4944 - val_acc: 0.7146\n",
      "Epoch 592/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2433 - acc: 0.9009 - val_loss: 1.4472 - val_acc: 0.7190\n",
      "Epoch 593/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2451 - acc: 0.9009 - val_loss: 1.5513 - val_acc: 0.7228\n",
      "Epoch 594/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2466 - acc: 0.9001 - val_loss: 1.4649 - val_acc: 0.7194\n",
      "Epoch 595/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2473 - acc: 0.8999 - val_loss: 1.8083 - val_acc: 0.6842\n",
      "Epoch 596/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2450 - acc: 0.9004 - val_loss: 1.5213 - val_acc: 0.7202\n",
      "Epoch 597/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2467 - acc: 0.8996 - val_loss: 1.4331 - val_acc: 0.7215\n",
      "Epoch 598/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2481 - acc: 0.8987 - val_loss: 1.4414 - val_acc: 0.7215\n",
      "Epoch 599/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2469 - acc: 0.9000 - val_loss: 1.7221 - val_acc: 0.7061\n",
      "Epoch 600/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2479 - acc: 0.9008 - val_loss: 1.3715 - val_acc: 0.7209\n",
      "Epoch 601/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2460 - acc: 0.9001 - val_loss: 1.5081 - val_acc: 0.7263\n",
      "Epoch 602/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2456 - acc: 0.9013 - val_loss: 1.6289 - val_acc: 0.7211\n",
      "Epoch 603/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2448 - acc: 0.9014 - val_loss: 1.5748 - val_acc: 0.7096\n",
      "Epoch 604/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2486 - acc: 0.8998 - val_loss: 1.4909 - val_acc: 0.7211\n",
      "Epoch 605/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2432 - acc: 0.9016 - val_loss: 1.4505 - val_acc: 0.6979\n",
      "Epoch 606/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2441 - acc: 0.9023 - val_loss: 1.3900 - val_acc: 0.7289\n",
      "Epoch 607/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2435 - acc: 0.9019 - val_loss: 1.4823 - val_acc: 0.7168\n",
      "Epoch 608/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2470 - acc: 0.9002 - val_loss: 1.5594 - val_acc: 0.7312\n",
      "Epoch 609/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2422 - acc: 0.9011 - val_loss: 1.5695 - val_acc: 0.7211\n",
      "Epoch 610/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2449 - acc: 0.9018 - val_loss: 1.5435 - val_acc: 0.7148\n",
      "Epoch 611/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2430 - acc: 0.9013 - val_loss: 1.5596 - val_acc: 0.7113\n",
      "Epoch 612/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2414 - acc: 0.9031 - val_loss: 1.6244 - val_acc: 0.7014\n",
      "Epoch 613/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2413 - acc: 0.9025 - val_loss: 1.5664 - val_acc: 0.7237\n",
      "Epoch 614/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2458 - acc: 0.9001 - val_loss: 1.5644 - val_acc: 0.7136\n",
      "Epoch 615/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2432 - acc: 0.9017 - val_loss: 1.6619 - val_acc: 0.6994\n",
      "Epoch 616/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2459 - acc: 0.9012 - val_loss: 1.3144 - val_acc: 0.7218\n",
      "Epoch 617/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2485 - acc: 0.8988 - val_loss: 1.4244 - val_acc: 0.7251\n",
      "Epoch 618/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2447 - acc: 0.9008 - val_loss: 1.4257 - val_acc: 0.7249\n",
      "Epoch 619/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2437 - acc: 0.9020 - val_loss: 1.6345 - val_acc: 0.7077\n",
      "Epoch 620/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2416 - acc: 0.9020 - val_loss: 1.5233 - val_acc: 0.7229\n",
      "Epoch 621/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2402 - acc: 0.9027 - val_loss: 1.5074 - val_acc: 0.7237\n",
      "Epoch 622/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2468 - acc: 0.9005 - val_loss: 1.4839 - val_acc: 0.7103\n",
      "Epoch 623/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2402 - acc: 0.9027 - val_loss: 1.5938 - val_acc: 0.7054\n",
      "Epoch 624/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2446 - acc: 0.9015 - val_loss: 1.4724 - val_acc: 0.7235\n",
      "Epoch 625/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2413 - acc: 0.9020 - val_loss: 1.4701 - val_acc: 0.7216\n",
      "Epoch 626/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2406 - acc: 0.9036 - val_loss: 1.4834 - val_acc: 0.7235\n",
      "Epoch 627/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2448 - acc: 0.9008 - val_loss: 1.5346 - val_acc: 0.7185\n",
      "Epoch 628/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2450 - acc: 0.9013 - val_loss: 1.4491 - val_acc: 0.7255\n",
      "Epoch 629/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2420 - acc: 0.9023 - val_loss: 1.5077 - val_acc: 0.7182\n",
      "Epoch 630/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2431 - acc: 0.9017 - val_loss: 1.4307 - val_acc: 0.7256\n",
      "Epoch 631/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2448 - acc: 0.9003 - val_loss: 1.5191 - val_acc: 0.7186\n",
      "Epoch 632/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2399 - acc: 0.9027 - val_loss: 1.4790 - val_acc: 0.7137\n",
      "Epoch 633/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2440 - acc: 0.9013 - val_loss: 1.5901 - val_acc: 0.7123\n",
      "Epoch 634/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2417 - acc: 0.9032 - val_loss: 1.4903 - val_acc: 0.7264\n",
      "Epoch 635/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2436 - acc: 0.9016 - val_loss: 1.4303 - val_acc: 0.7216\n",
      "Epoch 636/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2409 - acc: 0.9028 - val_loss: 1.5115 - val_acc: 0.7196\n",
      "Epoch 637/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2420 - acc: 0.9017 - val_loss: 1.4407 - val_acc: 0.7177\n",
      "Epoch 638/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2395 - acc: 0.9043 - val_loss: 1.4333 - val_acc: 0.7211\n",
      "Epoch 639/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2398 - acc: 0.9037 - val_loss: 1.4799 - val_acc: 0.7215\n",
      "Epoch 640/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2413 - acc: 0.9024 - val_loss: 1.5163 - val_acc: 0.7196\n",
      "Epoch 641/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2416 - acc: 0.9026 - val_loss: 1.5075 - val_acc: 0.7244\n",
      "Epoch 642/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2385 - acc: 0.9027 - val_loss: 1.5825 - val_acc: 0.7185\n",
      "Epoch 643/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2416 - acc: 0.9023 - val_loss: 1.6841 - val_acc: 0.7180\n",
      "Epoch 644/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2432 - acc: 0.9019 - val_loss: 1.3538 - val_acc: 0.7264\n",
      "Epoch 645/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2408 - acc: 0.9030 - val_loss: 1.6395 - val_acc: 0.7132\n",
      "Epoch 646/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2436 - acc: 0.9008 - val_loss: 1.4889 - val_acc: 0.7169\n",
      "Epoch 647/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2384 - acc: 0.9042 - val_loss: 1.5357 - val_acc: 0.7120\n",
      "Epoch 648/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2409 - acc: 0.9036 - val_loss: 1.5812 - val_acc: 0.7116\n",
      "Epoch 649/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2419 - acc: 0.9025 - val_loss: 1.4752 - val_acc: 0.7253\n",
      "Epoch 650/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2407 - acc: 0.9023 - val_loss: 1.3780 - val_acc: 0.7244\n",
      "Epoch 651/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2394 - acc: 0.9033 - val_loss: 1.4462 - val_acc: 0.7271\n",
      "Epoch 652/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2390 - acc: 0.9036 - val_loss: 1.6122 - val_acc: 0.7190\n",
      "Epoch 653/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2425 - acc: 0.9018 - val_loss: 1.6869 - val_acc: 0.7137\n",
      "Epoch 654/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2440 - acc: 0.9010 - val_loss: 1.5575 - val_acc: 0.7228\n",
      "Epoch 655/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2376 - acc: 0.9040 - val_loss: 1.4412 - val_acc: 0.7330\n",
      "Epoch 656/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2436 - acc: 0.9012 - val_loss: 1.5485 - val_acc: 0.7157\n",
      "Epoch 657/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2400 - acc: 0.9030 - val_loss: 1.7102 - val_acc: 0.7132\n",
      "Epoch 658/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2361 - acc: 0.9039 - val_loss: 1.4219 - val_acc: 0.7311\n",
      "Epoch 659/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2405 - acc: 0.9036 - val_loss: 1.6223 - val_acc: 0.7107\n",
      "Epoch 660/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2367 - acc: 0.9041 - val_loss: 1.7070 - val_acc: 0.7190\n",
      "Epoch 661/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2367 - acc: 0.9043 - val_loss: 1.5307 - val_acc: 0.7234\n",
      "Epoch 662/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2386 - acc: 0.9034 - val_loss: 1.4621 - val_acc: 0.7277\n",
      "Epoch 663/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2380 - acc: 0.9035 - val_loss: 1.4786 - val_acc: 0.7275\n",
      "Epoch 664/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2379 - acc: 0.9037 - val_loss: 1.4513 - val_acc: 0.7200\n",
      "Epoch 665/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2377 - acc: 0.9040 - val_loss: 1.4943 - val_acc: 0.7163\n",
      "Epoch 666/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2367 - acc: 0.9050 - val_loss: 1.6424 - val_acc: 0.7151\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2389 - acc: 0.9020 - val_loss: 1.4810 - val_acc: 0.7232\n",
      "Epoch 668/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2397 - acc: 0.9035 - val_loss: 1.5449 - val_acc: 0.7200\n",
      "Epoch 669/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2407 - acc: 0.9026 - val_loss: 1.7302 - val_acc: 0.7153\n",
      "Epoch 670/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2367 - acc: 0.9038 - val_loss: 1.4318 - val_acc: 0.7175\n",
      "Epoch 671/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2389 - acc: 0.9037 - val_loss: 1.5438 - val_acc: 0.7182\n",
      "Epoch 672/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2385 - acc: 0.9043 - val_loss: 1.5315 - val_acc: 0.7238\n",
      "Epoch 673/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2391 - acc: 0.9040 - val_loss: 1.6219 - val_acc: 0.7107\n",
      "Epoch 674/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2356 - acc: 0.9053 - val_loss: 1.5090 - val_acc: 0.7095\n",
      "Epoch 675/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2369 - acc: 0.9051 - val_loss: 1.6251 - val_acc: 0.7104\n",
      "Epoch 676/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2413 - acc: 0.9033 - val_loss: 1.6413 - val_acc: 0.7128\n",
      "Epoch 677/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2338 - acc: 0.9052 - val_loss: 1.4593 - val_acc: 0.7261\n",
      "Epoch 678/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2330 - acc: 0.9059 - val_loss: 1.5100 - val_acc: 0.7230\n",
      "Epoch 679/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2363 - acc: 0.9036 - val_loss: 1.5061 - val_acc: 0.7180\n",
      "Epoch 680/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2372 - acc: 0.9046 - val_loss: 1.5267 - val_acc: 0.7232\n",
      "Epoch 681/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2376 - acc: 0.9050 - val_loss: 1.4788 - val_acc: 0.7264\n",
      "Epoch 682/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2353 - acc: 0.9036 - val_loss: 1.5170 - val_acc: 0.7202\n",
      "Epoch 683/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2387 - acc: 0.9033 - val_loss: 1.5650 - val_acc: 0.7250\n",
      "Epoch 684/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2404 - acc: 0.9027 - val_loss: 1.7684 - val_acc: 0.7034\n",
      "Epoch 685/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2366 - acc: 0.9042 - val_loss: 1.5726 - val_acc: 0.7193\n",
      "Epoch 686/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2378 - acc: 0.9034 - val_loss: 1.5737 - val_acc: 0.7170\n",
      "Epoch 687/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2376 - acc: 0.9047 - val_loss: 1.5401 - val_acc: 0.7199\n",
      "Epoch 688/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2363 - acc: 0.9048 - val_loss: 1.5473 - val_acc: 0.7161\n",
      "Epoch 689/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2351 - acc: 0.9050 - val_loss: 1.6130 - val_acc: 0.7173\n",
      "Epoch 690/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2358 - acc: 0.9047 - val_loss: 1.4192 - val_acc: 0.7313\n",
      "Epoch 691/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2352 - acc: 0.9047 - val_loss: 1.5494 - val_acc: 0.7223\n",
      "Epoch 692/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2370 - acc: 0.9048 - val_loss: 1.4055 - val_acc: 0.7271\n",
      "Epoch 693/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2381 - acc: 0.9038 - val_loss: 1.4602 - val_acc: 0.7242\n",
      "Epoch 694/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2399 - acc: 0.9036 - val_loss: 1.3824 - val_acc: 0.7241\n",
      "Epoch 695/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2346 - acc: 0.9045 - val_loss: 1.5479 - val_acc: 0.7154\n",
      "Epoch 696/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2378 - acc: 0.9034 - val_loss: 1.6881 - val_acc: 0.7094\n",
      "Epoch 697/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2381 - acc: 0.9037 - val_loss: 1.4073 - val_acc: 0.7316\n",
      "Epoch 698/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2353 - acc: 0.9049 - val_loss: 1.6970 - val_acc: 0.6938\n",
      "Epoch 699/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2344 - acc: 0.9052 - val_loss: 1.5227 - val_acc: 0.7267\n",
      "Epoch 700/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2359 - acc: 0.9041 - val_loss: 1.5035 - val_acc: 0.7269\n",
      "Epoch 701/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2329 - acc: 0.9062 - val_loss: 1.6070 - val_acc: 0.7111\n",
      "Epoch 702/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2341 - acc: 0.9062 - val_loss: 1.6421 - val_acc: 0.7127\n",
      "Epoch 703/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2326 - acc: 0.9058 - val_loss: 1.6251 - val_acc: 0.7189\n",
      "Epoch 704/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2320 - acc: 0.9068 - val_loss: 1.5124 - val_acc: 0.7175\n",
      "Epoch 705/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2347 - acc: 0.9059 - val_loss: 1.4385 - val_acc: 0.7208\n",
      "Epoch 706/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2359 - acc: 0.9044 - val_loss: 1.5464 - val_acc: 0.7180\n",
      "Epoch 707/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2337 - acc: 0.9059 - val_loss: 1.5584 - val_acc: 0.7183\n",
      "Epoch 708/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2357 - acc: 0.9056 - val_loss: 1.6087 - val_acc: 0.7111\n",
      "Epoch 709/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2373 - acc: 0.9042 - val_loss: 1.4749 - val_acc: 0.7256\n",
      "Epoch 710/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2349 - acc: 0.9055 - val_loss: 1.5087 - val_acc: 0.7245\n",
      "Epoch 711/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2332 - acc: 0.9057 - val_loss: 1.4895 - val_acc: 0.7237\n",
      "Epoch 712/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2385 - acc: 0.9041 - val_loss: 1.5479 - val_acc: 0.7170\n",
      "Epoch 713/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2348 - acc: 0.9048 - val_loss: 1.4997 - val_acc: 0.7218\n",
      "Epoch 714/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2345 - acc: 0.9056 - val_loss: 1.4300 - val_acc: 0.7216\n",
      "Epoch 715/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2368 - acc: 0.9048 - val_loss: 1.5866 - val_acc: 0.7276\n",
      "Epoch 716/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2364 - acc: 0.9042 - val_loss: 1.5030 - val_acc: 0.7048\n",
      "Epoch 717/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2339 - acc: 0.9052 - val_loss: 1.5131 - val_acc: 0.7258\n",
      "Epoch 718/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2343 - acc: 0.9063 - val_loss: 1.4826 - val_acc: 0.7195\n",
      "Epoch 719/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2328 - acc: 0.9055 - val_loss: 1.5929 - val_acc: 0.7225\n",
      "Epoch 720/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2363 - acc: 0.9049 - val_loss: 1.4585 - val_acc: 0.7169\n",
      "Epoch 721/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2356 - acc: 0.9055 - val_loss: 1.4863 - val_acc: 0.7229\n",
      "Epoch 722/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2368 - acc: 0.9035 - val_loss: 1.4542 - val_acc: 0.7133\n",
      "Epoch 723/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2309 - acc: 0.9071 - val_loss: 1.4288 - val_acc: 0.7320\n",
      "Epoch 724/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2320 - acc: 0.9055 - val_loss: 1.5459 - val_acc: 0.7159\n",
      "Epoch 725/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2358 - acc: 0.9053 - val_loss: 1.5916 - val_acc: 0.7146\n",
      "Epoch 726/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2354 - acc: 0.9051 - val_loss: 1.6060 - val_acc: 0.7175\n",
      "Epoch 727/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2339 - acc: 0.9045 - val_loss: 1.4468 - val_acc: 0.7201\n",
      "Epoch 728/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2323 - acc: 0.9054 - val_loss: 1.4480 - val_acc: 0.7266\n",
      "Epoch 729/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2328 - acc: 0.9066 - val_loss: 1.4654 - val_acc: 0.7264\n",
      "Epoch 730/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2346 - acc: 0.9061 - val_loss: 1.5762 - val_acc: 0.7149\n",
      "Epoch 731/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2319 - acc: 0.9067 - val_loss: 1.5922 - val_acc: 0.7060\n",
      "Epoch 732/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2310 - acc: 0.9072 - val_loss: 1.5101 - val_acc: 0.7237\n",
      "Epoch 733/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2329 - acc: 0.9064 - val_loss: 1.4830 - val_acc: 0.7263\n",
      "Epoch 734/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2336 - acc: 0.9055 - val_loss: 1.5227 - val_acc: 0.7273\n",
      "Epoch 735/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2333 - acc: 0.9064 - val_loss: 1.5531 - val_acc: 0.7168\n",
      "Epoch 736/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2312 - acc: 0.9062 - val_loss: 1.5063 - val_acc: 0.7223\n",
      "Epoch 737/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2315 - acc: 0.9064 - val_loss: 1.3724 - val_acc: 0.7348\n",
      "Epoch 738/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2322 - acc: 0.9066 - val_loss: 1.6597 - val_acc: 0.7238\n",
      "Epoch 739/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2347 - acc: 0.9053 - val_loss: 1.4310 - val_acc: 0.7286\n",
      "Epoch 740/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2257 - acc: 0.9086 - val_loss: 1.5174 - val_acc: 0.7206\n",
      "Epoch 741/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2309 - acc: 0.9067 - val_loss: 1.4895 - val_acc: 0.7224\n",
      "Epoch 742/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2305 - acc: 0.9055 - val_loss: 1.4784 - val_acc: 0.7358\n",
      "Epoch 743/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2317 - acc: 0.9070 - val_loss: 1.5358 - val_acc: 0.7301\n",
      "Epoch 744/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2302 - acc: 0.9071 - val_loss: 1.6025 - val_acc: 0.7152\n",
      "Epoch 745/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2330 - acc: 0.9052 - val_loss: 1.4310 - val_acc: 0.7272\n",
      "Epoch 746/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2306 - acc: 0.9075 - val_loss: 1.5829 - val_acc: 0.7151\n",
      "Epoch 747/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2326 - acc: 0.9071 - val_loss: 1.4830 - val_acc: 0.7261\n",
      "Epoch 748/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2317 - acc: 0.9064 - val_loss: 1.5699 - val_acc: 0.7174\n",
      "Epoch 749/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2321 - acc: 0.9062 - val_loss: 1.4281 - val_acc: 0.7282\n",
      "Epoch 750/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2285 - acc: 0.9073 - val_loss: 1.5084 - val_acc: 0.7190\n",
      "Epoch 751/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2271 - acc: 0.9089 - val_loss: 1.4270 - val_acc: 0.7201\n",
      "Epoch 752/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2327 - acc: 0.9059 - val_loss: 1.7305 - val_acc: 0.6999\n",
      "Epoch 753/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2294 - acc: 0.9074 - val_loss: 1.5907 - val_acc: 0.7150\n",
      "Epoch 754/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2299 - acc: 0.9081 - val_loss: 1.4926 - val_acc: 0.7025\n",
      "Epoch 755/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2312 - acc: 0.9070 - val_loss: 1.6050 - val_acc: 0.7204\n",
      "Epoch 756/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2279 - acc: 0.9083 - val_loss: 1.5514 - val_acc: 0.7139\n",
      "Epoch 757/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2303 - acc: 0.9073 - val_loss: 1.6313 - val_acc: 0.7134\n",
      "Epoch 758/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2292 - acc: 0.9066 - val_loss: 1.5976 - val_acc: 0.7205\n",
      "Epoch 759/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2298 - acc: 0.9069 - val_loss: 1.5916 - val_acc: 0.7210\n",
      "Epoch 760/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2314 - acc: 0.9067 - val_loss: 1.5659 - val_acc: 0.7309\n",
      "Epoch 761/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2288 - acc: 0.9079 - val_loss: 1.6238 - val_acc: 0.7196\n",
      "Epoch 762/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2286 - acc: 0.9072 - val_loss: 1.5108 - val_acc: 0.7313\n",
      "Epoch 763/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2291 - acc: 0.9075 - val_loss: 1.5855 - val_acc: 0.7054\n",
      "Epoch 764/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2277 - acc: 0.9089 - val_loss: 1.5867 - val_acc: 0.7283\n",
      "Epoch 765/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2337 - acc: 0.9062 - val_loss: 1.5305 - val_acc: 0.7293\n",
      "Epoch 766/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2278 - acc: 0.9084 - val_loss: 1.4597 - val_acc: 0.7302\n",
      "Epoch 767/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2297 - acc: 0.9077 - val_loss: 1.4406 - val_acc: 0.7361\n",
      "Epoch 768/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2330 - acc: 0.9063 - val_loss: 1.5309 - val_acc: 0.7206\n",
      "Epoch 769/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2296 - acc: 0.9058 - val_loss: 1.6603 - val_acc: 0.7135\n",
      "Epoch 770/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2282 - acc: 0.9085 - val_loss: 1.7009 - val_acc: 0.7020\n",
      "Epoch 771/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2309 - acc: 0.9075 - val_loss: 1.6917 - val_acc: 0.7206\n",
      "Epoch 772/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2284 - acc: 0.9073 - val_loss: 1.5356 - val_acc: 0.7158\n",
      "Epoch 773/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2317 - acc: 0.9063 - val_loss: 1.6148 - val_acc: 0.7192\n",
      "Epoch 774/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2279 - acc: 0.9081 - val_loss: 1.4838 - val_acc: 0.7228\n",
      "Epoch 775/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2251 - acc: 0.9106 - val_loss: 1.6989 - val_acc: 0.7106\n",
      "Epoch 776/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2238 - acc: 0.9095 - val_loss: 1.3993 - val_acc: 0.7281\n",
      "Epoch 777/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2318 - acc: 0.9073 - val_loss: 1.7875 - val_acc: 0.7013\n",
      "Epoch 778/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2292 - acc: 0.9082 - val_loss: 1.4674 - val_acc: 0.7233\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2304 - acc: 0.9074 - val_loss: 1.4957 - val_acc: 0.7272\n",
      "Epoch 780/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2290 - acc: 0.9077 - val_loss: 1.6161 - val_acc: 0.7215\n",
      "Epoch 781/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2274 - acc: 0.9074 - val_loss: 1.4453 - val_acc: 0.7277\n",
      "Epoch 782/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2331 - acc: 0.9062 - val_loss: 1.3930 - val_acc: 0.7287\n",
      "Epoch 783/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2309 - acc: 0.9068 - val_loss: 1.5106 - val_acc: 0.7332\n",
      "Epoch 784/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2255 - acc: 0.9086 - val_loss: 1.6307 - val_acc: 0.7196\n",
      "Epoch 785/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2284 - acc: 0.9073 - val_loss: 1.4013 - val_acc: 0.7318\n",
      "Epoch 786/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2281 - acc: 0.9079 - val_loss: 1.6449 - val_acc: 0.7197\n",
      "Epoch 787/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2273 - acc: 0.9081 - val_loss: 1.4469 - val_acc: 0.7348\n",
      "Epoch 788/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2278 - acc: 0.9082 - val_loss: 1.8591 - val_acc: 0.7025\n",
      "Epoch 789/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2291 - acc: 0.9067 - val_loss: 1.3958 - val_acc: 0.7369\n",
      "Epoch 790/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2252 - acc: 0.9098 - val_loss: 1.6616 - val_acc: 0.7211\n",
      "Epoch 791/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2313 - acc: 0.9058 - val_loss: 1.4971 - val_acc: 0.7331\n",
      "Epoch 792/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2281 - acc: 0.9079 - val_loss: 1.5163 - val_acc: 0.7297\n",
      "Epoch 793/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2287 - acc: 0.9081 - val_loss: 1.5556 - val_acc: 0.7216\n",
      "Epoch 794/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2256 - acc: 0.9090 - val_loss: 1.4450 - val_acc: 0.7244\n",
      "Epoch 795/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2271 - acc: 0.9090 - val_loss: 1.5185 - val_acc: 0.7139\n",
      "Epoch 796/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2273 - acc: 0.9087 - val_loss: 1.4313 - val_acc: 0.7271\n",
      "Epoch 797/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2315 - acc: 0.9073 - val_loss: 1.7813 - val_acc: 0.7016\n",
      "Epoch 798/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2306 - acc: 0.9064 - val_loss: 1.4280 - val_acc: 0.7313\n",
      "Epoch 799/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2263 - acc: 0.9086 - val_loss: 1.5304 - val_acc: 0.7101\n",
      "Epoch 800/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2273 - acc: 0.9082 - val_loss: 1.6725 - val_acc: 0.7158\n",
      "Epoch 801/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2270 - acc: 0.9091 - val_loss: 1.6201 - val_acc: 0.7103\n",
      "Epoch 802/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2252 - acc: 0.9097 - val_loss: 1.7042 - val_acc: 0.7126\n",
      "Epoch 803/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2255 - acc: 0.9094 - val_loss: 1.4981 - val_acc: 0.7253\n",
      "Epoch 804/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2281 - acc: 0.9074 - val_loss: 1.5205 - val_acc: 0.7356\n",
      "Epoch 805/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2277 - acc: 0.9074 - val_loss: 1.5431 - val_acc: 0.7273\n",
      "Epoch 806/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2276 - acc: 0.9079 - val_loss: 1.5447 - val_acc: 0.7187\n",
      "Epoch 807/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2284 - acc: 0.9083 - val_loss: 1.4650 - val_acc: 0.7354\n",
      "Epoch 808/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2282 - acc: 0.9076 - val_loss: 1.4559 - val_acc: 0.7274\n",
      "Epoch 809/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2299 - acc: 0.9066 - val_loss: 1.6087 - val_acc: 0.7216\n",
      "Epoch 810/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2242 - acc: 0.9099 - val_loss: 1.4312 - val_acc: 0.7359\n",
      "Epoch 811/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2278 - acc: 0.9075 - val_loss: 1.5457 - val_acc: 0.7210\n",
      "Epoch 812/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2266 - acc: 0.9081 - val_loss: 1.5845 - val_acc: 0.7297\n",
      "Epoch 813/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2306 - acc: 0.9078 - val_loss: 1.5752 - val_acc: 0.7212\n",
      "Epoch 814/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2269 - acc: 0.9092 - val_loss: 1.5734 - val_acc: 0.7223\n",
      "Epoch 815/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2278 - acc: 0.9082 - val_loss: 1.5923 - val_acc: 0.7199\n",
      "Epoch 816/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2259 - acc: 0.9081 - val_loss: 1.5790 - val_acc: 0.7226\n",
      "Epoch 817/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2251 - acc: 0.9089 - val_loss: 1.5517 - val_acc: 0.7265\n",
      "Epoch 818/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2263 - acc: 0.9087 - val_loss: 1.5597 - val_acc: 0.7266\n",
      "Epoch 819/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2242 - acc: 0.9092 - val_loss: 1.6374 - val_acc: 0.7159\n",
      "Epoch 820/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2261 - acc: 0.9091 - val_loss: 1.4463 - val_acc: 0.7320\n",
      "Epoch 821/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2239 - acc: 0.9097 - val_loss: 1.4957 - val_acc: 0.7289\n",
      "Epoch 822/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2244 - acc: 0.9094 - val_loss: 1.5591 - val_acc: 0.7154\n",
      "Epoch 823/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2250 - acc: 0.9090 - val_loss: 1.6283 - val_acc: 0.7151\n",
      "Epoch 824/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2279 - acc: 0.9084 - val_loss: 1.6928 - val_acc: 0.7212\n",
      "Epoch 825/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2259 - acc: 0.9086 - val_loss: 1.6553 - val_acc: 0.7141\n",
      "Epoch 826/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2258 - acc: 0.9098 - val_loss: 1.7948 - val_acc: 0.7089\n",
      "Epoch 827/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2252 - acc: 0.9092 - val_loss: 1.5296 - val_acc: 0.7218\n",
      "Epoch 828/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2247 - acc: 0.9093 - val_loss: 1.5111 - val_acc: 0.7271\n",
      "Epoch 829/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2274 - acc: 0.9079 - val_loss: 1.6222 - val_acc: 0.7249\n",
      "Epoch 830/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2246 - acc: 0.9091 - val_loss: 1.5644 - val_acc: 0.7218\n",
      "Epoch 831/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2233 - acc: 0.9100 - val_loss: 1.5551 - val_acc: 0.7251\n",
      "Epoch 832/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2261 - acc: 0.9086 - val_loss: 1.4144 - val_acc: 0.7256\n",
      "Epoch 833/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2252 - acc: 0.9094 - val_loss: 1.5340 - val_acc: 0.7315\n",
      "Epoch 834/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2229 - acc: 0.9096 - val_loss: 1.6744 - val_acc: 0.7157\n",
      "Epoch 835/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2286 - acc: 0.9073 - val_loss: 1.5620 - val_acc: 0.7139\n",
      "Epoch 836/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2236 - acc: 0.9102 - val_loss: 1.5045 - val_acc: 0.7242\n",
      "Epoch 837/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2250 - acc: 0.9089 - val_loss: 1.5538 - val_acc: 0.7249\n",
      "Epoch 838/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2257 - acc: 0.9102 - val_loss: 1.5688 - val_acc: 0.7235\n",
      "Epoch 839/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2228 - acc: 0.9094 - val_loss: 1.6298 - val_acc: 0.7194\n",
      "Epoch 840/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2253 - acc: 0.9105 - val_loss: 1.4250 - val_acc: 0.7303\n",
      "Epoch 841/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2219 - acc: 0.9099 - val_loss: 1.4443 - val_acc: 0.7271\n",
      "Epoch 842/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2229 - acc: 0.9110 - val_loss: 1.4574 - val_acc: 0.7344\n",
      "Epoch 843/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2239 - acc: 0.9094 - val_loss: 1.5392 - val_acc: 0.7149\n",
      "Epoch 844/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2266 - acc: 0.9094 - val_loss: 1.7015 - val_acc: 0.7132\n",
      "Epoch 845/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2239 - acc: 0.9092 - val_loss: 1.4967 - val_acc: 0.7236\n",
      "Epoch 846/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2231 - acc: 0.9106 - val_loss: 1.6937 - val_acc: 0.7183\n",
      "Epoch 847/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2260 - acc: 0.9089 - val_loss: 1.6287 - val_acc: 0.7258\n",
      "Epoch 848/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2249 - acc: 0.9100 - val_loss: 1.5798 - val_acc: 0.7188\n",
      "Epoch 849/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2256 - acc: 0.9099 - val_loss: 1.6370 - val_acc: 0.7228\n",
      "Epoch 850/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2252 - acc: 0.9096 - val_loss: 1.7044 - val_acc: 0.7177\n",
      "Epoch 851/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2220 - acc: 0.9110 - val_loss: 1.5355 - val_acc: 0.7241\n",
      "Epoch 852/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2212 - acc: 0.9105 - val_loss: 1.6350 - val_acc: 0.7265\n",
      "Epoch 853/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2224 - acc: 0.9096 - val_loss: 1.5272 - val_acc: 0.7283\n",
      "Epoch 854/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2256 - acc: 0.9091 - val_loss: 1.5259 - val_acc: 0.7106\n",
      "Epoch 855/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2223 - acc: 0.9110 - val_loss: 1.7443 - val_acc: 0.7124\n",
      "Epoch 856/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2257 - acc: 0.9095 - val_loss: 1.5767 - val_acc: 0.7192\n",
      "Epoch 857/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2238 - acc: 0.9098 - val_loss: 1.7598 - val_acc: 0.7071\n",
      "Epoch 858/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2228 - acc: 0.9103 - val_loss: 1.5863 - val_acc: 0.7192\n",
      "Epoch 859/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2217 - acc: 0.9101 - val_loss: 1.5034 - val_acc: 0.7282\n",
      "Epoch 860/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2234 - acc: 0.9103 - val_loss: 1.6226 - val_acc: 0.7247\n",
      "Epoch 861/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2243 - acc: 0.9088 - val_loss: 1.5593 - val_acc: 0.7237\n",
      "Epoch 862/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2238 - acc: 0.9109 - val_loss: 1.5500 - val_acc: 0.7222\n",
      "Epoch 863/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2206 - acc: 0.9118 - val_loss: 1.4888 - val_acc: 0.7343\n",
      "Epoch 864/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2248 - acc: 0.9090 - val_loss: 1.6047 - val_acc: 0.7237\n",
      "Epoch 865/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2218 - acc: 0.9106 - val_loss: 1.6794 - val_acc: 0.7162\n",
      "Epoch 866/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2244 - acc: 0.9100 - val_loss: 1.7911 - val_acc: 0.7117\n",
      "Epoch 867/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2213 - acc: 0.9102 - val_loss: 1.6465 - val_acc: 0.7196\n",
      "Epoch 868/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2235 - acc: 0.9102 - val_loss: 1.4571 - val_acc: 0.7269\n",
      "Epoch 869/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2237 - acc: 0.9098 - val_loss: 1.5289 - val_acc: 0.7327\n",
      "Epoch 870/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2235 - acc: 0.9092 - val_loss: 1.4493 - val_acc: 0.7317\n",
      "Epoch 871/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2185 - acc: 0.9117 - val_loss: 1.6700 - val_acc: 0.7096\n",
      "Epoch 872/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2210 - acc: 0.9108 - val_loss: 1.5387 - val_acc: 0.7295\n",
      "Epoch 873/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2200 - acc: 0.9121 - val_loss: 1.5921 - val_acc: 0.7239\n",
      "Epoch 874/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2254 - acc: 0.9099 - val_loss: 1.6378 - val_acc: 0.7090\n",
      "Epoch 875/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2213 - acc: 0.9109 - val_loss: 1.5245 - val_acc: 0.7311\n",
      "Epoch 876/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2199 - acc: 0.9120 - val_loss: 1.5619 - val_acc: 0.7170\n",
      "Epoch 877/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2221 - acc: 0.9105 - val_loss: 1.5616 - val_acc: 0.7281\n",
      "Epoch 878/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2211 - acc: 0.9116 - val_loss: 1.5038 - val_acc: 0.7289\n",
      "Epoch 879/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2233 - acc: 0.9093 - val_loss: 1.7883 - val_acc: 0.6963\n",
      "Epoch 880/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2207 - acc: 0.9117 - val_loss: 1.6935 - val_acc: 0.7057\n",
      "Epoch 881/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2231 - acc: 0.9098 - val_loss: 1.6424 - val_acc: 0.7252\n",
      "Epoch 882/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2231 - acc: 0.9097 - val_loss: 1.5230 - val_acc: 0.7239\n",
      "Epoch 883/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2249 - acc: 0.9090 - val_loss: 1.5908 - val_acc: 0.7263\n",
      "Epoch 884/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2211 - acc: 0.9116 - val_loss: 1.5203 - val_acc: 0.7250\n",
      "Epoch 885/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2235 - acc: 0.9110 - val_loss: 1.6600 - val_acc: 0.6982\n",
      "Epoch 886/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2213 - acc: 0.9108 - val_loss: 1.6258 - val_acc: 0.6975\n",
      "Epoch 887/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2238 - acc: 0.9089 - val_loss: 1.3776 - val_acc: 0.7275\n",
      "Epoch 888/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2233 - acc: 0.9100 - val_loss: 1.4377 - val_acc: 0.7320\n",
      "Epoch 889/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2219 - acc: 0.9111 - val_loss: 1.7044 - val_acc: 0.7189\n",
      "Epoch 890/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2207 - acc: 0.9117 - val_loss: 1.6088 - val_acc: 0.7320\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2208 - acc: 0.9108 - val_loss: 1.5940 - val_acc: 0.7220\n",
      "Epoch 892/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2201 - acc: 0.9106 - val_loss: 1.5500 - val_acc: 0.7261\n",
      "Epoch 893/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2210 - acc: 0.9106 - val_loss: 1.6707 - val_acc: 0.7268\n",
      "Epoch 894/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2199 - acc: 0.9116 - val_loss: 1.6764 - val_acc: 0.7125\n",
      "Epoch 895/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2211 - acc: 0.9114 - val_loss: 1.5760 - val_acc: 0.7270\n",
      "Epoch 896/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2181 - acc: 0.9125 - val_loss: 1.7252 - val_acc: 0.7142\n",
      "Epoch 897/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2213 - acc: 0.9101 - val_loss: 1.4344 - val_acc: 0.7307\n",
      "Epoch 898/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2191 - acc: 0.9114 - val_loss: 1.5720 - val_acc: 0.7293\n",
      "Epoch 899/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2179 - acc: 0.9120 - val_loss: 1.5502 - val_acc: 0.7137\n",
      "Epoch 900/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2199 - acc: 0.9116 - val_loss: 1.7327 - val_acc: 0.7149\n",
      "Epoch 901/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2178 - acc: 0.9118 - val_loss: 1.6711 - val_acc: 0.7164\n",
      "Epoch 902/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2185 - acc: 0.9126 - val_loss: 1.5401 - val_acc: 0.7285\n",
      "Epoch 903/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2201 - acc: 0.9118 - val_loss: 1.5382 - val_acc: 0.7213\n",
      "Epoch 904/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2225 - acc: 0.9107 - val_loss: 1.4568 - val_acc: 0.7300\n",
      "Epoch 905/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2232 - acc: 0.9094 - val_loss: 1.6115 - val_acc: 0.7121\n",
      "Epoch 906/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2212 - acc: 0.9108 - val_loss: 1.7405 - val_acc: 0.7180\n",
      "Epoch 907/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2209 - acc: 0.9107 - val_loss: 1.5205 - val_acc: 0.7253\n",
      "Epoch 908/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2213 - acc: 0.9108 - val_loss: 1.7322 - val_acc: 0.7104\n",
      "Epoch 909/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2178 - acc: 0.9122 - val_loss: 1.6836 - val_acc: 0.7184\n",
      "Epoch 910/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2218 - acc: 0.9104 - val_loss: 1.4253 - val_acc: 0.7351\n",
      "Epoch 911/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2187 - acc: 0.9123 - val_loss: 1.6006 - val_acc: 0.7239\n",
      "Epoch 912/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2198 - acc: 0.9115 - val_loss: 1.5730 - val_acc: 0.7201\n",
      "Epoch 913/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2193 - acc: 0.9116 - val_loss: 1.6384 - val_acc: 0.7144\n",
      "Epoch 914/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2193 - acc: 0.9120 - val_loss: 1.5042 - val_acc: 0.7270\n",
      "Epoch 915/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2177 - acc: 0.9118 - val_loss: 1.6675 - val_acc: 0.7261\n",
      "Epoch 916/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2182 - acc: 0.9121 - val_loss: 2.0232 - val_acc: 0.6970\n",
      "Epoch 917/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2229 - acc: 0.9098 - val_loss: 1.6281 - val_acc: 0.7253\n",
      "Epoch 918/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2181 - acc: 0.9126 - val_loss: 1.6512 - val_acc: 0.7234\n",
      "Epoch 919/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2175 - acc: 0.9118 - val_loss: 1.6697 - val_acc: 0.7168\n",
      "Epoch 920/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2203 - acc: 0.9116 - val_loss: 1.4134 - val_acc: 0.7313\n",
      "Epoch 921/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2224 - acc: 0.9100 - val_loss: 1.5612 - val_acc: 0.7332\n",
      "Epoch 922/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2207 - acc: 0.9112 - val_loss: 1.6755 - val_acc: 0.7076\n",
      "Epoch 923/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2203 - acc: 0.9115 - val_loss: 1.6686 - val_acc: 0.7188\n",
      "Epoch 924/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2202 - acc: 0.9107 - val_loss: 1.4932 - val_acc: 0.7275\n",
      "Epoch 925/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2195 - acc: 0.9105 - val_loss: 1.6893 - val_acc: 0.7055\n",
      "Epoch 926/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2180 - acc: 0.9118 - val_loss: 1.5991 - val_acc: 0.7261\n",
      "Epoch 927/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2193 - acc: 0.9125 - val_loss: 1.5965 - val_acc: 0.7176\n",
      "Epoch 928/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2178 - acc: 0.9117 - val_loss: 1.7499 - val_acc: 0.7103\n",
      "Epoch 929/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2203 - acc: 0.9117 - val_loss: 1.5152 - val_acc: 0.7265\n",
      "Epoch 930/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2180 - acc: 0.9122 - val_loss: 1.7537 - val_acc: 0.7142\n",
      "Epoch 931/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2184 - acc: 0.9121 - val_loss: 1.5334 - val_acc: 0.7253\n",
      "Epoch 932/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2197 - acc: 0.9119 - val_loss: 1.5073 - val_acc: 0.7244\n",
      "Epoch 933/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2169 - acc: 0.9127 - val_loss: 1.6454 - val_acc: 0.7182\n",
      "Epoch 934/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2141 - acc: 0.9141 - val_loss: 1.5948 - val_acc: 0.7315\n",
      "Epoch 935/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2174 - acc: 0.9132 - val_loss: 1.3808 - val_acc: 0.7308\n",
      "Epoch 936/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2180 - acc: 0.9122 - val_loss: 1.6187 - val_acc: 0.7215\n",
      "Epoch 937/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2142 - acc: 0.9147 - val_loss: 1.4970 - val_acc: 0.7349\n",
      "Epoch 938/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2150 - acc: 0.9139 - val_loss: 1.7879 - val_acc: 0.7156\n",
      "Epoch 939/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2198 - acc: 0.9128 - val_loss: 1.6254 - val_acc: 0.7159\n",
      "Epoch 940/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2173 - acc: 0.9123 - val_loss: 1.6238 - val_acc: 0.7233\n",
      "Epoch 941/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2163 - acc: 0.9136 - val_loss: 1.6632 - val_acc: 0.7197\n",
      "Epoch 942/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2169 - acc: 0.9131 - val_loss: 1.5130 - val_acc: 0.7291\n",
      "Epoch 943/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2185 - acc: 0.9123 - val_loss: 1.6605 - val_acc: 0.7246\n",
      "Epoch 944/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2175 - acc: 0.9115 - val_loss: 1.6884 - val_acc: 0.7173\n",
      "Epoch 945/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2161 - acc: 0.9129 - val_loss: 1.5582 - val_acc: 0.7286\n",
      "Epoch 946/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2177 - acc: 0.9116 - val_loss: 1.6572 - val_acc: 0.7221\n",
      "Epoch 947/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2180 - acc: 0.9126 - val_loss: 1.5668 - val_acc: 0.7203\n",
      "Epoch 948/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2132 - acc: 0.9139 - val_loss: 1.6050 - val_acc: 0.7185\n",
      "Epoch 949/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2186 - acc: 0.9121 - val_loss: 1.4864 - val_acc: 0.7288\n",
      "Epoch 950/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2159 - acc: 0.9124 - val_loss: 1.6091 - val_acc: 0.7194\n",
      "Epoch 951/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2211 - acc: 0.9111 - val_loss: 1.4993 - val_acc: 0.7281\n",
      "Epoch 952/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2160 - acc: 0.9131 - val_loss: 1.3774 - val_acc: 0.7276\n",
      "Epoch 953/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2165 - acc: 0.9126 - val_loss: 1.5255 - val_acc: 0.7311\n",
      "Epoch 954/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2178 - acc: 0.9122 - val_loss: 1.7418 - val_acc: 0.7115\n",
      "Epoch 955/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2166 - acc: 0.9132 - val_loss: 1.4976 - val_acc: 0.7308\n",
      "Epoch 956/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2145 - acc: 0.9136 - val_loss: 1.4875 - val_acc: 0.7262\n",
      "Epoch 957/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2192 - acc: 0.9125 - val_loss: 1.7106 - val_acc: 0.7023\n",
      "Epoch 958/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2123 - acc: 0.9146 - val_loss: 1.5648 - val_acc: 0.7320\n",
      "Epoch 959/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2167 - acc: 0.9128 - val_loss: 1.4886 - val_acc: 0.7242\n",
      "Epoch 960/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2182 - acc: 0.9122 - val_loss: 1.5547 - val_acc: 0.7224\n",
      "Epoch 961/1000\n",
      "113600/113600 [==============================] - 1934s 17ms/sample - loss: 0.2184 - acc: 0.9127 - val_loss: 1.7318 - val_acc: 0.7157\n",
      "Epoch 962/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2142 - acc: 0.9129 - val_loss: 1.5467 - val_acc: 0.7317\n",
      "Epoch 963/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2143 - acc: 0.9143 - val_loss: 1.7162 - val_acc: 0.7193\n",
      "Epoch 964/1000\n",
      "113600/113600 [==============================] - 6s 57us/sample - loss: 0.2163 - acc: 0.9133 - val_loss: 1.5997 - val_acc: 0.7250\n",
      "Epoch 965/1000\n",
      "113600/113600 [==============================] - 11s 98us/sample - loss: 0.2175 - acc: 0.9131 - val_loss: 1.5210 - val_acc: 0.7316\n",
      "Epoch 966/1000\n",
      "113600/113600 [==============================] - 11s 95us/sample - loss: 0.2141 - acc: 0.9129 - val_loss: 1.5625 - val_acc: 0.7311\n",
      "Epoch 967/1000\n",
      "113600/113600 [==============================] - 11s 94us/sample - loss: 0.2171 - acc: 0.9136 - val_loss: 1.6279 - val_acc: 0.7342\n",
      "Epoch 968/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.2169 - acc: 0.9130 - val_loss: 1.4638 - val_acc: 0.7289\n",
      "Epoch 969/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.2173 - acc: 0.9124 - val_loss: 1.6516 - val_acc: 0.7190\n",
      "Epoch 970/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.2190 - acc: 0.9120 - val_loss: 1.6023 - val_acc: 0.7230\n",
      "Epoch 971/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.2133 - acc: 0.9139 - val_loss: 1.5493 - val_acc: 0.7335\n",
      "Epoch 972/1000\n",
      "113600/113600 [==============================] - 2237s 20ms/sample - loss: 0.2144 - acc: 0.9133 - val_loss: 1.6236 - val_acc: 0.7251\n",
      "Epoch 973/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2133 - acc: 0.9138 - val_loss: 1.7844 - val_acc: 0.7185\n",
      "Epoch 974/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2127 - acc: 0.9137 - val_loss: 1.7095 - val_acc: 0.7190\n",
      "Epoch 975/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2160 - acc: 0.9130 - val_loss: 1.5496 - val_acc: 0.7323\n",
      "Epoch 976/1000\n",
      "113600/113600 [==============================] - 7s 63us/sample - loss: 0.2140 - acc: 0.9130 - val_loss: 1.7598 - val_acc: 0.7185\n",
      "Epoch 977/1000\n",
      "113600/113600 [==============================] - 10s 90us/sample - loss: 0.2157 - acc: 0.9133 - val_loss: 1.4823 - val_acc: 0.7370\n",
      "Epoch 978/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2146 - acc: 0.9138 - val_loss: 1.5235 - val_acc: 0.7350\n",
      "Epoch 979/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.2142 - acc: 0.9137 - val_loss: 1.6352 - val_acc: 0.7254\n",
      "Epoch 980/1000\n",
      "113600/113600 [==============================] - 1965s 17ms/sample - loss: 0.2166 - acc: 0.9129 - val_loss: 1.5701 - val_acc: 0.7271\n",
      "Epoch 981/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2142 - acc: 0.9143 - val_loss: 1.5953 - val_acc: 0.7185\n",
      "Epoch 982/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2163 - acc: 0.9134 - val_loss: 1.8274 - val_acc: 0.7070\n",
      "Epoch 983/1000\n",
      "113600/113600 [==============================] - 6s 51us/sample - loss: 0.2134 - acc: 0.9146 - val_loss: 1.6241 - val_acc: 0.7159\n",
      "Epoch 984/1000\n",
      "113600/113600 [==============================] - 10s 90us/sample - loss: 0.2131 - acc: 0.9149 - val_loss: 1.5233 - val_acc: 0.7304\n",
      "Epoch 985/1000\n",
      "113600/113600 [==============================] - 10s 90us/sample - loss: 0.2145 - acc: 0.9134 - val_loss: 1.5213 - val_acc: 0.7282\n",
      "Epoch 986/1000\n",
      "113600/113600 [==============================] - 10s 90us/sample - loss: 0.2182 - acc: 0.9130 - val_loss: 1.6440 - val_acc: 0.7204\n",
      "Epoch 987/1000\n",
      "113600/113600 [==============================] - 1913s 17ms/sample - loss: 0.2145 - acc: 0.9132 - val_loss: 1.5369 - val_acc: 0.7338\n",
      "Epoch 988/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.2175 - acc: 0.9117 - val_loss: 1.6209 - val_acc: 0.7295\n",
      "Epoch 989/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.2179 - acc: 0.9115 - val_loss: 1.6862 - val_acc: 0.7175\n",
      "Epoch 990/1000\n",
      "113600/113600 [==============================] - 4s 36us/sample - loss: 0.2185 - acc: 0.9125 - val_loss: 1.4408 - val_acc: 0.7286\n",
      "Epoch 991/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2146 - acc: 0.9140 - val_loss: 1.8100 - val_acc: 0.7118\n",
      "Epoch 992/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2160 - acc: 0.9127 - val_loss: 1.6683 - val_acc: 0.7179\n",
      "Epoch 993/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2142 - acc: 0.9136 - val_loss: 1.9427 - val_acc: 0.7092\n",
      "Epoch 994/1000\n",
      "113600/113600 [==============================] - 1874s 16ms/sample - loss: 0.2133 - acc: 0.9155 - val_loss: 1.6829 - val_acc: 0.7194\n",
      "Epoch 995/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2149 - acc: 0.9133 - val_loss: 1.5232 - val_acc: 0.7349\n",
      "Epoch 996/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2174 - acc: 0.9121 - val_loss: 1.4993 - val_acc: 0.7275\n",
      "Epoch 997/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2122 - acc: 0.9142 - val_loss: 1.7228 - val_acc: 0.7126\n",
      "Epoch 998/1000\n",
      "113600/113600 [==============================] - 11s 95us/sample - loss: 0.2144 - acc: 0.9136 - val_loss: 1.4769 - val_acc: 0.7271\n",
      "Epoch 999/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2162 - acc: 0.9128 - val_loss: 1.4765 - val_acc: 0.7279\n",
      "Epoch 1000/1000\n",
      "113600/113600 [==============================] - 11s 97us/sample - loss: 0.2124 - acc: 0.9147 - val_loss: 1.6838 - val_acc: 0.7161\n",
      "14200/14200 [==============================] - 2s 134us/sample - loss: 1.6838 - acc: 0.7161\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/1000\n",
      "113600/113600 [==============================] - 1198s 11ms/sample - loss: 1.2133 - acc: 0.4957 - val_loss: 1.1466 - val_acc: 0.5285\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.9942 - acc: 0.5917 - val_loss: 1.1225 - val_acc: 0.5327\n",
      "Epoch 3/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.9155 - acc: 0.6278 - val_loss: 1.2547 - val_acc: 0.4920\n",
      "Epoch 4/1000\n",
      "113600/113600 [==============================] - 8s 69us/sample - loss: 0.8478 - acc: 0.6615 - val_loss: 2.2771 - val_acc: 0.4155\n",
      "Epoch 5/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.7992 - acc: 0.6844 - val_loss: 2.0627 - val_acc: 0.4383\n",
      "Epoch 6/1000\n",
      "113600/113600 [==============================] - 11s 92us/sample - loss: 0.7490 - acc: 0.7062 - val_loss: 1.0996 - val_acc: 0.6010\n",
      "Epoch 7/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.7064 - acc: 0.7267 - val_loss: 1.2475 - val_acc: 0.5820\n",
      "Epoch 8/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.6689 - acc: 0.7433 - val_loss: 1.2421 - val_acc: 0.5730\n",
      "Epoch 9/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.6355 - acc: 0.7552 - val_loss: 1.4899 - val_acc: 0.5469\n",
      "Epoch 10/1000\n",
      "113600/113600 [==============================] - 2001s 18ms/sample - loss: 0.6035 - acc: 0.7691 - val_loss: 2.1555 - val_acc: 0.5296\n",
      "Epoch 11/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.5767 - acc: 0.7796 - val_loss: 1.4770 - val_acc: 0.5705\n",
      "Epoch 12/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.5517 - acc: 0.7884 - val_loss: 1.4276 - val_acc: 0.6090\n",
      "Epoch 13/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.5316 - acc: 0.7974 - val_loss: 1.4083 - val_acc: 0.5828\n",
      "Epoch 14/1000\n",
      "113600/113600 [==============================] - 11s 95us/sample - loss: 0.5111 - acc: 0.8055 - val_loss: 1.1497 - val_acc: 0.6382\n",
      "Epoch 15/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.4929 - acc: 0.8128 - val_loss: 1.6283 - val_acc: 0.5991\n",
      "Epoch 16/1000\n",
      "113600/113600 [==============================] - 11s 98us/sample - loss: 0.4780 - acc: 0.8173 - val_loss: 1.1696 - val_acc: 0.6347\n",
      "Epoch 17/1000\n",
      "113600/113600 [==============================] - 1952s 17ms/sample - loss: 0.4642 - acc: 0.8236 - val_loss: 1.5904 - val_acc: 0.5859\n",
      "Epoch 18/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4535 - acc: 0.8285 - val_loss: 1.8280 - val_acc: 0.5500\n",
      "Epoch 19/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.4446 - acc: 0.8315 - val_loss: 1.5290 - val_acc: 0.6071\n",
      "Epoch 20/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4323 - acc: 0.8361 - val_loss: 1.2000 - val_acc: 0.6337\n",
      "Epoch 21/1000\n",
      "113600/113600 [==============================] - 9s 79us/sample - loss: 0.4189 - acc: 0.8414 - val_loss: 1.2434 - val_acc: 0.6494\n",
      "Epoch 22/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.4083 - acc: 0.8453 - val_loss: 1.4291 - val_acc: 0.6408\n",
      "Epoch 23/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3994 - acc: 0.8489 - val_loss: 1.5964 - val_acc: 0.6354\n",
      "Epoch 24/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3927 - acc: 0.8516 - val_loss: 1.6487 - val_acc: 0.6164\n",
      "Epoch 25/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3873 - acc: 0.8525 - val_loss: 1.9226 - val_acc: 0.5725\n",
      "Epoch 26/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3787 - acc: 0.8559 - val_loss: 1.3950 - val_acc: 0.6606\n",
      "Epoch 27/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3711 - acc: 0.8590 - val_loss: 1.8172 - val_acc: 0.6050\n",
      "Epoch 28/1000\n",
      "113600/113600 [==============================] - 2201s 19ms/sample - loss: 0.3648 - acc: 0.8616 - val_loss: 1.5070 - val_acc: 0.6502\n",
      "Epoch 29/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.3579 - acc: 0.8650 - val_loss: 1.7553 - val_acc: 0.5946\n",
      "Epoch 30/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3519 - acc: 0.8671 - val_loss: 1.5570 - val_acc: 0.6322\n",
      "Epoch 31/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3486 - acc: 0.8685 - val_loss: 1.0176 - val_acc: 0.7090\n",
      "Epoch 32/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3561 - acc: 0.8653 - val_loss: 1.1611 - val_acc: 0.6763\n",
      "Epoch 33/1000\n",
      "113600/113600 [==============================] - 11s 94us/sample - loss: 0.3403 - acc: 0.8710 - val_loss: 1.1721 - val_acc: 0.6759\n",
      "Epoch 34/1000\n",
      "113600/113600 [==============================] - 11s 97us/sample - loss: 0.3402 - acc: 0.8717 - val_loss: 1.2882 - val_acc: 0.6890\n",
      "Epoch 35/1000\n",
      "113600/113600 [==============================] - 1823s 16ms/sample - loss: 0.3325 - acc: 0.8734 - val_loss: 1.3518 - val_acc: 0.6780\n",
      "Epoch 36/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3250 - acc: 0.8768 - val_loss: 1.5216 - val_acc: 0.6630\n",
      "Epoch 37/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.3232 - acc: 0.8783 - val_loss: 1.8906 - val_acc: 0.5935\n",
      "Epoch 38/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3218 - acc: 0.8783 - val_loss: 2.1463 - val_acc: 0.6475\n",
      "Epoch 39/1000\n",
      "113600/113600 [==============================] - 11s 95us/sample - loss: 0.3162 - acc: 0.8809 - val_loss: 1.4174 - val_acc: 0.6711\n",
      "Epoch 40/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3109 - acc: 0.8824 - val_loss: 1.4270 - val_acc: 0.6695\n",
      "Epoch 41/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.3118 - acc: 0.8829 - val_loss: 1.7198 - val_acc: 0.6425\n",
      "Epoch 42/1000\n",
      "113600/113600 [==============================] - 2130s 19ms/sample - loss: 0.3083 - acc: 0.8846 - val_loss: 1.7028 - val_acc: 0.6450\n",
      "Epoch 43/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3052 - acc: 0.8846 - val_loss: 1.3831 - val_acc: 0.6751\n",
      "Epoch 44/1000\n",
      "113600/113600 [==============================] - 3s 24us/sample - loss: 0.2998 - acc: 0.8873 - val_loss: 1.3143 - val_acc: 0.6972\n",
      "Epoch 45/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2989 - acc: 0.8881 - val_loss: 1.7238 - val_acc: 0.6194\n",
      "Epoch 46/1000\n",
      "113600/113600 [==============================] - 10s 91us/sample - loss: 0.2954 - acc: 0.8890 - val_loss: 1.3874 - val_acc: 0.6846\n",
      "Epoch 47/1000\n",
      "113600/113600 [==============================] - 11s 92us/sample - loss: 0.2937 - acc: 0.8903 - val_loss: 1.4391 - val_acc: 0.6715\n",
      "Epoch 48/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.2899 - acc: 0.8916 - val_loss: 1.3230 - val_acc: 0.6802\n",
      "Epoch 49/1000\n",
      "113600/113600 [==============================] - 2191s 19ms/sample - loss: 0.2869 - acc: 0.8922 - val_loss: 1.2229 - val_acc: 0.6967\n",
      "Epoch 50/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2828 - acc: 0.8936 - val_loss: 1.5052 - val_acc: 0.6699\n",
      "Epoch 51/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2837 - acc: 0.8935 - val_loss: 1.2703 - val_acc: 0.6921\n",
      "Epoch 52/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2818 - acc: 0.8947 - val_loss: 1.3651 - val_acc: 0.6901\n",
      "Epoch 53/1000\n",
      "113600/113600 [==============================] - 11s 94us/sample - loss: 0.2811 - acc: 0.8941 - val_loss: 1.5212 - val_acc: 0.6722\n",
      "Epoch 54/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.2771 - acc: 0.8963 - val_loss: 2.0352 - val_acc: 0.6020\n",
      "Epoch 55/1000\n",
      "113600/113600 [==============================] - 11s 93us/sample - loss: 0.2756 - acc: 0.8957 - val_loss: 1.6745 - val_acc: 0.6537\n",
      "Epoch 56/1000\n",
      "113600/113600 [==============================] - 2076s 18ms/sample - loss: 0.2757 - acc: 0.8960 - val_loss: 1.7601 - val_acc: 0.6675\n",
      "Epoch 57/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2710 - acc: 0.8980 - val_loss: 1.4494 - val_acc: 0.6820\n",
      "Epoch 58/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2676 - acc: 0.8993 - val_loss: 1.3658 - val_acc: 0.6664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2704 - acc: 0.8986 - val_loss: 1.3772 - val_acc: 0.6869\n",
      "Epoch 60/1000\n",
      "113600/113600 [==============================] - 11s 95us/sample - loss: 0.2673 - acc: 0.9000 - val_loss: 1.3200 - val_acc: 0.6905\n",
      "Epoch 61/1000\n",
      "113600/113600 [==============================] - 11s 94us/sample - loss: 0.2635 - acc: 0.9011 - val_loss: 1.5892 - val_acc: 0.6734\n",
      "Epoch 62/1000\n",
      "113600/113600 [==============================] - 10s 92us/sample - loss: 0.2638 - acc: 0.9012 - val_loss: 2.0807 - val_acc: 0.6107\n",
      "Epoch 63/1000\n",
      "113600/113600 [==============================] - 613s 5ms/sample - loss: 0.2614 - acc: 0.9022 - val_loss: 1.5864 - val_acc: 0.6756\n",
      "Epoch 64/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2595 - acc: 0.9028 - val_loss: 1.7895 - val_acc: 0.6563\n",
      "Epoch 65/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2560 - acc: 0.9033 - val_loss: 1.3664 - val_acc: 0.6777\n",
      "Epoch 66/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2559 - acc: 0.9036 - val_loss: 1.6221 - val_acc: 0.6896\n",
      "Epoch 67/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2534 - acc: 0.9047 - val_loss: 1.3164 - val_acc: 0.7080\n",
      "Epoch 68/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2539 - acc: 0.9047 - val_loss: 1.3763 - val_acc: 0.6898\n",
      "Epoch 69/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2497 - acc: 0.9071 - val_loss: 1.3715 - val_acc: 0.6872\n",
      "Epoch 70/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2489 - acc: 0.9067 - val_loss: 1.6612 - val_acc: 0.6653\n",
      "Epoch 71/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2521 - acc: 0.9059 - val_loss: 1.6321 - val_acc: 0.6749\n",
      "Epoch 72/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2440 - acc: 0.9081 - val_loss: 1.6272 - val_acc: 0.6813\n",
      "Epoch 73/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2455 - acc: 0.9081 - val_loss: 1.5330 - val_acc: 0.6894\n",
      "Epoch 74/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2423 - acc: 0.9089 - val_loss: 1.7761 - val_acc: 0.6763\n",
      "Epoch 75/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2460 - acc: 0.9074 - val_loss: 1.6888 - val_acc: 0.6830\n",
      "Epoch 76/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2444 - acc: 0.9082 - val_loss: 1.5176 - val_acc: 0.6760\n",
      "Epoch 77/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2422 - acc: 0.9090 - val_loss: 1.2823 - val_acc: 0.7073\n",
      "Epoch 78/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2404 - acc: 0.9097 - val_loss: 1.9109 - val_acc: 0.6589\n",
      "Epoch 79/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2379 - acc: 0.9106 - val_loss: 1.5694 - val_acc: 0.6827\n",
      "Epoch 80/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2381 - acc: 0.9112 - val_loss: 1.2500 - val_acc: 0.7068\n",
      "Epoch 81/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2350 - acc: 0.9132 - val_loss: 1.2618 - val_acc: 0.7149\n",
      "Epoch 82/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2343 - acc: 0.9131 - val_loss: 1.6295 - val_acc: 0.6647\n",
      "Epoch 83/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2333 - acc: 0.9137 - val_loss: 1.4948 - val_acc: 0.6887\n",
      "Epoch 84/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2334 - acc: 0.9127 - val_loss: 1.8329 - val_acc: 0.6364\n",
      "Epoch 85/1000\n",
      "113600/113600 [==============================] - 3s 30us/sample - loss: 0.2322 - acc: 0.9144 - val_loss: 1.5948 - val_acc: 0.6792\n",
      "Epoch 86/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2342 - acc: 0.9124 - val_loss: 1.6949 - val_acc: 0.6768\n",
      "Epoch 87/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2315 - acc: 0.9135 - val_loss: 1.4775 - val_acc: 0.6935\n",
      "Epoch 88/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2306 - acc: 0.9137 - val_loss: 1.5012 - val_acc: 0.7025\n",
      "Epoch 89/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2302 - acc: 0.9158 - val_loss: 1.3265 - val_acc: 0.7147\n",
      "Epoch 90/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2285 - acc: 0.9154 - val_loss: 1.6999 - val_acc: 0.6728\n",
      "Epoch 91/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2290 - acc: 0.9148 - val_loss: 1.8042 - val_acc: 0.6689\n",
      "Epoch 92/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2303 - acc: 0.9146 - val_loss: 1.4482 - val_acc: 0.7071\n",
      "Epoch 93/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2212 - acc: 0.9180 - val_loss: 1.8482 - val_acc: 0.6508\n",
      "Epoch 94/1000\n",
      "113600/113600 [==============================] - 4s 32us/sample - loss: 0.2264 - acc: 0.9158 - val_loss: 1.7018 - val_acc: 0.6707\n",
      "Epoch 95/1000\n",
      "113600/113600 [==============================] - 3s 31us/sample - loss: 0.2234 - acc: 0.9177 - val_loss: 1.9982 - val_acc: 0.6713\n",
      "Epoch 96/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2219 - acc: 0.9171 - val_loss: 2.2497 - val_acc: 0.6075\n",
      "Epoch 97/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2221 - acc: 0.9166 - val_loss: 1.8712 - val_acc: 0.6365\n",
      "Epoch 98/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2189 - acc: 0.9189 - val_loss: 1.5240 - val_acc: 0.6962\n",
      "Epoch 99/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.2211 - acc: 0.9179 - val_loss: 1.5976 - val_acc: 0.6958\n",
      "Epoch 100/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2208 - acc: 0.9177 - val_loss: 1.9087 - val_acc: 0.6595\n",
      "Epoch 101/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.2223 - acc: 0.9177 - val_loss: 1.5884 - val_acc: 0.6774\n",
      "Epoch 102/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2172 - acc: 0.9188 - val_loss: 1.6646 - val_acc: 0.6851\n",
      "Epoch 103/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2164 - acc: 0.9197 - val_loss: 1.6834 - val_acc: 0.6870\n",
      "Epoch 104/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2139 - acc: 0.9203 - val_loss: 1.5843 - val_acc: 0.6939\n",
      "Epoch 105/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2172 - acc: 0.9189 - val_loss: 1.8913 - val_acc: 0.6804\n",
      "Epoch 106/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2090 - acc: 0.9220 - val_loss: 1.7026 - val_acc: 0.6817\n",
      "Epoch 107/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2134 - acc: 0.9204 - val_loss: 1.7952 - val_acc: 0.6685\n",
      "Epoch 108/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2182 - acc: 0.9188 - val_loss: 1.6043 - val_acc: 0.6876\n",
      "Epoch 109/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2139 - acc: 0.9217 - val_loss: 1.5867 - val_acc: 0.6856\n",
      "Epoch 110/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2134 - acc: 0.9209 - val_loss: 1.3992 - val_acc: 0.6953\n",
      "Epoch 111/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2140 - acc: 0.9214 - val_loss: 1.9239 - val_acc: 0.6646\n",
      "Epoch 112/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2088 - acc: 0.9225 - val_loss: 1.7213 - val_acc: 0.6665\n",
      "Epoch 113/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2098 - acc: 0.9222 - val_loss: 1.4996 - val_acc: 0.6868\n",
      "Epoch 114/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2072 - acc: 0.9224 - val_loss: 1.5729 - val_acc: 0.6915\n",
      "Epoch 115/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2072 - acc: 0.9229 - val_loss: 1.5898 - val_acc: 0.6771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2054 - acc: 0.9240 - val_loss: 1.4465 - val_acc: 0.7077\n",
      "Epoch 117/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2078 - acc: 0.9233 - val_loss: 1.7131 - val_acc: 0.6811\n",
      "Epoch 118/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2087 - acc: 0.9222 - val_loss: 1.4853 - val_acc: 0.6929\n",
      "Epoch 119/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2065 - acc: 0.9235 - val_loss: 1.6876 - val_acc: 0.6961\n",
      "Epoch 120/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2041 - acc: 0.9242 - val_loss: 1.6118 - val_acc: 0.6886\n",
      "Epoch 121/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2024 - acc: 0.9247 - val_loss: 1.5012 - val_acc: 0.6888\n",
      "Epoch 122/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2049 - acc: 0.9234 - val_loss: 1.3792 - val_acc: 0.7012\n",
      "Epoch 123/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2029 - acc: 0.9242 - val_loss: 1.9747 - val_acc: 0.6611\n",
      "Epoch 124/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2063 - acc: 0.9231 - val_loss: 1.7423 - val_acc: 0.6821\n",
      "Epoch 125/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2027 - acc: 0.9246 - val_loss: 1.7061 - val_acc: 0.6899\n",
      "Epoch 126/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2012 - acc: 0.9248 - val_loss: 1.4825 - val_acc: 0.7032\n",
      "Epoch 127/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2021 - acc: 0.9256 - val_loss: 1.5949 - val_acc: 0.6846\n",
      "Epoch 128/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1998 - acc: 0.9263 - val_loss: 1.6453 - val_acc: 0.6991\n",
      "Epoch 129/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2041 - acc: 0.9242 - val_loss: 1.3675 - val_acc: 0.7088\n",
      "Epoch 130/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1999 - acc: 0.9256 - val_loss: 1.4644 - val_acc: 0.6954\n",
      "Epoch 131/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2010 - acc: 0.9257 - val_loss: 1.3934 - val_acc: 0.7168\n",
      "Epoch 132/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1963 - acc: 0.9270 - val_loss: 2.1883 - val_acc: 0.6265\n",
      "Epoch 133/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1959 - acc: 0.9272 - val_loss: 1.4738 - val_acc: 0.7139\n",
      "Epoch 134/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1992 - acc: 0.9252 - val_loss: 1.4116 - val_acc: 0.7178\n",
      "Epoch 135/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1979 - acc: 0.9266 - val_loss: 1.4379 - val_acc: 0.7073\n",
      "Epoch 136/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1957 - acc: 0.9275 - val_loss: 1.4638 - val_acc: 0.7096\n",
      "Epoch 137/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1958 - acc: 0.9280 - val_loss: 1.5104 - val_acc: 0.7054\n",
      "Epoch 138/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1971 - acc: 0.9271 - val_loss: 1.5632 - val_acc: 0.7003\n",
      "Epoch 139/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1967 - acc: 0.9270 - val_loss: 1.6567 - val_acc: 0.6810\n",
      "Epoch 140/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1959 - acc: 0.9272 - val_loss: 1.4848 - val_acc: 0.7143\n",
      "Epoch 141/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1909 - acc: 0.9294 - val_loss: 1.4928 - val_acc: 0.7007\n",
      "Epoch 142/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1943 - acc: 0.9276 - val_loss: 1.9318 - val_acc: 0.6551\n",
      "Epoch 143/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1928 - acc: 0.9291 - val_loss: 1.6430 - val_acc: 0.6946\n",
      "Epoch 144/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1920 - acc: 0.9292 - val_loss: 1.6306 - val_acc: 0.7057\n",
      "Epoch 145/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1928 - acc: 0.9293 - val_loss: 1.5996 - val_acc: 0.7047\n",
      "Epoch 146/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1932 - acc: 0.9285 - val_loss: 1.4525 - val_acc: 0.7067\n",
      "Epoch 147/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1929 - acc: 0.9285 - val_loss: 1.4540 - val_acc: 0.6950\n",
      "Epoch 148/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1900 - acc: 0.9303 - val_loss: 1.7846 - val_acc: 0.6672\n",
      "Epoch 149/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1849 - acc: 0.9305 - val_loss: 1.5216 - val_acc: 0.7035\n",
      "Epoch 150/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1915 - acc: 0.9294 - val_loss: 2.1188 - val_acc: 0.6558\n",
      "Epoch 151/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1898 - acc: 0.9297 - val_loss: 1.7499 - val_acc: 0.6884\n",
      "Epoch 152/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1913 - acc: 0.9286 - val_loss: 1.5532 - val_acc: 0.7077\n",
      "Epoch 153/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1895 - acc: 0.9295 - val_loss: 1.7415 - val_acc: 0.6631\n",
      "Epoch 154/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1894 - acc: 0.9303 - val_loss: 1.6995 - val_acc: 0.6968\n",
      "Epoch 155/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1861 - acc: 0.9308 - val_loss: 1.4452 - val_acc: 0.7140\n",
      "Epoch 156/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1882 - acc: 0.9299 - val_loss: 1.5778 - val_acc: 0.6977\n",
      "Epoch 157/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1860 - acc: 0.9314 - val_loss: 1.6571 - val_acc: 0.6977\n",
      "Epoch 158/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1832 - acc: 0.9317 - val_loss: 1.7728 - val_acc: 0.6835\n",
      "Epoch 159/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1865 - acc: 0.9306 - val_loss: 1.9974 - val_acc: 0.6700\n",
      "Epoch 160/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1800 - acc: 0.9332 - val_loss: 1.7822 - val_acc: 0.6990\n",
      "Epoch 161/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1836 - acc: 0.9316 - val_loss: 1.6696 - val_acc: 0.7001\n",
      "Epoch 162/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1847 - acc: 0.9319 - val_loss: 1.8483 - val_acc: 0.6775\n",
      "Epoch 163/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1874 - acc: 0.9314 - val_loss: 1.7108 - val_acc: 0.6987\n",
      "Epoch 164/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1856 - acc: 0.9308 - val_loss: 1.8900 - val_acc: 0.6563\n",
      "Epoch 165/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1849 - acc: 0.9311 - val_loss: 1.7009 - val_acc: 0.6920\n",
      "Epoch 166/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1818 - acc: 0.9330 - val_loss: 1.5586 - val_acc: 0.7064\n",
      "Epoch 167/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1802 - acc: 0.9335 - val_loss: 1.6183 - val_acc: 0.7144\n",
      "Epoch 168/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1844 - acc: 0.9318 - val_loss: 1.7115 - val_acc: 0.6873\n",
      "Epoch 169/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1799 - acc: 0.9336 - val_loss: 1.5639 - val_acc: 0.7025\n",
      "Epoch 170/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1805 - acc: 0.9337 - val_loss: 1.8269 - val_acc: 0.6989\n",
      "Epoch 171/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1825 - acc: 0.9332 - val_loss: 1.5699 - val_acc: 0.7071\n",
      "Epoch 172/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1801 - acc: 0.9342 - val_loss: 1.5038 - val_acc: 0.7166\n",
      "Epoch 173/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1791 - acc: 0.9339 - val_loss: 1.6106 - val_acc: 0.7047\n",
      "Epoch 174/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1814 - acc: 0.9331 - val_loss: 1.5344 - val_acc: 0.6954\n",
      "Epoch 175/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1812 - acc: 0.9329 - val_loss: 1.5097 - val_acc: 0.7080\n",
      "Epoch 176/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1781 - acc: 0.9338 - val_loss: 1.7003 - val_acc: 0.6929\n",
      "Epoch 177/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1772 - acc: 0.9341 - val_loss: 1.6885 - val_acc: 0.7085\n",
      "Epoch 178/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1812 - acc: 0.9322 - val_loss: 1.6147 - val_acc: 0.7032\n",
      "Epoch 179/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1766 - acc: 0.9350 - val_loss: 1.5213 - val_acc: 0.7192\n",
      "Epoch 180/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1770 - acc: 0.9338 - val_loss: 1.6625 - val_acc: 0.7050\n",
      "Epoch 181/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1771 - acc: 0.9352 - val_loss: 1.7242 - val_acc: 0.7029\n",
      "Epoch 182/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1771 - acc: 0.9337 - val_loss: 1.7693 - val_acc: 0.6921\n",
      "Epoch 183/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1757 - acc: 0.9352 - val_loss: 1.7489 - val_acc: 0.7046\n",
      "Epoch 184/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1780 - acc: 0.9342 - val_loss: 1.7942 - val_acc: 0.6853\n",
      "Epoch 185/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1757 - acc: 0.9355 - val_loss: 1.7447 - val_acc: 0.6981\n",
      "Epoch 186/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1735 - acc: 0.9360 - val_loss: 1.4828 - val_acc: 0.7143\n",
      "Epoch 187/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1724 - acc: 0.9362 - val_loss: 1.6860 - val_acc: 0.6917\n",
      "Epoch 188/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1747 - acc: 0.9364 - val_loss: 1.5629 - val_acc: 0.7170\n",
      "Epoch 189/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1752 - acc: 0.9344 - val_loss: 1.6882 - val_acc: 0.7023\n",
      "Epoch 190/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1725 - acc: 0.9362 - val_loss: 1.6192 - val_acc: 0.7014\n",
      "Epoch 191/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1738 - acc: 0.9357 - val_loss: 1.5644 - val_acc: 0.6969\n",
      "Epoch 192/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1724 - acc: 0.9370 - val_loss: 1.8465 - val_acc: 0.6955\n",
      "Epoch 193/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1770 - acc: 0.9351 - val_loss: 1.6279 - val_acc: 0.7045\n",
      "Epoch 194/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1734 - acc: 0.9360 - val_loss: 1.5705 - val_acc: 0.7102\n",
      "Epoch 195/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1733 - acc: 0.9356 - val_loss: 1.4920 - val_acc: 0.7099\n",
      "Epoch 196/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1736 - acc: 0.9353 - val_loss: 1.9343 - val_acc: 0.6783\n",
      "Epoch 197/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1728 - acc: 0.9362 - val_loss: 1.5751 - val_acc: 0.7009\n",
      "Epoch 198/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1716 - acc: 0.9372 - val_loss: 1.7069 - val_acc: 0.6925\n",
      "Epoch 199/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1710 - acc: 0.9373 - val_loss: 1.6191 - val_acc: 0.7012\n",
      "Epoch 200/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1707 - acc: 0.9375 - val_loss: 1.5160 - val_acc: 0.7173\n",
      "Epoch 201/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1698 - acc: 0.9373 - val_loss: 1.8951 - val_acc: 0.6905\n",
      "Epoch 202/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1739 - acc: 0.9359 - val_loss: 1.5054 - val_acc: 0.7007\n",
      "Epoch 203/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1691 - acc: 0.9375 - val_loss: 2.0749 - val_acc: 0.6657\n",
      "Epoch 204/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1692 - acc: 0.9371 - val_loss: 1.6858 - val_acc: 0.7012\n",
      "Epoch 205/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1719 - acc: 0.9369 - val_loss: 1.7980 - val_acc: 0.7006\n",
      "Epoch 206/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1666 - acc: 0.9388 - val_loss: 1.8040 - val_acc: 0.6890\n",
      "Epoch 207/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1694 - acc: 0.9375 - val_loss: 1.8176 - val_acc: 0.6925\n",
      "Epoch 208/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1698 - acc: 0.9382 - val_loss: 1.6842 - val_acc: 0.6961\n",
      "Epoch 209/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1675 - acc: 0.9382 - val_loss: 1.9804 - val_acc: 0.6733\n",
      "Epoch 210/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1668 - acc: 0.9382 - val_loss: 1.5276 - val_acc: 0.7105\n",
      "Epoch 211/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1689 - acc: 0.9374 - val_loss: 1.5930 - val_acc: 0.6963\n",
      "Epoch 212/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1696 - acc: 0.9387 - val_loss: 1.5573 - val_acc: 0.7109\n",
      "Epoch 213/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1688 - acc: 0.9379 - val_loss: 1.6655 - val_acc: 0.7005\n",
      "Epoch 214/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1627 - acc: 0.9405 - val_loss: 1.4744 - val_acc: 0.7078\n",
      "Epoch 215/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1677 - acc: 0.9386 - val_loss: 1.7935 - val_acc: 0.6829\n",
      "Epoch 216/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1657 - acc: 0.9388 - val_loss: 1.8402 - val_acc: 0.6738\n",
      "Epoch 217/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1670 - acc: 0.9395 - val_loss: 1.7339 - val_acc: 0.6923\n",
      "Epoch 218/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1658 - acc: 0.9389 - val_loss: 1.6532 - val_acc: 0.7094\n",
      "Epoch 219/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1687 - acc: 0.9380 - val_loss: 1.5404 - val_acc: 0.7134\n",
      "Epoch 220/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1633 - acc: 0.9412 - val_loss: 1.6859 - val_acc: 0.7023\n",
      "Epoch 221/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1677 - acc: 0.9380 - val_loss: 1.4712 - val_acc: 0.7042\n",
      "Epoch 222/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1648 - acc: 0.9392 - val_loss: 1.5008 - val_acc: 0.7142\n",
      "Epoch 223/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1676 - acc: 0.9382 - val_loss: 1.6985 - val_acc: 0.6974\n",
      "Epoch 224/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1669 - acc: 0.9387 - val_loss: 1.6438 - val_acc: 0.6982\n",
      "Epoch 225/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1631 - acc: 0.9405 - val_loss: 1.5893 - val_acc: 0.6975\n",
      "Epoch 226/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1647 - acc: 0.9391 - val_loss: 1.5752 - val_acc: 0.7177\n",
      "Epoch 227/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1642 - acc: 0.9394 - val_loss: 1.6657 - val_acc: 0.6904\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1664 - acc: 0.9391 - val_loss: 1.6622 - val_acc: 0.7077\n",
      "Epoch 229/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1646 - acc: 0.9395 - val_loss: 1.6239 - val_acc: 0.7099\n",
      "Epoch 230/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1600 - acc: 0.9405 - val_loss: 1.7176 - val_acc: 0.6917\n",
      "Epoch 231/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1615 - acc: 0.9414 - val_loss: 1.8058 - val_acc: 0.7080\n",
      "Epoch 232/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1641 - acc: 0.9398 - val_loss: 1.5599 - val_acc: 0.7017\n",
      "Epoch 233/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1627 - acc: 0.9400 - val_loss: 1.7107 - val_acc: 0.6919\n",
      "Epoch 234/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1614 - acc: 0.9403 - val_loss: 1.6653 - val_acc: 0.7079\n",
      "Epoch 235/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1576 - acc: 0.9425 - val_loss: 2.0703 - val_acc: 0.6842\n",
      "Epoch 236/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1645 - acc: 0.9389 - val_loss: 1.5617 - val_acc: 0.7086\n",
      "Epoch 237/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1568 - acc: 0.9420 - val_loss: 1.4925 - val_acc: 0.7211\n",
      "Epoch 238/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1593 - acc: 0.9409 - val_loss: 1.7799 - val_acc: 0.7074\n",
      "Epoch 239/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1604 - acc: 0.9413 - val_loss: 1.9000 - val_acc: 0.6933\n",
      "Epoch 240/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1603 - acc: 0.9401 - val_loss: 1.7301 - val_acc: 0.7130\n",
      "Epoch 241/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1616 - acc: 0.9406 - val_loss: 1.6583 - val_acc: 0.7169\n",
      "Epoch 242/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1621 - acc: 0.9407 - val_loss: 1.5613 - val_acc: 0.7098\n",
      "Epoch 243/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1606 - acc: 0.9415 - val_loss: 1.5340 - val_acc: 0.7154\n",
      "Epoch 244/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1605 - acc: 0.9413 - val_loss: 1.7180 - val_acc: 0.6989\n",
      "Epoch 245/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1598 - acc: 0.9410 - val_loss: 2.0823 - val_acc: 0.6852\n",
      "Epoch 246/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1606 - acc: 0.9411 - val_loss: 1.7325 - val_acc: 0.6903\n",
      "Epoch 247/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1609 - acc: 0.9406 - val_loss: 1.6906 - val_acc: 0.7030\n",
      "Epoch 248/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1591 - acc: 0.9419 - val_loss: 1.9960 - val_acc: 0.6885\n",
      "Epoch 249/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1593 - acc: 0.9413 - val_loss: 1.7391 - val_acc: 0.7028\n",
      "Epoch 250/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1572 - acc: 0.9433 - val_loss: 1.5950 - val_acc: 0.7138\n",
      "Epoch 251/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1563 - acc: 0.9431 - val_loss: 1.6852 - val_acc: 0.6942\n",
      "Epoch 252/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1579 - acc: 0.9414 - val_loss: 1.5684 - val_acc: 0.7196\n",
      "Epoch 253/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1579 - acc: 0.9420 - val_loss: 1.4975 - val_acc: 0.7211\n",
      "Epoch 254/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1586 - acc: 0.9417 - val_loss: 1.8197 - val_acc: 0.6794\n",
      "Epoch 255/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1597 - acc: 0.9418 - val_loss: 1.8792 - val_acc: 0.6946\n",
      "Epoch 256/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1559 - acc: 0.9422 - val_loss: 1.5538 - val_acc: 0.7014\n",
      "Epoch 257/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1596 - acc: 0.9424 - val_loss: 1.9639 - val_acc: 0.6687\n",
      "Epoch 258/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1571 - acc: 0.9424 - val_loss: 1.7292 - val_acc: 0.6874\n",
      "Epoch 259/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1567 - acc: 0.9421 - val_loss: 1.7254 - val_acc: 0.7049\n",
      "Epoch 260/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1585 - acc: 0.9419 - val_loss: 1.5506 - val_acc: 0.7145\n",
      "Epoch 261/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1551 - acc: 0.9443 - val_loss: 1.8355 - val_acc: 0.6991\n",
      "Epoch 262/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1553 - acc: 0.9431 - val_loss: 1.5522 - val_acc: 0.6992\n",
      "Epoch 263/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1571 - acc: 0.9422 - val_loss: 1.4636 - val_acc: 0.7279\n",
      "Epoch 264/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1545 - acc: 0.9432 - val_loss: 1.4795 - val_acc: 0.7221\n",
      "Epoch 265/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1569 - acc: 0.9429 - val_loss: 1.9060 - val_acc: 0.6841\n",
      "Epoch 266/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1563 - acc: 0.9429 - val_loss: 1.9330 - val_acc: 0.6838\n",
      "Epoch 267/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1546 - acc: 0.9432 - val_loss: 1.5584 - val_acc: 0.7074\n",
      "Epoch 268/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1525 - acc: 0.9445 - val_loss: 1.6593 - val_acc: 0.7010\n",
      "Epoch 269/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1561 - acc: 0.9424 - val_loss: 1.8681 - val_acc: 0.7011\n",
      "Epoch 270/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1543 - acc: 0.9433 - val_loss: 1.7748 - val_acc: 0.7044\n",
      "Epoch 271/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1558 - acc: 0.9429 - val_loss: 1.5160 - val_acc: 0.7218\n",
      "Epoch 272/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1542 - acc: 0.9439 - val_loss: 1.7678 - val_acc: 0.6996\n",
      "Epoch 273/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1527 - acc: 0.9442 - val_loss: 1.6235 - val_acc: 0.7089\n",
      "Epoch 274/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1541 - acc: 0.9434 - val_loss: 1.6137 - val_acc: 0.7100\n",
      "Epoch 275/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1509 - acc: 0.9440 - val_loss: 1.4825 - val_acc: 0.7124\n",
      "Epoch 276/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1528 - acc: 0.9440 - val_loss: 1.6992 - val_acc: 0.7010\n",
      "Epoch 277/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1513 - acc: 0.9442 - val_loss: 2.1095 - val_acc: 0.6737\n",
      "Epoch 278/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1520 - acc: 0.9441 - val_loss: 1.6122 - val_acc: 0.7123\n",
      "Epoch 279/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1533 - acc: 0.9436 - val_loss: 1.8683 - val_acc: 0.6907\n",
      "Epoch 280/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1502 - acc: 0.9452 - val_loss: 1.5676 - val_acc: 0.7153\n",
      "Epoch 281/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1531 - acc: 0.9442 - val_loss: 1.6019 - val_acc: 0.7070\n",
      "Epoch 282/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1532 - acc: 0.9438 - val_loss: 1.9066 - val_acc: 0.6927\n",
      "Epoch 283/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1526 - acc: 0.9445 - val_loss: 1.6341 - val_acc: 0.7087\n",
      "Epoch 284/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1510 - acc: 0.9446 - val_loss: 1.6278 - val_acc: 0.7206\n",
      "Epoch 285/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1511 - acc: 0.9440 - val_loss: 1.9986 - val_acc: 0.6937\n",
      "Epoch 286/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1453 - acc: 0.9462 - val_loss: 1.7758 - val_acc: 0.7165\n",
      "Epoch 287/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1508 - acc: 0.9446 - val_loss: 1.5877 - val_acc: 0.7151\n",
      "Epoch 288/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1496 - acc: 0.9449 - val_loss: 1.6990 - val_acc: 0.7071\n",
      "Epoch 289/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1516 - acc: 0.9458 - val_loss: 1.7061 - val_acc: 0.7118\n",
      "Epoch 290/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1489 - acc: 0.9460 - val_loss: 1.9172 - val_acc: 0.6932\n",
      "Epoch 291/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1506 - acc: 0.9451 - val_loss: 1.5918 - val_acc: 0.7113\n",
      "Epoch 292/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1500 - acc: 0.9452 - val_loss: 1.8410 - val_acc: 0.6836\n",
      "Epoch 293/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1522 - acc: 0.9444 - val_loss: 1.9085 - val_acc: 0.7058\n",
      "Epoch 294/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1479 - acc: 0.9455 - val_loss: 1.5438 - val_acc: 0.7199\n",
      "Epoch 295/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1514 - acc: 0.9442 - val_loss: 1.7306 - val_acc: 0.7005\n",
      "Epoch 296/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1447 - acc: 0.9470 - val_loss: 1.9847 - val_acc: 0.6932\n",
      "Epoch 297/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1503 - acc: 0.9448 - val_loss: 1.6030 - val_acc: 0.7092\n",
      "Epoch 298/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1483 - acc: 0.9462 - val_loss: 1.8334 - val_acc: 0.7046\n",
      "Epoch 299/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1490 - acc: 0.9455 - val_loss: 1.8472 - val_acc: 0.7042\n",
      "Epoch 300/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1520 - acc: 0.9451 - val_loss: 1.6545 - val_acc: 0.7075\n",
      "Epoch 301/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1489 - acc: 0.9451 - val_loss: 1.8888 - val_acc: 0.6980\n",
      "Epoch 302/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1479 - acc: 0.9454 - val_loss: 1.5855 - val_acc: 0.7253\n",
      "Epoch 303/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1514 - acc: 0.9446 - val_loss: 1.7604 - val_acc: 0.7102\n",
      "Epoch 304/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1473 - acc: 0.9458 - val_loss: 1.5897 - val_acc: 0.7204\n",
      "Epoch 305/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1489 - acc: 0.9459 - val_loss: 1.7442 - val_acc: 0.7106\n",
      "Epoch 306/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1486 - acc: 0.9458 - val_loss: 1.5239 - val_acc: 0.6998\n",
      "Epoch 307/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1479 - acc: 0.9456 - val_loss: 1.6294 - val_acc: 0.7121\n",
      "Epoch 308/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1459 - acc: 0.9466 - val_loss: 1.6509 - val_acc: 0.7117\n",
      "Epoch 309/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1452 - acc: 0.9465 - val_loss: 1.6541 - val_acc: 0.7067\n",
      "Epoch 310/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1466 - acc: 0.9464 - val_loss: 1.5303 - val_acc: 0.7175\n",
      "Epoch 311/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1456 - acc: 0.9464 - val_loss: 1.7850 - val_acc: 0.7019\n",
      "Epoch 312/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1483 - acc: 0.9459 - val_loss: 1.7808 - val_acc: 0.7030\n",
      "Epoch 313/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1467 - acc: 0.9464 - val_loss: 1.7087 - val_acc: 0.7093\n",
      "Epoch 314/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1454 - acc: 0.9469 - val_loss: 1.9882 - val_acc: 0.6851\n",
      "Epoch 315/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1462 - acc: 0.9469 - val_loss: 1.7905 - val_acc: 0.6989\n",
      "Epoch 316/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1453 - acc: 0.9469 - val_loss: 1.5287 - val_acc: 0.7349\n",
      "Epoch 317/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1454 - acc: 0.9463 - val_loss: 1.6535 - val_acc: 0.7114\n",
      "Epoch 318/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1445 - acc: 0.9473 - val_loss: 1.8847 - val_acc: 0.7010\n",
      "Epoch 319/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1481 - acc: 0.9453 - val_loss: 1.5920 - val_acc: 0.7239\n",
      "Epoch 320/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1437 - acc: 0.9476 - val_loss: 1.8207 - val_acc: 0.6996\n",
      "Epoch 321/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1438 - acc: 0.9470 - val_loss: 1.7800 - val_acc: 0.7082\n",
      "Epoch 322/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1448 - acc: 0.9472 - val_loss: 1.8221 - val_acc: 0.7015\n",
      "Epoch 323/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1449 - acc: 0.9470 - val_loss: 1.6614 - val_acc: 0.7159\n",
      "Epoch 324/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1458 - acc: 0.9462 - val_loss: 1.7484 - val_acc: 0.7207\n",
      "Epoch 325/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1489 - acc: 0.9460 - val_loss: 2.0821 - val_acc: 0.6930\n",
      "Epoch 326/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1455 - acc: 0.9472 - val_loss: 1.5397 - val_acc: 0.7218\n",
      "Epoch 327/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1406 - acc: 0.9490 - val_loss: 1.8982 - val_acc: 0.7043\n",
      "Epoch 328/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1436 - acc: 0.9474 - val_loss: 1.7533 - val_acc: 0.7107\n",
      "Epoch 329/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1431 - acc: 0.9468 - val_loss: 1.7329 - val_acc: 0.7145\n",
      "Epoch 330/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1429 - acc: 0.9477 - val_loss: 1.6516 - val_acc: 0.7234\n",
      "Epoch 331/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1437 - acc: 0.9477 - val_loss: 1.6434 - val_acc: 0.7175\n",
      "Epoch 332/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1392 - acc: 0.9495 - val_loss: 2.0876 - val_acc: 0.6889\n",
      "Epoch 333/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1438 - acc: 0.9474 - val_loss: 1.5029 - val_acc: 0.7187\n",
      "Epoch 334/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1463 - acc: 0.9470 - val_loss: 1.9386 - val_acc: 0.6911\n",
      "Epoch 335/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1442 - acc: 0.9475 - val_loss: 1.7426 - val_acc: 0.7135\n",
      "Epoch 336/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1411 - acc: 0.9494 - val_loss: 1.4211 - val_acc: 0.7284\n",
      "Epoch 337/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1431 - acc: 0.9476 - val_loss: 1.8257 - val_acc: 0.6967\n",
      "Epoch 338/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1418 - acc: 0.9479 - val_loss: 1.8404 - val_acc: 0.7000\n",
      "Epoch 339/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1429 - acc: 0.9474 - val_loss: 1.8778 - val_acc: 0.6855\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1422 - acc: 0.9476 - val_loss: 1.5476 - val_acc: 0.7214\n",
      "Epoch 341/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1425 - acc: 0.9483 - val_loss: 1.7193 - val_acc: 0.7077\n",
      "Epoch 342/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1408 - acc: 0.9480 - val_loss: 1.9899 - val_acc: 0.6889\n",
      "Epoch 343/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1430 - acc: 0.9471 - val_loss: 2.0189 - val_acc: 0.6918\n",
      "Epoch 344/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1405 - acc: 0.9485 - val_loss: 1.9615 - val_acc: 0.6968\n",
      "Epoch 345/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1367 - acc: 0.9505 - val_loss: 2.0259 - val_acc: 0.6989\n",
      "Epoch 346/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1400 - acc: 0.9485 - val_loss: 1.8586 - val_acc: 0.7097\n",
      "Epoch 347/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1427 - acc: 0.9472 - val_loss: 1.6089 - val_acc: 0.7095\n",
      "Epoch 348/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1426 - acc: 0.9480 - val_loss: 1.7181 - val_acc: 0.7020\n",
      "Epoch 349/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1408 - acc: 0.9478 - val_loss: 1.5170 - val_acc: 0.7204\n",
      "Epoch 350/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1387 - acc: 0.9491 - val_loss: 1.6555 - val_acc: 0.7189\n",
      "Epoch 351/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1409 - acc: 0.9479 - val_loss: 1.7007 - val_acc: 0.7086\n",
      "Epoch 352/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1372 - acc: 0.9500 - val_loss: 1.6696 - val_acc: 0.7158\n",
      "Epoch 353/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1386 - acc: 0.9496 - val_loss: 1.8036 - val_acc: 0.7070\n",
      "Epoch 354/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1378 - acc: 0.9504 - val_loss: 1.7871 - val_acc: 0.7158\n",
      "Epoch 355/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1385 - acc: 0.9496 - val_loss: 1.7096 - val_acc: 0.7095\n",
      "Epoch 356/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1407 - acc: 0.9491 - val_loss: 1.6352 - val_acc: 0.7089\n",
      "Epoch 357/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1377 - acc: 0.9493 - val_loss: 1.8932 - val_acc: 0.6983\n",
      "Epoch 358/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1395 - acc: 0.9490 - val_loss: 2.0634 - val_acc: 0.6802\n",
      "Epoch 359/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1379 - acc: 0.9494 - val_loss: 1.6116 - val_acc: 0.7215\n",
      "Epoch 360/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1388 - acc: 0.9487 - val_loss: 1.7256 - val_acc: 0.7076\n",
      "Epoch 361/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1430 - acc: 0.9476 - val_loss: 1.6998 - val_acc: 0.7056\n",
      "Epoch 362/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1409 - acc: 0.9485 - val_loss: 1.6031 - val_acc: 0.7123\n",
      "Epoch 363/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1407 - acc: 0.9486 - val_loss: 1.7272 - val_acc: 0.7126\n",
      "Epoch 364/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1376 - acc: 0.9502 - val_loss: 1.9121 - val_acc: 0.7071\n",
      "Epoch 365/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1389 - acc: 0.9498 - val_loss: 1.7805 - val_acc: 0.6942\n",
      "Epoch 366/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1370 - acc: 0.9494 - val_loss: 1.7022 - val_acc: 0.7215\n",
      "Epoch 367/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1357 - acc: 0.9501 - val_loss: 1.8800 - val_acc: 0.6932\n",
      "Epoch 368/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1380 - acc: 0.9499 - val_loss: 1.7965 - val_acc: 0.7084\n",
      "Epoch 369/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1382 - acc: 0.9494 - val_loss: 1.5552 - val_acc: 0.7100\n",
      "Epoch 370/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1362 - acc: 0.9501 - val_loss: 2.1624 - val_acc: 0.6864\n",
      "Epoch 371/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1387 - acc: 0.9492 - val_loss: 1.6218 - val_acc: 0.7196\n",
      "Epoch 372/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1355 - acc: 0.9507 - val_loss: 1.5572 - val_acc: 0.7214\n",
      "Epoch 373/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1385 - acc: 0.9498 - val_loss: 1.6116 - val_acc: 0.7194\n",
      "Epoch 374/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1359 - acc: 0.9504 - val_loss: 1.5943 - val_acc: 0.7250\n",
      "Epoch 375/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1382 - acc: 0.9492 - val_loss: 1.7353 - val_acc: 0.7049\n",
      "Epoch 376/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1374 - acc: 0.9503 - val_loss: 1.8459 - val_acc: 0.7127\n",
      "Epoch 377/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1351 - acc: 0.9504 - val_loss: 1.6555 - val_acc: 0.7061\n",
      "Epoch 378/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1380 - acc: 0.9498 - val_loss: 1.7769 - val_acc: 0.7048\n",
      "Epoch 379/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1386 - acc: 0.9498 - val_loss: 1.7008 - val_acc: 0.7140\n",
      "Epoch 380/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1362 - acc: 0.9504 - val_loss: 1.6999 - val_acc: 0.7106\n",
      "Epoch 381/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1335 - acc: 0.9511 - val_loss: 2.0376 - val_acc: 0.6884\n",
      "Epoch 382/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1364 - acc: 0.9502 - val_loss: 1.6693 - val_acc: 0.7196\n",
      "Epoch 383/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1364 - acc: 0.9504 - val_loss: 1.7981 - val_acc: 0.7146\n",
      "Epoch 384/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1345 - acc: 0.9514 - val_loss: 1.7080 - val_acc: 0.7109\n",
      "Epoch 385/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1367 - acc: 0.9498 - val_loss: 1.6477 - val_acc: 0.7127\n",
      "Epoch 386/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1373 - acc: 0.9493 - val_loss: 1.9614 - val_acc: 0.6883\n",
      "Epoch 387/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1354 - acc: 0.9506 - val_loss: 1.6721 - val_acc: 0.7190\n",
      "Epoch 388/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1358 - acc: 0.9507 - val_loss: 1.9988 - val_acc: 0.6993\n",
      "Epoch 389/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1381 - acc: 0.9502 - val_loss: 1.6722 - val_acc: 0.7254\n",
      "Epoch 390/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1338 - acc: 0.9508 - val_loss: 1.8935 - val_acc: 0.7106\n",
      "Epoch 391/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1318 - acc: 0.9516 - val_loss: 1.6564 - val_acc: 0.7250\n",
      "Epoch 392/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1327 - acc: 0.9512 - val_loss: 1.9405 - val_acc: 0.7037\n",
      "Epoch 393/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1343 - acc: 0.9513 - val_loss: 1.7538 - val_acc: 0.7090\n",
      "Epoch 394/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1361 - acc: 0.9507 - val_loss: 1.7141 - val_acc: 0.7089\n",
      "Epoch 395/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1325 - acc: 0.9516 - val_loss: 2.0749 - val_acc: 0.6829\n",
      "Epoch 396/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1359 - acc: 0.9508 - val_loss: 1.5791 - val_acc: 0.7165\n",
      "Epoch 397/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1321 - acc: 0.9512 - val_loss: 1.8406 - val_acc: 0.7086\n",
      "Epoch 398/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1331 - acc: 0.9520 - val_loss: 1.8546 - val_acc: 0.6936\n",
      "Epoch 399/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1304 - acc: 0.9524 - val_loss: 1.5082 - val_acc: 0.7269\n",
      "Epoch 400/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1378 - acc: 0.9499 - val_loss: 1.8139 - val_acc: 0.7173\n",
      "Epoch 401/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1369 - acc: 0.9501 - val_loss: 1.8008 - val_acc: 0.7077\n",
      "Epoch 402/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1328 - acc: 0.9520 - val_loss: 1.7803 - val_acc: 0.7046\n",
      "Epoch 403/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1351 - acc: 0.9513 - val_loss: 1.7032 - val_acc: 0.7030\n",
      "Epoch 404/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1327 - acc: 0.9521 - val_loss: 1.7655 - val_acc: 0.7146\n",
      "Epoch 405/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1319 - acc: 0.9522 - val_loss: 1.5775 - val_acc: 0.7145\n",
      "Epoch 406/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1343 - acc: 0.9509 - val_loss: 1.6771 - val_acc: 0.7175\n",
      "Epoch 407/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1362 - acc: 0.9505 - val_loss: 1.6874 - val_acc: 0.7159\n",
      "Epoch 408/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1330 - acc: 0.9516 - val_loss: 1.5928 - val_acc: 0.7170\n",
      "Epoch 409/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1344 - acc: 0.9520 - val_loss: 1.6973 - val_acc: 0.7155\n",
      "Epoch 410/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1323 - acc: 0.9521 - val_loss: 1.5986 - val_acc: 0.7242\n",
      "Epoch 411/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1298 - acc: 0.9524 - val_loss: 1.5772 - val_acc: 0.7177\n",
      "Epoch 412/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1346 - acc: 0.9509 - val_loss: 1.8826 - val_acc: 0.7075\n",
      "Epoch 413/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1313 - acc: 0.9517 - val_loss: 1.5544 - val_acc: 0.7169\n",
      "Epoch 414/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1312 - acc: 0.9518 - val_loss: 1.7722 - val_acc: 0.7047\n",
      "Epoch 415/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1306 - acc: 0.9525 - val_loss: 1.7757 - val_acc: 0.7175\n",
      "Epoch 416/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1337 - acc: 0.9513 - val_loss: 1.8777 - val_acc: 0.7110\n",
      "Epoch 417/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1332 - acc: 0.9523 - val_loss: 1.8656 - val_acc: 0.7077\n",
      "Epoch 418/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1301 - acc: 0.9531 - val_loss: 1.6467 - val_acc: 0.7181\n",
      "Epoch 419/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1295 - acc: 0.9526 - val_loss: 1.8225 - val_acc: 0.7104\n",
      "Epoch 420/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1313 - acc: 0.9518 - val_loss: 2.0359 - val_acc: 0.6781\n",
      "Epoch 421/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1304 - acc: 0.9524 - val_loss: 1.6636 - val_acc: 0.7180\n",
      "Epoch 422/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1296 - acc: 0.9535 - val_loss: 1.7812 - val_acc: 0.7027\n",
      "Epoch 423/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1311 - acc: 0.9519 - val_loss: 1.6774 - val_acc: 0.7087\n",
      "Epoch 424/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1316 - acc: 0.9518 - val_loss: 1.9072 - val_acc: 0.7064\n",
      "Epoch 425/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1322 - acc: 0.9515 - val_loss: 2.0143 - val_acc: 0.7026\n",
      "Epoch 426/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1296 - acc: 0.9532 - val_loss: 1.9561 - val_acc: 0.6909\n",
      "Epoch 427/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1322 - acc: 0.9516 - val_loss: 1.6474 - val_acc: 0.7161\n",
      "Epoch 428/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1302 - acc: 0.9524 - val_loss: 1.6699 - val_acc: 0.7103\n",
      "Epoch 429/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1341 - acc: 0.9510 - val_loss: 1.8233 - val_acc: 0.6949\n",
      "Epoch 430/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1312 - acc: 0.9523 - val_loss: 1.6747 - val_acc: 0.7163\n",
      "Epoch 431/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1302 - acc: 0.9532 - val_loss: 2.0501 - val_acc: 0.6840\n",
      "Epoch 432/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1293 - acc: 0.9529 - val_loss: 2.0567 - val_acc: 0.7006\n",
      "Epoch 433/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1285 - acc: 0.9529 - val_loss: 1.9981 - val_acc: 0.6989\n",
      "Epoch 434/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1306 - acc: 0.9523 - val_loss: 1.7141 - val_acc: 0.7167\n",
      "Epoch 435/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1279 - acc: 0.9528 - val_loss: 1.6755 - val_acc: 0.7083\n",
      "Epoch 436/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1282 - acc: 0.9533 - val_loss: 1.9095 - val_acc: 0.7079\n",
      "Epoch 437/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1291 - acc: 0.9532 - val_loss: 1.8378 - val_acc: 0.7106\n",
      "Epoch 438/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1305 - acc: 0.9523 - val_loss: 1.8149 - val_acc: 0.6998\n",
      "Epoch 439/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1277 - acc: 0.9534 - val_loss: 1.6972 - val_acc: 0.7121\n",
      "Epoch 440/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1326 - acc: 0.9525 - val_loss: 1.8599 - val_acc: 0.7097\n",
      "Epoch 441/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1262 - acc: 0.9541 - val_loss: 1.7828 - val_acc: 0.7124\n",
      "Epoch 442/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1312 - acc: 0.9532 - val_loss: 1.9471 - val_acc: 0.7059\n",
      "Epoch 443/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1281 - acc: 0.9533 - val_loss: 1.6512 - val_acc: 0.7132\n",
      "Epoch 444/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1293 - acc: 0.9530 - val_loss: 1.5642 - val_acc: 0.7249\n",
      "Epoch 445/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1310 - acc: 0.9521 - val_loss: 1.9178 - val_acc: 0.6977\n",
      "Epoch 446/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1315 - acc: 0.9519 - val_loss: 1.8504 - val_acc: 0.7039\n",
      "Epoch 447/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1289 - acc: 0.9525 - val_loss: 1.7404 - val_acc: 0.7071\n",
      "Epoch 448/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1285 - acc: 0.9531 - val_loss: 1.7560 - val_acc: 0.7178\n",
      "Epoch 449/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1297 - acc: 0.9527 - val_loss: 1.8393 - val_acc: 0.7169\n",
      "Epoch 450/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1291 - acc: 0.9531 - val_loss: 1.8267 - val_acc: 0.6996\n",
      "Epoch 451/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1263 - acc: 0.9542 - val_loss: 1.8440 - val_acc: 0.7042\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1278 - acc: 0.9537 - val_loss: 1.6280 - val_acc: 0.7127\n",
      "Epoch 453/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1286 - acc: 0.9536 - val_loss: 1.9307 - val_acc: 0.7082\n",
      "Epoch 454/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1275 - acc: 0.9537 - val_loss: 1.6819 - val_acc: 0.7105\n",
      "Epoch 455/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1287 - acc: 0.9537 - val_loss: 1.8536 - val_acc: 0.7135\n",
      "Epoch 456/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1297 - acc: 0.9523 - val_loss: 1.7497 - val_acc: 0.7183\n",
      "Epoch 457/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1307 - acc: 0.9528 - val_loss: 1.9873 - val_acc: 0.6878\n",
      "Epoch 458/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1281 - acc: 0.9533 - val_loss: 1.9177 - val_acc: 0.7006\n",
      "Epoch 459/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1285 - acc: 0.9532 - val_loss: 1.9966 - val_acc: 0.6922\n",
      "Epoch 460/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1272 - acc: 0.9541 - val_loss: 1.8401 - val_acc: 0.7118\n",
      "Epoch 461/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1268 - acc: 0.9536 - val_loss: 1.7015 - val_acc: 0.7214\n",
      "Epoch 462/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1275 - acc: 0.9539 - val_loss: 1.7525 - val_acc: 0.7137\n",
      "Epoch 463/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1246 - acc: 0.9546 - val_loss: 1.9415 - val_acc: 0.7085\n",
      "Epoch 464/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1231 - acc: 0.9552 - val_loss: 1.7135 - val_acc: 0.7218\n",
      "Epoch 465/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1272 - acc: 0.9535 - val_loss: 1.8208 - val_acc: 0.7155\n",
      "Epoch 466/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1247 - acc: 0.9537 - val_loss: 1.8372 - val_acc: 0.7144\n",
      "Epoch 467/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1270 - acc: 0.9534 - val_loss: 1.6616 - val_acc: 0.7146\n",
      "Epoch 468/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1231 - acc: 0.9550 - val_loss: 1.8815 - val_acc: 0.7174\n",
      "Epoch 469/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1261 - acc: 0.9535 - val_loss: 1.9409 - val_acc: 0.7004\n",
      "Epoch 470/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1261 - acc: 0.9536 - val_loss: 1.6725 - val_acc: 0.7214\n",
      "Epoch 471/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1243 - acc: 0.9550 - val_loss: 1.7966 - val_acc: 0.7177\n",
      "Epoch 472/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1264 - acc: 0.9539 - val_loss: 1.7937 - val_acc: 0.6986\n",
      "Epoch 473/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.1247 - acc: 0.9548 - val_loss: 1.6969 - val_acc: 0.7234\n",
      "Epoch 474/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1243 - acc: 0.9549 - val_loss: 1.5748 - val_acc: 0.7307\n",
      "Epoch 475/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1242 - acc: 0.9546 - val_loss: 1.6974 - val_acc: 0.7077\n",
      "Epoch 476/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1278 - acc: 0.9538 - val_loss: 1.8018 - val_acc: 0.7034\n",
      "Epoch 477/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1236 - acc: 0.9552 - val_loss: 1.5824 - val_acc: 0.7237\n",
      "Epoch 478/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1223 - acc: 0.9556 - val_loss: 1.7832 - val_acc: 0.7184\n",
      "Epoch 479/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1254 - acc: 0.9536 - val_loss: 1.7789 - val_acc: 0.6989\n",
      "Epoch 480/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1247 - acc: 0.9544 - val_loss: 1.8669 - val_acc: 0.7027\n",
      "Epoch 481/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1253 - acc: 0.9542 - val_loss: 1.6767 - val_acc: 0.7010\n",
      "Epoch 482/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1255 - acc: 0.9542 - val_loss: 1.6550 - val_acc: 0.7213\n",
      "Epoch 483/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1249 - acc: 0.9542 - val_loss: 1.6682 - val_acc: 0.7218\n",
      "Epoch 484/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1277 - acc: 0.9544 - val_loss: 1.6618 - val_acc: 0.7179\n",
      "Epoch 485/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1221 - acc: 0.9558 - val_loss: 1.7208 - val_acc: 0.7247\n",
      "Epoch 486/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1229 - acc: 0.9558 - val_loss: 1.5697 - val_acc: 0.7265\n",
      "Epoch 487/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1261 - acc: 0.9540 - val_loss: 1.6710 - val_acc: 0.7095\n",
      "Epoch 488/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1258 - acc: 0.9542 - val_loss: 1.8081 - val_acc: 0.7172\n",
      "Epoch 489/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1222 - acc: 0.9551 - val_loss: 1.8041 - val_acc: 0.7017\n",
      "Epoch 490/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1225 - acc: 0.9555 - val_loss: 1.7715 - val_acc: 0.7198\n",
      "Epoch 491/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1253 - acc: 0.9538 - val_loss: 1.9286 - val_acc: 0.7123\n",
      "Epoch 492/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1218 - acc: 0.9560 - val_loss: 1.8728 - val_acc: 0.6907\n",
      "Epoch 493/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1232 - acc: 0.9556 - val_loss: 1.6545 - val_acc: 0.7224\n",
      "Epoch 494/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1240 - acc: 0.9551 - val_loss: 1.9791 - val_acc: 0.6946\n",
      "Epoch 495/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1236 - acc: 0.9552 - val_loss: 1.6840 - val_acc: 0.7238\n",
      "Epoch 496/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1202 - acc: 0.9558 - val_loss: 1.9445 - val_acc: 0.7071\n",
      "Epoch 497/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1249 - acc: 0.9542 - val_loss: 1.7136 - val_acc: 0.7234\n",
      "Epoch 498/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1212 - acc: 0.9558 - val_loss: 2.1793 - val_acc: 0.6889\n",
      "Epoch 499/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1242 - acc: 0.9549 - val_loss: 1.6510 - val_acc: 0.7199\n",
      "Epoch 500/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1233 - acc: 0.9546 - val_loss: 1.7426 - val_acc: 0.7220\n",
      "Epoch 501/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1219 - acc: 0.9557 - val_loss: 1.6690 - val_acc: 0.7248\n",
      "Epoch 502/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1233 - acc: 0.9544 - val_loss: 1.8657 - val_acc: 0.7007\n",
      "Epoch 503/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1224 - acc: 0.9556 - val_loss: 1.6926 - val_acc: 0.7247\n",
      "Epoch 504/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1238 - acc: 0.9551 - val_loss: 1.9396 - val_acc: 0.6860\n",
      "Epoch 505/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1227 - acc: 0.9552 - val_loss: 1.7833 - val_acc: 0.7189\n",
      "Epoch 506/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1215 - acc: 0.9560 - val_loss: 1.7382 - val_acc: 0.7216\n",
      "Epoch 507/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1204 - acc: 0.9564 - val_loss: 1.6089 - val_acc: 0.7211\n",
      "Epoch 508/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1216 - acc: 0.9557 - val_loss: 1.6285 - val_acc: 0.7245\n",
      "Epoch 509/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1227 - acc: 0.9555 - val_loss: 1.9375 - val_acc: 0.6969\n",
      "Epoch 510/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1219 - acc: 0.9556 - val_loss: 1.5695 - val_acc: 0.7210\n",
      "Epoch 511/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1193 - acc: 0.9569 - val_loss: 1.7822 - val_acc: 0.7220\n",
      "Epoch 512/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1246 - acc: 0.9549 - val_loss: 1.8135 - val_acc: 0.7001\n",
      "Epoch 513/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1213 - acc: 0.9559 - val_loss: 1.8179 - val_acc: 0.7116\n",
      "Epoch 514/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1229 - acc: 0.9550 - val_loss: 1.5983 - val_acc: 0.7144\n",
      "Epoch 515/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1210 - acc: 0.9558 - val_loss: 1.7133 - val_acc: 0.7268\n",
      "Epoch 516/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1221 - acc: 0.9557 - val_loss: 2.0975 - val_acc: 0.6994\n",
      "Epoch 517/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1223 - acc: 0.9557 - val_loss: 1.9169 - val_acc: 0.7139\n",
      "Epoch 518/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1209 - acc: 0.9561 - val_loss: 1.9378 - val_acc: 0.7115\n",
      "Epoch 519/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1197 - acc: 0.9562 - val_loss: 1.7914 - val_acc: 0.7089\n",
      "Epoch 520/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1208 - acc: 0.9565 - val_loss: 2.1270 - val_acc: 0.6937\n",
      "Epoch 521/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1219 - acc: 0.9558 - val_loss: 1.6772 - val_acc: 0.7247\n",
      "Epoch 522/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1217 - acc: 0.9551 - val_loss: 1.8888 - val_acc: 0.7054\n",
      "Epoch 523/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1216 - acc: 0.9558 - val_loss: 1.9114 - val_acc: 0.7176\n",
      "Epoch 524/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1186 - acc: 0.9567 - val_loss: 1.8171 - val_acc: 0.7137\n",
      "Epoch 525/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1198 - acc: 0.9560 - val_loss: 1.8535 - val_acc: 0.7129\n",
      "Epoch 526/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1212 - acc: 0.9555 - val_loss: 1.7047 - val_acc: 0.7203\n",
      "Epoch 527/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1219 - acc: 0.9553 - val_loss: 1.9694 - val_acc: 0.7064\n",
      "Epoch 528/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1226 - acc: 0.9557 - val_loss: 1.8601 - val_acc: 0.7168\n",
      "Epoch 529/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1212 - acc: 0.9558 - val_loss: 1.7764 - val_acc: 0.7146\n",
      "Epoch 530/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1194 - acc: 0.9564 - val_loss: 1.6975 - val_acc: 0.7177\n",
      "Epoch 531/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1206 - acc: 0.9561 - val_loss: 1.8278 - val_acc: 0.7182\n",
      "Epoch 532/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1187 - acc: 0.9568 - val_loss: 1.9783 - val_acc: 0.7026\n",
      "Epoch 533/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1224 - acc: 0.9552 - val_loss: 1.7830 - val_acc: 0.7123\n",
      "Epoch 534/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1180 - acc: 0.9569 - val_loss: 1.7116 - val_acc: 0.7168\n",
      "Epoch 535/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1211 - acc: 0.9559 - val_loss: 1.6308 - val_acc: 0.7261\n",
      "Epoch 536/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1197 - acc: 0.9560 - val_loss: 1.7520 - val_acc: 0.7208\n",
      "Epoch 537/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1211 - acc: 0.9566 - val_loss: 1.8708 - val_acc: 0.7149\n",
      "Epoch 538/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1207 - acc: 0.9563 - val_loss: 1.7513 - val_acc: 0.7100\n",
      "Epoch 539/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1171 - acc: 0.9573 - val_loss: 2.1102 - val_acc: 0.6898\n",
      "Epoch 540/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1167 - acc: 0.9573 - val_loss: 1.7971 - val_acc: 0.7120\n",
      "Epoch 541/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1207 - acc: 0.9556 - val_loss: 2.0760 - val_acc: 0.7001\n",
      "Epoch 542/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1205 - acc: 0.9562 - val_loss: 1.6816 - val_acc: 0.7139\n",
      "Epoch 543/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1194 - acc: 0.9565 - val_loss: 1.6661 - val_acc: 0.7225\n",
      "Epoch 544/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1204 - acc: 0.9571 - val_loss: 1.7793 - val_acc: 0.7281\n",
      "Epoch 545/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1180 - acc: 0.9578 - val_loss: 1.8788 - val_acc: 0.7063\n",
      "Epoch 546/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1172 - acc: 0.9569 - val_loss: 1.6840 - val_acc: 0.7301\n",
      "Epoch 547/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1160 - acc: 0.9581 - val_loss: 1.9771 - val_acc: 0.7130\n",
      "Epoch 548/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1193 - acc: 0.9565 - val_loss: 1.7176 - val_acc: 0.7254\n",
      "Epoch 549/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1186 - acc: 0.9566 - val_loss: 2.0078 - val_acc: 0.6956\n",
      "Epoch 550/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1187 - acc: 0.9573 - val_loss: 1.6771 - val_acc: 0.7144\n",
      "Epoch 551/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1174 - acc: 0.9569 - val_loss: 2.1121 - val_acc: 0.6869\n",
      "Epoch 552/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1160 - acc: 0.9581 - val_loss: 1.8652 - val_acc: 0.7144\n",
      "Epoch 553/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1204 - acc: 0.9561 - val_loss: 1.8259 - val_acc: 0.7088\n",
      "Epoch 554/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1189 - acc: 0.9571 - val_loss: 1.6880 - val_acc: 0.7185\n",
      "Epoch 555/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1198 - acc: 0.9555 - val_loss: 2.0804 - val_acc: 0.6992\n",
      "Epoch 556/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1207 - acc: 0.9563 - val_loss: 1.6384 - val_acc: 0.7309\n",
      "Epoch 557/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1176 - acc: 0.9568 - val_loss: 1.9103 - val_acc: 0.7155\n",
      "Epoch 558/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1188 - acc: 0.9571 - val_loss: 1.8162 - val_acc: 0.7244\n",
      "Epoch 559/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1155 - acc: 0.9583 - val_loss: 1.8227 - val_acc: 0.7175\n",
      "Epoch 560/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1177 - acc: 0.9576 - val_loss: 1.9342 - val_acc: 0.7175\n",
      "Epoch 561/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1171 - acc: 0.9578 - val_loss: 1.9888 - val_acc: 0.7046\n",
      "Epoch 562/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1194 - acc: 0.9571 - val_loss: 1.7452 - val_acc: 0.7282\n",
      "Epoch 563/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1202 - acc: 0.9563 - val_loss: 2.0161 - val_acc: 0.7043\n",
      "Epoch 564/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1197 - acc: 0.9557 - val_loss: 1.7524 - val_acc: 0.7210\n",
      "Epoch 565/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1184 - acc: 0.9564 - val_loss: 1.7553 - val_acc: 0.7194\n",
      "Epoch 566/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1208 - acc: 0.9557 - val_loss: 1.6976 - val_acc: 0.7208\n",
      "Epoch 567/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1179 - acc: 0.9565 - val_loss: 1.6991 - val_acc: 0.7192\n",
      "Epoch 568/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1164 - acc: 0.9578 - val_loss: 1.6870 - val_acc: 0.7195\n",
      "Epoch 569/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1153 - acc: 0.9582 - val_loss: 1.7597 - val_acc: 0.7192\n",
      "Epoch 570/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1193 - acc: 0.9570 - val_loss: 1.8057 - val_acc: 0.7205\n",
      "Epoch 571/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1174 - acc: 0.9575 - val_loss: 1.7664 - val_acc: 0.7206\n",
      "Epoch 572/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1188 - acc: 0.9568 - val_loss: 1.7711 - val_acc: 0.7065\n",
      "Epoch 573/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1187 - acc: 0.9563 - val_loss: 1.7125 - val_acc: 0.7219\n",
      "Epoch 574/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1168 - acc: 0.9580 - val_loss: 1.8339 - val_acc: 0.7177\n",
      "Epoch 575/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1165 - acc: 0.9571 - val_loss: 1.8050 - val_acc: 0.7079\n",
      "Epoch 576/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1148 - acc: 0.9576 - val_loss: 1.7867 - val_acc: 0.6999\n",
      "Epoch 577/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1176 - acc: 0.9572 - val_loss: 2.0014 - val_acc: 0.6994\n",
      "Epoch 578/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1186 - acc: 0.9572 - val_loss: 1.8625 - val_acc: 0.7096\n",
      "Epoch 579/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1153 - acc: 0.9580 - val_loss: 1.8017 - val_acc: 0.7201\n",
      "Epoch 580/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1157 - acc: 0.9583 - val_loss: 1.8028 - val_acc: 0.7163\n",
      "Epoch 581/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1169 - acc: 0.9581 - val_loss: 1.9419 - val_acc: 0.7101\n",
      "Epoch 582/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1166 - acc: 0.9574 - val_loss: 1.7524 - val_acc: 0.7161\n",
      "Epoch 583/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1142 - acc: 0.9586 - val_loss: 1.7254 - val_acc: 0.7213\n",
      "Epoch 584/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1174 - acc: 0.9580 - val_loss: 1.8499 - val_acc: 0.7099\n",
      "Epoch 585/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1186 - acc: 0.9576 - val_loss: 1.7447 - val_acc: 0.7154\n",
      "Epoch 586/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1134 - acc: 0.9593 - val_loss: 1.8154 - val_acc: 0.7114\n",
      "Epoch 587/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1148 - acc: 0.9585 - val_loss: 1.6255 - val_acc: 0.7258\n",
      "Epoch 588/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1147 - acc: 0.9581 - val_loss: 1.7316 - val_acc: 0.7218\n",
      "Epoch 589/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1169 - acc: 0.9576 - val_loss: 1.9786 - val_acc: 0.7096\n",
      "Epoch 590/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1163 - acc: 0.9579 - val_loss: 1.8569 - val_acc: 0.7156\n",
      "Epoch 591/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9580 - val_loss: 1.7611 - val_acc: 0.7222\n",
      "Epoch 592/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1171 - acc: 0.9571 - val_loss: 1.9159 - val_acc: 0.6911\n",
      "Epoch 593/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1117 - acc: 0.9597 - val_loss: 1.8355 - val_acc: 0.7207\n",
      "Epoch 594/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1147 - acc: 0.9584 - val_loss: 1.8108 - val_acc: 0.7136\n",
      "Epoch 595/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1146 - acc: 0.9584 - val_loss: 1.8584 - val_acc: 0.7165\n",
      "Epoch 596/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1146 - acc: 0.9583 - val_loss: 2.0209 - val_acc: 0.7049\n",
      "Epoch 597/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1134 - acc: 0.9584 - val_loss: 1.9825 - val_acc: 0.6994\n",
      "Epoch 598/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9585 - val_loss: 1.6869 - val_acc: 0.7242\n",
      "Epoch 599/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1156 - acc: 0.9576 - val_loss: 1.8361 - val_acc: 0.7265\n",
      "Epoch 600/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1169 - acc: 0.9579 - val_loss: 1.7141 - val_acc: 0.7218\n",
      "Epoch 601/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1150 - acc: 0.9590 - val_loss: 1.9203 - val_acc: 0.7130\n",
      "Epoch 602/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1149 - acc: 0.9589 - val_loss: 1.8388 - val_acc: 0.7144\n",
      "Epoch 603/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1136 - acc: 0.9592 - val_loss: 2.0454 - val_acc: 0.7061\n",
      "Epoch 604/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1169 - acc: 0.9578 - val_loss: 2.0023 - val_acc: 0.7046\n",
      "Epoch 605/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1151 - acc: 0.9577 - val_loss: 1.7189 - val_acc: 0.7275\n",
      "Epoch 606/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1136 - acc: 0.9589 - val_loss: 1.7595 - val_acc: 0.7179\n",
      "Epoch 607/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1162 - acc: 0.9585 - val_loss: 1.8620 - val_acc: 0.7157\n",
      "Epoch 608/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1151 - acc: 0.9586 - val_loss: 1.9039 - val_acc: 0.7102\n",
      "Epoch 609/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1164 - acc: 0.9575 - val_loss: 1.9453 - val_acc: 0.7054\n",
      "Epoch 610/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1151 - acc: 0.9579 - val_loss: 1.8173 - val_acc: 0.7101\n",
      "Epoch 611/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1147 - acc: 0.9582 - val_loss: 2.0330 - val_acc: 0.6979\n",
      "Epoch 612/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1172 - acc: 0.9581 - val_loss: 1.6386 - val_acc: 0.7238\n",
      "Epoch 613/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1137 - acc: 0.9582 - val_loss: 1.6462 - val_acc: 0.7264\n",
      "Epoch 614/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1125 - acc: 0.9593 - val_loss: 1.6575 - val_acc: 0.7275\n",
      "Epoch 615/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1112 - acc: 0.9596 - val_loss: 1.9014 - val_acc: 0.7089\n",
      "Epoch 616/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1126 - acc: 0.9587 - val_loss: 2.0189 - val_acc: 0.7070\n",
      "Epoch 617/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1148 - acc: 0.9578 - val_loss: 1.6810 - val_acc: 0.7199\n",
      "Epoch 618/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1134 - acc: 0.9588 - val_loss: 1.7526 - val_acc: 0.7236\n",
      "Epoch 619/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1137 - acc: 0.9590 - val_loss: 1.8291 - val_acc: 0.7173\n",
      "Epoch 620/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9587 - val_loss: 1.8404 - val_acc: 0.7155\n",
      "Epoch 621/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1119 - acc: 0.9593 - val_loss: 1.7160 - val_acc: 0.7246\n",
      "Epoch 622/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1161 - acc: 0.9576 - val_loss: 1.8073 - val_acc: 0.7195\n",
      "Epoch 623/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1127 - acc: 0.9591 - val_loss: 1.8084 - val_acc: 0.7124\n",
      "Epoch 624/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1167 - acc: 0.9573 - val_loss: 1.8323 - val_acc: 0.7172\n",
      "Epoch 625/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1135 - acc: 0.9582 - val_loss: 1.7551 - val_acc: 0.7257\n",
      "Epoch 626/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1118 - acc: 0.9597 - val_loss: 1.7742 - val_acc: 0.7060\n",
      "Epoch 627/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1146 - acc: 0.9585 - val_loss: 2.1263 - val_acc: 0.6985\n",
      "Epoch 628/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1153 - acc: 0.9586 - val_loss: 1.9588 - val_acc: 0.7170\n",
      "Epoch 629/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1150 - acc: 0.9584 - val_loss: 1.8875 - val_acc: 0.7144\n",
      "Epoch 630/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1127 - acc: 0.9591 - val_loss: 1.8092 - val_acc: 0.7201\n",
      "Epoch 631/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1126 - acc: 0.9592 - val_loss: 1.6643 - val_acc: 0.7241\n",
      "Epoch 632/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1129 - acc: 0.9595 - val_loss: 1.6996 - val_acc: 0.7225\n",
      "Epoch 633/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1115 - acc: 0.9595 - val_loss: 1.7503 - val_acc: 0.7265\n",
      "Epoch 634/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1124 - acc: 0.9592 - val_loss: 1.8077 - val_acc: 0.7241\n",
      "Epoch 635/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1128 - acc: 0.9591 - val_loss: 2.0965 - val_acc: 0.7070\n",
      "Epoch 636/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1150 - acc: 0.9584 - val_loss: 1.9164 - val_acc: 0.6979\n",
      "Epoch 637/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1102 - acc: 0.9597 - val_loss: 1.6414 - val_acc: 0.7247\n",
      "Epoch 638/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1154 - acc: 0.9579 - val_loss: 1.7931 - val_acc: 0.7185\n",
      "Epoch 639/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1112 - acc: 0.9594 - val_loss: 1.8086 - val_acc: 0.7126\n",
      "Epoch 640/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1143 - acc: 0.9586 - val_loss: 2.0298 - val_acc: 0.7087\n",
      "Epoch 641/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1153 - acc: 0.9584 - val_loss: 1.7065 - val_acc: 0.7191\n",
      "Epoch 642/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9592 - val_loss: 1.7886 - val_acc: 0.7235\n",
      "Epoch 643/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1152 - acc: 0.9582 - val_loss: 1.9373 - val_acc: 0.7103\n",
      "Epoch 644/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9591 - val_loss: 2.0920 - val_acc: 0.7034\n",
      "Epoch 645/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1095 - acc: 0.9602 - val_loss: 1.9118 - val_acc: 0.7206\n",
      "Epoch 646/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1129 - acc: 0.9589 - val_loss: 1.6964 - val_acc: 0.7235\n",
      "Epoch 647/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1124 - acc: 0.9588 - val_loss: 2.0348 - val_acc: 0.7072\n",
      "Epoch 648/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1136 - acc: 0.9586 - val_loss: 1.8655 - val_acc: 0.7130\n",
      "Epoch 649/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1124 - acc: 0.9591 - val_loss: 1.8852 - val_acc: 0.7144\n",
      "Epoch 650/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1118 - acc: 0.9595 - val_loss: 1.7274 - val_acc: 0.7284\n",
      "Epoch 651/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1144 - acc: 0.9588 - val_loss: 1.7458 - val_acc: 0.7274\n",
      "Epoch 652/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1119 - acc: 0.9590 - val_loss: 1.6790 - val_acc: 0.7282\n",
      "Epoch 653/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1133 - acc: 0.9585 - val_loss: 1.7916 - val_acc: 0.7273\n",
      "Epoch 654/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1130 - acc: 0.9591 - val_loss: 1.7476 - val_acc: 0.7246\n",
      "Epoch 655/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1107 - acc: 0.9603 - val_loss: 1.9348 - val_acc: 0.7058\n",
      "Epoch 656/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1105 - acc: 0.9598 - val_loss: 1.6514 - val_acc: 0.7172\n",
      "Epoch 657/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1080 - acc: 0.9614 - val_loss: 1.8681 - val_acc: 0.7119\n",
      "Epoch 658/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1091 - acc: 0.9604 - val_loss: 1.6670 - val_acc: 0.7275\n",
      "Epoch 659/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1127 - acc: 0.9589 - val_loss: 1.5942 - val_acc: 0.7320\n",
      "Epoch 660/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1102 - acc: 0.9598 - val_loss: 2.2498 - val_acc: 0.7019\n",
      "Epoch 661/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9592 - val_loss: 1.7328 - val_acc: 0.7325\n",
      "Epoch 662/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1128 - acc: 0.9587 - val_loss: 1.8439 - val_acc: 0.7187\n",
      "Epoch 663/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1089 - acc: 0.9602 - val_loss: 2.2056 - val_acc: 0.6958\n",
      "Epoch 664/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1117 - acc: 0.9599 - val_loss: 1.7307 - val_acc: 0.7289\n",
      "Epoch 665/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1088 - acc: 0.9603 - val_loss: 1.9803 - val_acc: 0.6925\n",
      "Epoch 666/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1133 - acc: 0.9592 - val_loss: 1.9638 - val_acc: 0.7088\n",
      "Epoch 667/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9603 - val_loss: 1.9149 - val_acc: 0.7111\n",
      "Epoch 668/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1100 - acc: 0.9603 - val_loss: 1.8469 - val_acc: 0.7113\n",
      "Epoch 669/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1115 - acc: 0.9595 - val_loss: 2.0144 - val_acc: 0.7080\n",
      "Epoch 670/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1118 - acc: 0.9597 - val_loss: 1.8621 - val_acc: 0.7162\n",
      "Epoch 671/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1101 - acc: 0.9597 - val_loss: 1.8569 - val_acc: 0.7124\n",
      "Epoch 672/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 0.1119 - acc: 0.9592 - val_loss: 1.7414 - val_acc: 0.7270\n",
      "Epoch 673/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1080 - acc: 0.9602 - val_loss: 1.9082 - val_acc: 0.7204\n",
      "Epoch 674/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1109 - acc: 0.9602 - val_loss: 1.7702 - val_acc: 0.7072\n",
      "Epoch 675/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1094 - acc: 0.9604 - val_loss: 1.8103 - val_acc: 0.7134\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1114 - acc: 0.9594 - val_loss: 1.7915 - val_acc: 0.7161\n",
      "Epoch 677/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1102 - acc: 0.9606 - val_loss: 1.7711 - val_acc: 0.7198\n",
      "Epoch 678/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1113 - acc: 0.9599 - val_loss: 2.0475 - val_acc: 0.7044\n",
      "Epoch 679/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1087 - acc: 0.9600 - val_loss: 1.6310 - val_acc: 0.7299\n",
      "Epoch 680/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1092 - acc: 0.9607 - val_loss: 1.7937 - val_acc: 0.7203\n",
      "Epoch 681/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1100 - acc: 0.9602 - val_loss: 1.8314 - val_acc: 0.7120\n",
      "Epoch 682/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1105 - acc: 0.9597 - val_loss: 2.0062 - val_acc: 0.7106\n",
      "Epoch 683/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1099 - acc: 0.9598 - val_loss: 1.7153 - val_acc: 0.7280\n",
      "Epoch 684/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1109 - acc: 0.9593 - val_loss: 1.9913 - val_acc: 0.6990\n",
      "Epoch 685/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1087 - acc: 0.9603 - val_loss: 1.8869 - val_acc: 0.7178\n",
      "Epoch 686/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1111 - acc: 0.9596 - val_loss: 2.0124 - val_acc: 0.7151\n",
      "Epoch 687/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1106 - acc: 0.9596 - val_loss: 1.9163 - val_acc: 0.7155\n",
      "Epoch 688/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1081 - acc: 0.9612 - val_loss: 1.7619 - val_acc: 0.7238\n",
      "Epoch 689/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1094 - acc: 0.9600 - val_loss: 1.9887 - val_acc: 0.7135\n",
      "Epoch 690/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1097 - acc: 0.9596 - val_loss: 1.8355 - val_acc: 0.7185\n",
      "Epoch 691/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1100 - acc: 0.9610 - val_loss: 1.8399 - val_acc: 0.7206\n",
      "Epoch 692/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1101 - acc: 0.9605 - val_loss: 1.8019 - val_acc: 0.7197\n",
      "Epoch 693/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1099 - acc: 0.9601 - val_loss: 1.7766 - val_acc: 0.7215\n",
      "Epoch 694/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1093 - acc: 0.9604 - val_loss: 1.9336 - val_acc: 0.7210\n",
      "Epoch 695/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1113 - acc: 0.9598 - val_loss: 2.0397 - val_acc: 0.6992\n",
      "Epoch 696/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9599 - val_loss: 2.2115 - val_acc: 0.6898\n",
      "Epoch 697/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1091 - acc: 0.9601 - val_loss: 1.7013 - val_acc: 0.7234\n",
      "Epoch 698/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1090 - acc: 0.9602 - val_loss: 1.9265 - val_acc: 0.7067\n",
      "Epoch 699/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1065 - acc: 0.9611 - val_loss: 1.7165 - val_acc: 0.7254\n",
      "Epoch 700/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1099 - acc: 0.9596 - val_loss: 1.9486 - val_acc: 0.7111\n",
      "Epoch 701/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1090 - acc: 0.9602 - val_loss: 1.9381 - val_acc: 0.7171\n",
      "Epoch 702/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1080 - acc: 0.9607 - val_loss: 2.0280 - val_acc: 0.7118\n",
      "Epoch 703/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1113 - acc: 0.9597 - val_loss: 1.9624 - val_acc: 0.7113\n",
      "Epoch 704/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1071 - acc: 0.9612 - val_loss: 1.7792 - val_acc: 0.7276\n",
      "Epoch 705/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1081 - acc: 0.9603 - val_loss: 1.8352 - val_acc: 0.7197\n",
      "Epoch 706/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1102 - acc: 0.9598 - val_loss: 1.8122 - val_acc: 0.7173\n",
      "Epoch 707/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1088 - acc: 0.9606 - val_loss: 1.8409 - val_acc: 0.7209\n",
      "Epoch 708/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1083 - acc: 0.9608 - val_loss: 1.9386 - val_acc: 0.7144\n",
      "Epoch 709/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1099 - acc: 0.9596 - val_loss: 1.8177 - val_acc: 0.7188\n",
      "Epoch 710/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1083 - acc: 0.9613 - val_loss: 1.8915 - val_acc: 0.7092\n",
      "Epoch 711/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1097 - acc: 0.9603 - val_loss: 1.9586 - val_acc: 0.7125\n",
      "Epoch 712/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1065 - acc: 0.9612 - val_loss: 1.7714 - val_acc: 0.7244\n",
      "Epoch 713/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1081 - acc: 0.9605 - val_loss: 1.7148 - val_acc: 0.7244\n",
      "Epoch 714/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1079 - acc: 0.9609 - val_loss: 1.8256 - val_acc: 0.7250\n",
      "Epoch 715/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1104 - acc: 0.9600 - val_loss: 1.8501 - val_acc: 0.7139\n",
      "Epoch 716/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1079 - acc: 0.9620 - val_loss: 2.2869 - val_acc: 0.6815\n",
      "Epoch 717/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1046 - acc: 0.9625 - val_loss: 1.7685 - val_acc: 0.7213\n",
      "Epoch 718/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1077 - acc: 0.9612 - val_loss: 1.7701 - val_acc: 0.7249\n",
      "Epoch 719/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1073 - acc: 0.9614 - val_loss: 1.9139 - val_acc: 0.7077\n",
      "Epoch 720/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1115 - acc: 0.9585 - val_loss: 1.8786 - val_acc: 0.7165\n",
      "Epoch 721/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1081 - acc: 0.9606 - val_loss: 1.7730 - val_acc: 0.7243\n",
      "Epoch 722/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1074 - acc: 0.9610 - val_loss: 1.7140 - val_acc: 0.7341\n",
      "Epoch 723/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1086 - acc: 0.9607 - val_loss: 1.7379 - val_acc: 0.7270\n",
      "Epoch 724/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1079 - acc: 0.9609 - val_loss: 1.6818 - val_acc: 0.7327\n",
      "Epoch 725/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1063 - acc: 0.9614 - val_loss: 1.7397 - val_acc: 0.7292\n",
      "Epoch 726/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1076 - acc: 0.9613 - val_loss: 1.8913 - val_acc: 0.7103\n",
      "Epoch 727/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1073 - acc: 0.9611 - val_loss: 1.9123 - val_acc: 0.7076\n",
      "Epoch 728/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1050 - acc: 0.9623 - val_loss: 1.8943 - val_acc: 0.7103\n",
      "Epoch 729/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1064 - acc: 0.9613 - val_loss: 1.8194 - val_acc: 0.7275\n",
      "Epoch 730/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1064 - acc: 0.9627 - val_loss: 1.9760 - val_acc: 0.6994\n",
      "Epoch 731/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1087 - acc: 0.9607 - val_loss: 1.6712 - val_acc: 0.7341\n",
      "Epoch 732/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1108 - acc: 0.9600 - val_loss: 1.6643 - val_acc: 0.7361\n",
      "Epoch 733/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1071 - acc: 0.9610 - val_loss: 1.9576 - val_acc: 0.7156\n",
      "Epoch 734/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1096 - acc: 0.9610 - val_loss: 2.0067 - val_acc: 0.7008\n",
      "Epoch 735/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1084 - acc: 0.9613 - val_loss: 1.7862 - val_acc: 0.7189\n",
      "Epoch 736/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1042 - acc: 0.9626 - val_loss: 1.7357 - val_acc: 0.7201\n",
      "Epoch 737/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1078 - acc: 0.9608 - val_loss: 1.8729 - val_acc: 0.7247\n",
      "Epoch 738/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1041 - acc: 0.9625 - val_loss: 1.6828 - val_acc: 0.7275\n",
      "Epoch 739/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1067 - acc: 0.9618 - val_loss: 1.8242 - val_acc: 0.7269\n",
      "Epoch 740/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9614 - val_loss: 1.7853 - val_acc: 0.7190\n",
      "Epoch 741/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1058 - acc: 0.9618 - val_loss: 1.7182 - val_acc: 0.7279\n",
      "Epoch 742/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1075 - acc: 0.9611 - val_loss: 1.7948 - val_acc: 0.7164\n",
      "Epoch 743/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1028 - acc: 0.9629 - val_loss: 1.9328 - val_acc: 0.7196\n",
      "Epoch 744/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9614 - val_loss: 2.0883 - val_acc: 0.7083\n",
      "Epoch 745/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1084 - acc: 0.9608 - val_loss: 1.8867 - val_acc: 0.7125\n",
      "Epoch 746/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1058 - acc: 0.9619 - val_loss: 1.8767 - val_acc: 0.7113\n",
      "Epoch 747/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1063 - acc: 0.9617 - val_loss: 1.8493 - val_acc: 0.7146\n",
      "Epoch 748/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1065 - acc: 0.9614 - val_loss: 1.8151 - val_acc: 0.7265\n",
      "Epoch 749/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1086 - acc: 0.9615 - val_loss: 1.9582 - val_acc: 0.7094\n",
      "Epoch 750/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1076 - acc: 0.9611 - val_loss: 1.7043 - val_acc: 0.7296\n",
      "Epoch 751/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1038 - acc: 0.9619 - val_loss: 1.9244 - val_acc: 0.7152\n",
      "Epoch 752/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1037 - acc: 0.9619 - val_loss: 1.8041 - val_acc: 0.7126\n",
      "Epoch 753/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1064 - acc: 0.9610 - val_loss: 1.8613 - val_acc: 0.7213\n",
      "Epoch 754/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1073 - acc: 0.9617 - val_loss: 1.7760 - val_acc: 0.7234\n",
      "Epoch 755/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1081 - acc: 0.9612 - val_loss: 1.9461 - val_acc: 0.7187\n",
      "Epoch 756/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1051 - acc: 0.9613 - val_loss: 2.1097 - val_acc: 0.7013\n",
      "Epoch 757/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1054 - acc: 0.9614 - val_loss: 1.7624 - val_acc: 0.7309\n",
      "Epoch 758/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1053 - acc: 0.9614 - val_loss: 1.8059 - val_acc: 0.7279\n",
      "Epoch 759/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1072 - acc: 0.9607 - val_loss: 1.8236 - val_acc: 0.7244\n",
      "Epoch 760/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1046 - acc: 0.9620 - val_loss: 1.8611 - val_acc: 0.7154\n",
      "Epoch 761/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9615 - val_loss: 1.7586 - val_acc: 0.7208\n",
      "Epoch 762/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1076 - acc: 0.9616 - val_loss: 1.7573 - val_acc: 0.7199\n",
      "Epoch 763/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1042 - acc: 0.9618 - val_loss: 1.7799 - val_acc: 0.7281\n",
      "Epoch 764/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9614 - val_loss: 1.8277 - val_acc: 0.7233\n",
      "Epoch 765/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1059 - acc: 0.9615 - val_loss: 2.1092 - val_acc: 0.7088\n",
      "Epoch 766/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1054 - acc: 0.9618 - val_loss: 1.8799 - val_acc: 0.7172\n",
      "Epoch 767/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1059 - acc: 0.9615 - val_loss: 1.8238 - val_acc: 0.7144\n",
      "Epoch 768/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1069 - acc: 0.9612 - val_loss: 1.8683 - val_acc: 0.7217\n",
      "Epoch 769/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1036 - acc: 0.9624 - val_loss: 1.9182 - val_acc: 0.7156\n",
      "Epoch 770/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1054 - acc: 0.9625 - val_loss: 1.8779 - val_acc: 0.7157\n",
      "Epoch 771/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1036 - acc: 0.9629 - val_loss: 2.0127 - val_acc: 0.7044\n",
      "Epoch 772/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9615 - val_loss: 1.9808 - val_acc: 0.7061\n",
      "Epoch 773/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1061 - acc: 0.9618 - val_loss: 1.9511 - val_acc: 0.7177\n",
      "Epoch 774/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1018 - acc: 0.9629 - val_loss: 1.8890 - val_acc: 0.7189\n",
      "Epoch 775/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1034 - acc: 0.9626 - val_loss: 1.7866 - val_acc: 0.7208\n",
      "Epoch 776/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1069 - acc: 0.9612 - val_loss: 1.8926 - val_acc: 0.7067\n",
      "Epoch 777/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1071 - acc: 0.9606 - val_loss: 1.7760 - val_acc: 0.7256\n",
      "Epoch 778/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1050 - acc: 0.9618 - val_loss: 1.8233 - val_acc: 0.7310\n",
      "Epoch 779/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9620 - val_loss: 1.8998 - val_acc: 0.7148\n",
      "Epoch 780/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1027 - acc: 0.9631 - val_loss: 1.8740 - val_acc: 0.7177\n",
      "Epoch 781/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1042 - acc: 0.9620 - val_loss: 2.0162 - val_acc: 0.7177\n",
      "Epoch 782/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9618 - val_loss: 1.7602 - val_acc: 0.7197\n",
      "Epoch 783/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1056 - acc: 0.9610 - val_loss: 1.9556 - val_acc: 0.7075\n",
      "Epoch 784/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1051 - acc: 0.9618 - val_loss: 1.8681 - val_acc: 0.7193\n",
      "Epoch 785/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1057 - acc: 0.9622 - val_loss: 1.9687 - val_acc: 0.7144\n",
      "Epoch 786/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1021 - acc: 0.9626 - val_loss: 1.8227 - val_acc: 0.7239\n",
      "Epoch 787/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1061 - acc: 0.9612 - val_loss: 1.8974 - val_acc: 0.7152\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1036 - acc: 0.9621 - val_loss: 1.6982 - val_acc: 0.7313\n",
      "Epoch 789/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1038 - acc: 0.9619 - val_loss: 1.9780 - val_acc: 0.7158\n",
      "Epoch 790/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1072 - acc: 0.9614 - val_loss: 1.8919 - val_acc: 0.7196\n",
      "Epoch 791/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1039 - acc: 0.9621 - val_loss: 2.0236 - val_acc: 0.7127\n",
      "Epoch 792/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1060 - acc: 0.9617 - val_loss: 1.8570 - val_acc: 0.7128\n",
      "Epoch 793/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1009 - acc: 0.9627 - val_loss: 1.7598 - val_acc: 0.7291\n",
      "Epoch 794/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1017 - acc: 0.9627 - val_loss: 1.8077 - val_acc: 0.7213\n",
      "Epoch 795/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1044 - acc: 0.9624 - val_loss: 1.9089 - val_acc: 0.7129\n",
      "Epoch 796/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1027 - acc: 0.9629 - val_loss: 1.7500 - val_acc: 0.7293\n",
      "Epoch 797/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9621 - val_loss: 1.9677 - val_acc: 0.7148\n",
      "Epoch 798/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1015 - acc: 0.9637 - val_loss: 1.9463 - val_acc: 0.7104\n",
      "Epoch 799/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1045 - acc: 0.9615 - val_loss: 1.7554 - val_acc: 0.7130\n",
      "Epoch 800/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1013 - acc: 0.9636 - val_loss: 1.8455 - val_acc: 0.7202\n",
      "Epoch 801/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9625 - val_loss: 1.9565 - val_acc: 0.7112\n",
      "Epoch 802/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1036 - acc: 0.9619 - val_loss: 1.8133 - val_acc: 0.7235\n",
      "Epoch 803/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1030 - acc: 0.9627 - val_loss: 2.0746 - val_acc: 0.7127\n",
      "Epoch 804/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9634 - val_loss: 1.7405 - val_acc: 0.7168\n",
      "Epoch 805/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1037 - acc: 0.9625 - val_loss: 1.9208 - val_acc: 0.7125\n",
      "Epoch 806/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1020 - acc: 0.9632 - val_loss: 1.9841 - val_acc: 0.7202\n",
      "Epoch 807/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1043 - acc: 0.9623 - val_loss: 1.6949 - val_acc: 0.7211\n",
      "Epoch 808/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1041 - acc: 0.9623 - val_loss: 1.7129 - val_acc: 0.7356\n",
      "Epoch 809/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1043 - acc: 0.9620 - val_loss: 2.0169 - val_acc: 0.7098\n",
      "Epoch 810/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1013 - acc: 0.9637 - val_loss: 1.8746 - val_acc: 0.7222\n",
      "Epoch 811/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9635 - val_loss: 1.8192 - val_acc: 0.7094\n",
      "Epoch 812/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1028 - acc: 0.9627 - val_loss: 1.8541 - val_acc: 0.7165\n",
      "Epoch 813/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1025 - acc: 0.9634 - val_loss: 1.7260 - val_acc: 0.7316\n",
      "Epoch 814/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1009 - acc: 0.9635 - val_loss: 1.6927 - val_acc: 0.7335\n",
      "Epoch 815/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1026 - acc: 0.9630 - val_loss: 1.9010 - val_acc: 0.7132\n",
      "Epoch 816/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1037 - acc: 0.9624 - val_loss: 1.9721 - val_acc: 0.7137\n",
      "Epoch 817/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1050 - acc: 0.9622 - val_loss: 2.0005 - val_acc: 0.7169\n",
      "Epoch 818/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1048 - acc: 0.9622 - val_loss: 1.7675 - val_acc: 0.7251\n",
      "Epoch 819/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1017 - acc: 0.9629 - val_loss: 1.9594 - val_acc: 0.7163\n",
      "Epoch 820/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1025 - acc: 0.9630 - val_loss: 1.9293 - val_acc: 0.7107\n",
      "Epoch 821/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1026 - acc: 0.9628 - val_loss: 2.1621 - val_acc: 0.7009\n",
      "Epoch 822/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1024 - acc: 0.9628 - val_loss: 2.0627 - val_acc: 0.7108\n",
      "Epoch 823/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1060 - acc: 0.9614 - val_loss: 1.7266 - val_acc: 0.7278\n",
      "Epoch 824/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1020 - acc: 0.9630 - val_loss: 1.9715 - val_acc: 0.7058\n",
      "Epoch 825/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1042 - acc: 0.9624 - val_loss: 1.8716 - val_acc: 0.7114\n",
      "Epoch 826/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1027 - acc: 0.9624 - val_loss: 2.0147 - val_acc: 0.7138\n",
      "Epoch 827/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1037 - acc: 0.9627 - val_loss: 1.7354 - val_acc: 0.7142\n",
      "Epoch 828/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1058 - acc: 0.9616 - val_loss: 1.7647 - val_acc: 0.7097\n",
      "Epoch 829/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9638 - val_loss: 1.6698 - val_acc: 0.7281\n",
      "Epoch 830/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1003 - acc: 0.9640 - val_loss: 1.8578 - val_acc: 0.7191\n",
      "Epoch 831/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1028 - acc: 0.9631 - val_loss: 1.7507 - val_acc: 0.7275\n",
      "Epoch 832/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1014 - acc: 0.9631 - val_loss: 1.8846 - val_acc: 0.7184\n",
      "Epoch 833/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1008 - acc: 0.9636 - val_loss: 1.8498 - val_acc: 0.7185\n",
      "Epoch 834/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1011 - acc: 0.9630 - val_loss: 1.8943 - val_acc: 0.7222\n",
      "Epoch 835/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1015 - acc: 0.9634 - val_loss: 1.8047 - val_acc: 0.7173\n",
      "Epoch 836/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1024 - acc: 0.9628 - val_loss: 1.7731 - val_acc: 0.7271\n",
      "Epoch 837/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1027 - acc: 0.9628 - val_loss: 1.9423 - val_acc: 0.7299\n",
      "Epoch 838/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1043 - acc: 0.9618 - val_loss: 1.8254 - val_acc: 0.7226\n",
      "Epoch 839/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1056 - acc: 0.9616 - val_loss: 1.9003 - val_acc: 0.7215\n",
      "Epoch 840/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1014 - acc: 0.9627 - val_loss: 1.9773 - val_acc: 0.7200\n",
      "Epoch 841/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1009 - acc: 0.9632 - val_loss: 1.7568 - val_acc: 0.7283\n",
      "Epoch 842/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1043 - acc: 0.9619 - val_loss: 1.6712 - val_acc: 0.7316\n",
      "Epoch 843/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9640 - val_loss: 1.7365 - val_acc: 0.7197\n",
      "Epoch 844/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9633 - val_loss: 1.9981 - val_acc: 0.7184\n",
      "Epoch 845/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1005 - acc: 0.9641 - val_loss: 1.8891 - val_acc: 0.7205\n",
      "Epoch 846/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9646 - val_loss: 1.8060 - val_acc: 0.7265\n",
      "Epoch 847/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1009 - acc: 0.9639 - val_loss: 1.7917 - val_acc: 0.7238\n",
      "Epoch 848/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1024 - acc: 0.9627 - val_loss: 1.7704 - val_acc: 0.7229\n",
      "Epoch 849/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1024 - acc: 0.9625 - val_loss: 1.6484 - val_acc: 0.7266\n",
      "Epoch 850/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1006 - acc: 0.9635 - val_loss: 1.7525 - val_acc: 0.7249\n",
      "Epoch 851/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1016 - acc: 0.9626 - val_loss: 1.8625 - val_acc: 0.7094\n",
      "Epoch 852/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1029 - acc: 0.9629 - val_loss: 2.0516 - val_acc: 0.7031\n",
      "Epoch 853/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0998 - acc: 0.9641 - val_loss: 1.9494 - val_acc: 0.7165\n",
      "Epoch 854/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9637 - val_loss: 1.9429 - val_acc: 0.7145\n",
      "Epoch 855/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0993 - acc: 0.9638 - val_loss: 1.9338 - val_acc: 0.7175\n",
      "Epoch 856/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1018 - acc: 0.9633 - val_loss: 1.8778 - val_acc: 0.7113\n",
      "Epoch 857/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1018 - acc: 0.9635 - val_loss: 1.9859 - val_acc: 0.7070\n",
      "Epoch 858/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9633 - val_loss: 1.9103 - val_acc: 0.7196\n",
      "Epoch 859/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1014 - acc: 0.9633 - val_loss: 1.9821 - val_acc: 0.7023\n",
      "Epoch 860/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1015 - acc: 0.9629 - val_loss: 1.8402 - val_acc: 0.7199\n",
      "Epoch 861/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9647 - val_loss: 2.0096 - val_acc: 0.7275\n",
      "Epoch 862/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1034 - acc: 0.9631 - val_loss: 1.8894 - val_acc: 0.7185\n",
      "Epoch 863/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1013 - acc: 0.9629 - val_loss: 1.8641 - val_acc: 0.7302\n",
      "Epoch 864/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1005 - acc: 0.9641 - val_loss: 1.8575 - val_acc: 0.7220\n",
      "Epoch 865/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9644 - val_loss: 1.8774 - val_acc: 0.7255\n",
      "Epoch 866/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9639 - val_loss: 1.8929 - val_acc: 0.7142\n",
      "Epoch 867/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1001 - acc: 0.9637 - val_loss: 1.8270 - val_acc: 0.7168\n",
      "Epoch 868/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0998 - acc: 0.9646 - val_loss: 1.8904 - val_acc: 0.7158\n",
      "Epoch 869/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1012 - acc: 0.9634 - val_loss: 2.2145 - val_acc: 0.6967\n",
      "Epoch 870/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1031 - acc: 0.9633 - val_loss: 2.0695 - val_acc: 0.7021\n",
      "Epoch 871/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0999 - acc: 0.9643 - val_loss: 1.7765 - val_acc: 0.7303\n",
      "Epoch 872/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1016 - acc: 0.9634 - val_loss: 1.8451 - val_acc: 0.7196\n",
      "Epoch 873/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0995 - acc: 0.9640 - val_loss: 1.8565 - val_acc: 0.7203\n",
      "Epoch 874/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0995 - acc: 0.9643 - val_loss: 1.8325 - val_acc: 0.7268\n",
      "Epoch 875/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1025 - acc: 0.9632 - val_loss: 1.8955 - val_acc: 0.7182\n",
      "Epoch 876/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1019 - acc: 0.9639 - val_loss: 1.8899 - val_acc: 0.7158\n",
      "Epoch 877/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1027 - acc: 0.9641 - val_loss: 1.9138 - val_acc: 0.7251\n",
      "Epoch 878/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0992 - acc: 0.9637 - val_loss: 1.9299 - val_acc: 0.7240\n",
      "Epoch 879/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1005 - acc: 0.9640 - val_loss: 1.7380 - val_acc: 0.7277\n",
      "Epoch 880/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1012 - acc: 0.9631 - val_loss: 1.8567 - val_acc: 0.7242\n",
      "Epoch 881/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0996 - acc: 0.9639 - val_loss: 1.9236 - val_acc: 0.7156\n",
      "Epoch 882/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0997 - acc: 0.9644 - val_loss: 1.9978 - val_acc: 0.7150\n",
      "Epoch 883/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1001 - acc: 0.9638 - val_loss: 2.1294 - val_acc: 0.7080\n",
      "Epoch 884/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1013 - acc: 0.9628 - val_loss: 1.7629 - val_acc: 0.7298\n",
      "Epoch 885/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1002 - acc: 0.9645 - val_loss: 1.9613 - val_acc: 0.7188\n",
      "Epoch 886/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1024 - acc: 0.9631 - val_loss: 1.8554 - val_acc: 0.7224\n",
      "Epoch 887/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1009 - acc: 0.9635 - val_loss: 1.8368 - val_acc: 0.7237\n",
      "Epoch 888/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9646 - val_loss: 1.7882 - val_acc: 0.7228\n",
      "Epoch 889/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1001 - acc: 0.9642 - val_loss: 2.0175 - val_acc: 0.7108\n",
      "Epoch 890/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0999 - acc: 0.9645 - val_loss: 1.8764 - val_acc: 0.7127\n",
      "Epoch 891/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0983 - acc: 0.9650 - val_loss: 1.8996 - val_acc: 0.7262\n",
      "Epoch 892/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9634 - val_loss: 1.9452 - val_acc: 0.7206\n",
      "Epoch 893/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0991 - acc: 0.9640 - val_loss: 1.8380 - val_acc: 0.7173\n",
      "Epoch 894/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9647 - val_loss: 1.9655 - val_acc: 0.7070\n",
      "Epoch 895/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1008 - acc: 0.9635 - val_loss: 1.8031 - val_acc: 0.7304\n",
      "Epoch 896/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1006 - acc: 0.9638 - val_loss: 1.9234 - val_acc: 0.7112\n",
      "Epoch 897/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9637 - val_loss: 2.1872 - val_acc: 0.6994\n",
      "Epoch 898/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9645 - val_loss: 1.7493 - val_acc: 0.7342\n",
      "Epoch 899/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9644 - val_loss: 2.1427 - val_acc: 0.7017\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0963 - acc: 0.9648 - val_loss: 1.8629 - val_acc: 0.7147\n",
      "Epoch 901/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1004 - acc: 0.9636 - val_loss: 1.7186 - val_acc: 0.7263\n",
      "Epoch 902/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0984 - acc: 0.9644 - val_loss: 1.8721 - val_acc: 0.7218\n",
      "Epoch 903/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9640 - val_loss: 1.8808 - val_acc: 0.7261\n",
      "Epoch 904/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0996 - acc: 0.9637 - val_loss: 1.8727 - val_acc: 0.7211\n",
      "Epoch 905/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0974 - acc: 0.9641 - val_loss: 2.0285 - val_acc: 0.7113\n",
      "Epoch 906/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0967 - acc: 0.9650 - val_loss: 1.8539 - val_acc: 0.7255\n",
      "Epoch 907/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1006 - acc: 0.9640 - val_loss: 1.7332 - val_acc: 0.7254\n",
      "Epoch 908/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1001 - acc: 0.9633 - val_loss: 2.1650 - val_acc: 0.6979\n",
      "Epoch 909/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1015 - acc: 0.9633 - val_loss: 1.8810 - val_acc: 0.7235\n",
      "Epoch 910/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9629 - val_loss: 1.7208 - val_acc: 0.7322\n",
      "Epoch 911/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1004 - acc: 0.9640 - val_loss: 1.8824 - val_acc: 0.7277\n",
      "Epoch 912/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0975 - acc: 0.9648 - val_loss: 1.9867 - val_acc: 0.7231\n",
      "Epoch 913/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0980 - acc: 0.9651 - val_loss: 1.8111 - val_acc: 0.7335\n",
      "Epoch 914/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0990 - acc: 0.9643 - val_loss: 1.9618 - val_acc: 0.7199\n",
      "Epoch 915/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0970 - acc: 0.9645 - val_loss: 1.7620 - val_acc: 0.7196\n",
      "Epoch 916/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1007 - acc: 0.9634 - val_loss: 2.0047 - val_acc: 0.7174\n",
      "Epoch 917/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9648 - val_loss: 1.9035 - val_acc: 0.7198\n",
      "Epoch 918/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1005 - acc: 0.9636 - val_loss: 1.9370 - val_acc: 0.7204\n",
      "Epoch 919/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0983 - acc: 0.9644 - val_loss: 1.8589 - val_acc: 0.7235\n",
      "Epoch 920/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1005 - acc: 0.9634 - val_loss: 1.8599 - val_acc: 0.7168\n",
      "Epoch 921/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9640 - val_loss: 1.9779 - val_acc: 0.7208\n",
      "Epoch 922/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1012 - acc: 0.9639 - val_loss: 1.9186 - val_acc: 0.7156\n",
      "Epoch 923/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0969 - acc: 0.9648 - val_loss: 2.0238 - val_acc: 0.7127\n",
      "Epoch 924/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0957 - acc: 0.9660 - val_loss: 1.9173 - val_acc: 0.7090\n",
      "Epoch 925/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9650 - val_loss: 1.8662 - val_acc: 0.7218\n",
      "Epoch 926/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0983 - acc: 0.9644 - val_loss: 1.8893 - val_acc: 0.7249\n",
      "Epoch 927/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0984 - acc: 0.9642 - val_loss: 1.6172 - val_acc: 0.7325\n",
      "Epoch 928/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0990 - acc: 0.9641 - val_loss: 1.9205 - val_acc: 0.7182\n",
      "Epoch 929/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0987 - acc: 0.9641 - val_loss: 1.8174 - val_acc: 0.7312\n",
      "Epoch 930/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9643 - val_loss: 1.8625 - val_acc: 0.7239\n",
      "Epoch 931/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0966 - acc: 0.9654 - val_loss: 1.8890 - val_acc: 0.7217\n",
      "Epoch 932/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9641 - val_loss: 1.9334 - val_acc: 0.7255\n",
      "Epoch 933/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0957 - acc: 0.9657 - val_loss: 1.6783 - val_acc: 0.7274\n",
      "Epoch 934/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0973 - acc: 0.9652 - val_loss: 1.9378 - val_acc: 0.7196\n",
      "Epoch 935/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0984 - acc: 0.9646 - val_loss: 1.8778 - val_acc: 0.7118\n",
      "Epoch 936/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0972 - acc: 0.9646 - val_loss: 1.8899 - val_acc: 0.7285\n",
      "Epoch 937/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0979 - acc: 0.9650 - val_loss: 1.7360 - val_acc: 0.7274\n",
      "Epoch 938/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0985 - acc: 0.9645 - val_loss: 1.7700 - val_acc: 0.7329\n",
      "Epoch 939/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0961 - acc: 0.9659 - val_loss: 1.9130 - val_acc: 0.7113\n",
      "Epoch 940/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0984 - acc: 0.9639 - val_loss: 1.9173 - val_acc: 0.7173\n",
      "Epoch 941/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0998 - acc: 0.9641 - val_loss: 1.7024 - val_acc: 0.7233\n",
      "Epoch 942/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9649 - val_loss: 1.7387 - val_acc: 0.7295\n",
      "Epoch 943/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0968 - acc: 0.9651 - val_loss: 1.8708 - val_acc: 0.7227\n",
      "Epoch 944/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0991 - acc: 0.9645 - val_loss: 1.7361 - val_acc: 0.7342\n",
      "Epoch 945/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0993 - acc: 0.9638 - val_loss: 1.9374 - val_acc: 0.7222\n",
      "Epoch 946/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0982 - acc: 0.9651 - val_loss: 1.9611 - val_acc: 0.7204\n",
      "Epoch 947/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0985 - acc: 0.9640 - val_loss: 1.8700 - val_acc: 0.7190\n",
      "Epoch 948/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0950 - acc: 0.9656 - val_loss: 1.8818 - val_acc: 0.7278\n",
      "Epoch 949/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0965 - acc: 0.9654 - val_loss: 1.7727 - val_acc: 0.7242\n",
      "Epoch 950/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0987 - acc: 0.9647 - val_loss: 2.0946 - val_acc: 0.7161\n",
      "Epoch 951/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0944 - acc: 0.9662 - val_loss: 1.7862 - val_acc: 0.7228\n",
      "Epoch 952/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0971 - acc: 0.9652 - val_loss: 1.7853 - val_acc: 0.7238\n",
      "Epoch 953/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0971 - acc: 0.9647 - val_loss: 1.8223 - val_acc: 0.7287\n",
      "Epoch 954/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0984 - acc: 0.9650 - val_loss: 2.0091 - val_acc: 0.7106\n",
      "Epoch 955/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0963 - acc: 0.9658 - val_loss: 1.8562 - val_acc: 0.7258\n",
      "Epoch 956/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0999 - acc: 0.9644 - val_loss: 1.9314 - val_acc: 0.7196\n",
      "Epoch 957/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9643 - val_loss: 1.8161 - val_acc: 0.7325\n",
      "Epoch 958/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0984 - acc: 0.9645 - val_loss: 1.9647 - val_acc: 0.7223\n",
      "Epoch 959/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0989 - acc: 0.9639 - val_loss: 1.7407 - val_acc: 0.7232\n",
      "Epoch 960/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0982 - acc: 0.9645 - val_loss: 1.8536 - val_acc: 0.7129\n",
      "Epoch 961/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0952 - acc: 0.9652 - val_loss: 1.7595 - val_acc: 0.7292\n",
      "Epoch 962/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9644 - val_loss: 1.7597 - val_acc: 0.7297\n",
      "Epoch 963/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0978 - acc: 0.9646 - val_loss: 1.9206 - val_acc: 0.7185\n",
      "Epoch 964/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0959 - acc: 0.9659 - val_loss: 1.7985 - val_acc: 0.7308\n",
      "Epoch 965/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9644 - val_loss: 1.9387 - val_acc: 0.7231\n",
      "Epoch 966/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9643 - val_loss: 1.8230 - val_acc: 0.7299\n",
      "Epoch 967/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0977 - acc: 0.9647 - val_loss: 1.8054 - val_acc: 0.7260\n",
      "Epoch 968/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0950 - acc: 0.9661 - val_loss: 1.9451 - val_acc: 0.7251\n",
      "Epoch 969/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0980 - acc: 0.9643 - val_loss: 1.9206 - val_acc: 0.7266\n",
      "Epoch 970/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0975 - acc: 0.9647 - val_loss: 1.9765 - val_acc: 0.7246\n",
      "Epoch 971/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0960 - acc: 0.9650 - val_loss: 1.9394 - val_acc: 0.7233\n",
      "Epoch 972/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9637 - val_loss: 1.7865 - val_acc: 0.7295\n",
      "Epoch 973/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0966 - acc: 0.9649 - val_loss: 1.7992 - val_acc: 0.7258\n",
      "Epoch 974/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0968 - acc: 0.9648 - val_loss: 1.8528 - val_acc: 0.7227\n",
      "Epoch 975/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.0962 - acc: 0.9648 - val_loss: 1.9467 - val_acc: 0.7170\n",
      "Epoch 976/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0955 - acc: 0.9650 - val_loss: 1.9197 - val_acc: 0.7158\n",
      "Epoch 977/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0962 - acc: 0.9648 - val_loss: 1.9856 - val_acc: 0.7175\n",
      "Epoch 978/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0941 - acc: 0.9659 - val_loss: 1.7647 - val_acc: 0.7246\n",
      "Epoch 979/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0961 - acc: 0.9654 - val_loss: 1.7728 - val_acc: 0.7311\n",
      "Epoch 980/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0961 - acc: 0.9648 - val_loss: 1.9408 - val_acc: 0.7267\n",
      "Epoch 981/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0961 - acc: 0.9652 - val_loss: 1.7814 - val_acc: 0.7287\n",
      "Epoch 982/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0971 - acc: 0.9648 - val_loss: 1.7852 - val_acc: 0.7192\n",
      "Epoch 983/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0993 - acc: 0.9646 - val_loss: 1.8196 - val_acc: 0.7242\n",
      "Epoch 984/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0954 - acc: 0.9650 - val_loss: 1.8825 - val_acc: 0.7137\n",
      "Epoch 985/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0975 - acc: 0.9647 - val_loss: 1.7759 - val_acc: 0.7342\n",
      "Epoch 986/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0964 - acc: 0.9646 - val_loss: 1.8374 - val_acc: 0.7304\n",
      "Epoch 987/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0981 - acc: 0.9652 - val_loss: 1.9704 - val_acc: 0.7223\n",
      "Epoch 988/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0958 - acc: 0.9651 - val_loss: 1.7394 - val_acc: 0.7289\n",
      "Epoch 989/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0948 - acc: 0.9652 - val_loss: 1.9559 - val_acc: 0.7166\n",
      "Epoch 990/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0964 - acc: 0.9649 - val_loss: 1.8362 - val_acc: 0.7239\n",
      "Epoch 991/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0963 - acc: 0.9655 - val_loss: 1.9052 - val_acc: 0.7136\n",
      "Epoch 992/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0941 - acc: 0.9655 - val_loss: 1.8328 - val_acc: 0.7217\n",
      "Epoch 993/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0973 - acc: 0.9646 - val_loss: 1.7932 - val_acc: 0.7220\n",
      "Epoch 994/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0941 - acc: 0.9667 - val_loss: 1.8605 - val_acc: 0.7309\n",
      "Epoch 995/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0956 - acc: 0.9653 - val_loss: 1.8268 - val_acc: 0.7262\n",
      "Epoch 996/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0986 - acc: 0.9647 - val_loss: 1.8097 - val_acc: 0.7165\n",
      "Epoch 997/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0947 - acc: 0.9656 - val_loss: 1.9246 - val_acc: 0.7175\n",
      "Epoch 998/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0974 - acc: 0.9649 - val_loss: 1.9849 - val_acc: 0.7209\n",
      "Epoch 999/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0939 - acc: 0.9657 - val_loss: 1.8492 - val_acc: 0.7249\n",
      "Epoch 1000/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0952 - acc: 0.9654 - val_loss: 1.8826 - val_acc: 0.7232\n",
      "14200/14200 [==============================] - 1s 37us/sample - loss: 1.8826 - acc: 0.7232\n"
     ]
    }
   ],
   "source": [
    "run_custom_training(conf_list, x_train, y_train, x_valid, y_valid,1000, 512,model_path_prefix='5_lbls_elu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### activation relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(conf, model_weights=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(conf[0], conf[0])),\n",
    "        tf.keras.layers.Dense(conf[1], activation=tf.nn.relu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(conf[2], activation=tf.nn.relu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(conf[3]),\n",
    "        tf.keras.layers.Dense(len(labels), activation=tf.nn.softmax)\n",
    "    ])\n",
    "    if model_weights is not None:\n",
    "        print('loading pre-trained model')\n",
    "        model.load_weights(model_weights, by_name=True)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 1.3166 - acc: 0.4673 - val_loss: 1.3530 - val_acc: 0.4725\n",
      "Epoch 2/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 1.0054 - acc: 0.5860 - val_loss: 1.1953 - val_acc: 0.5296\n",
      "Epoch 3/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.9325 - acc: 0.6226 - val_loss: 1.3136 - val_acc: 0.5127\n",
      "Epoch 4/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.8785 - acc: 0.6503 - val_loss: 1.3962 - val_acc: 0.4858\n",
      "Epoch 5/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.8357 - acc: 0.6677 - val_loss: 1.1096 - val_acc: 0.5689\n",
      "Epoch 6/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.8013 - acc: 0.6853 - val_loss: 0.9448 - val_acc: 0.6262\n",
      "Epoch 7/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7765 - acc: 0.6949 - val_loss: 1.4007 - val_acc: 0.5288\n",
      "Epoch 8/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7531 - acc: 0.7050 - val_loss: 1.2480 - val_acc: 0.5514\n",
      "Epoch 9/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7274 - acc: 0.7153 - val_loss: 1.5510 - val_acc: 0.5619\n",
      "Epoch 10/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7080 - acc: 0.7238 - val_loss: 1.1229 - val_acc: 0.6094\n",
      "Epoch 11/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.6913 - acc: 0.7302 - val_loss: 1.3128 - val_acc: 0.5547\n",
      "Epoch 12/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6733 - acc: 0.7370 - val_loss: 0.9816 - val_acc: 0.6430\n",
      "Epoch 13/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6568 - acc: 0.7454 - val_loss: 1.2440 - val_acc: 0.5527\n",
      "Epoch 14/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6438 - acc: 0.7490 - val_loss: 1.0055 - val_acc: 0.6484\n",
      "Epoch 15/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6329 - acc: 0.7533 - val_loss: 1.4720 - val_acc: 0.5601\n",
      "Epoch 16/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.6196 - acc: 0.7595 - val_loss: 1.0774 - val_acc: 0.6232\n",
      "Epoch 17/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6135 - acc: 0.7633 - val_loss: 0.9925 - val_acc: 0.6497\n",
      "Epoch 18/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.6032 - acc: 0.7651 - val_loss: 0.9420 - val_acc: 0.6553\n",
      "Epoch 19/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.5914 - acc: 0.7709 - val_loss: 1.2034 - val_acc: 0.6072\n",
      "Epoch 20/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5842 - acc: 0.7741 - val_loss: 1.5394 - val_acc: 0.5422\n",
      "Epoch 21/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.5752 - acc: 0.7767 - val_loss: 1.0753 - val_acc: 0.6309\n",
      "Epoch 22/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5672 - acc: 0.7797 - val_loss: 1.3454 - val_acc: 0.6327\n",
      "Epoch 23/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.5577 - acc: 0.7843 - val_loss: 1.1614 - val_acc: 0.6249\n",
      "Epoch 24/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5537 - acc: 0.7832 - val_loss: 1.0245 - val_acc: 0.6527\n",
      "Epoch 25/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5511 - acc: 0.7858 - val_loss: 1.0798 - val_acc: 0.6501\n",
      "Epoch 26/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5448 - acc: 0.7872 - val_loss: 0.9949 - val_acc: 0.6448\n",
      "Epoch 27/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5386 - acc: 0.7891 - val_loss: 1.0076 - val_acc: 0.6683\n",
      "Epoch 28/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5310 - acc: 0.7930 - val_loss: 1.2837 - val_acc: 0.6244\n",
      "Epoch 29/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5258 - acc: 0.7947 - val_loss: 1.1268 - val_acc: 0.6501\n",
      "Epoch 30/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5234 - acc: 0.7963 - val_loss: 1.2503 - val_acc: 0.6262\n",
      "Epoch 31/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5228 - acc: 0.7959 - val_loss: 0.9460 - val_acc: 0.6864\n",
      "Epoch 32/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.5132 - acc: 0.7993 - val_loss: 1.6081 - val_acc: 0.5825\n",
      "Epoch 33/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.5120 - acc: 0.8000 - val_loss: 1.0301 - val_acc: 0.6556\n",
      "Epoch 34/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5088 - acc: 0.8018 - val_loss: 1.0546 - val_acc: 0.6665\n",
      "Epoch 35/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5036 - acc: 0.8042 - val_loss: 1.1352 - val_acc: 0.6360\n",
      "Epoch 36/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5057 - acc: 0.8039 - val_loss: 1.3858 - val_acc: 0.6163\n",
      "Epoch 37/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4956 - acc: 0.8059 - val_loss: 1.0634 - val_acc: 0.6562\n",
      "Epoch 38/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4938 - acc: 0.8066 - val_loss: 1.2708 - val_acc: 0.6425\n",
      "Epoch 39/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4893 - acc: 0.8095 - val_loss: 1.1619 - val_acc: 0.6515\n",
      "Epoch 40/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4884 - acc: 0.8095 - val_loss: 0.9785 - val_acc: 0.6819\n",
      "Epoch 41/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4850 - acc: 0.8112 - val_loss: 1.5318 - val_acc: 0.6232\n",
      "Epoch 42/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4800 - acc: 0.8127 - val_loss: 0.9393 - val_acc: 0.7007\n",
      "Epoch 43/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4785 - acc: 0.8125 - val_loss: 1.1174 - val_acc: 0.6589\n",
      "Epoch 44/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4746 - acc: 0.8140 - val_loss: 0.9958 - val_acc: 0.6683\n",
      "Epoch 45/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4739 - acc: 0.8148 - val_loss: 1.1474 - val_acc: 0.6756\n",
      "Epoch 46/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4721 - acc: 0.8164 - val_loss: 0.9497 - val_acc: 0.6901\n",
      "Epoch 47/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4709 - acc: 0.8147 - val_loss: 0.9921 - val_acc: 0.6786\n",
      "Epoch 48/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4693 - acc: 0.8160 - val_loss: 0.9273 - val_acc: 0.6908\n",
      "Epoch 49/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4663 - acc: 0.8177 - val_loss: 1.1821 - val_acc: 0.6723\n",
      "Epoch 50/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4591 - acc: 0.8196 - val_loss: 1.0094 - val_acc: 0.6875\n",
      "Epoch 51/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4604 - acc: 0.8185 - val_loss: 1.0033 - val_acc: 0.6926\n",
      "Epoch 52/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4570 - acc: 0.8209 - val_loss: 1.0726 - val_acc: 0.6763\n",
      "Epoch 53/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4510 - acc: 0.8237 - val_loss: 1.1965 - val_acc: 0.6754\n",
      "Epoch 54/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4516 - acc: 0.8230 - val_loss: 1.0604 - val_acc: 0.6794\n",
      "Epoch 55/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4547 - acc: 0.8217 - val_loss: 1.1904 - val_acc: 0.6756\n",
      "Epoch 56/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4504 - acc: 0.8227 - val_loss: 1.1349 - val_acc: 0.6682\n",
      "Epoch 57/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4461 - acc: 0.8242 - val_loss: 1.2412 - val_acc: 0.6275\n",
      "Epoch 58/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4463 - acc: 0.8244 - val_loss: 1.0987 - val_acc: 0.6688\n",
      "Epoch 59/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4473 - acc: 0.8239 - val_loss: 1.1945 - val_acc: 0.6744\n",
      "Epoch 60/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4425 - acc: 0.8261 - val_loss: 1.0785 - val_acc: 0.6829\n",
      "Epoch 61/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4404 - acc: 0.8266 - val_loss: 0.9498 - val_acc: 0.6918\n",
      "Epoch 62/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4378 - acc: 0.8281 - val_loss: 1.2951 - val_acc: 0.6592\n",
      "Epoch 63/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4370 - acc: 0.8283 - val_loss: 1.0428 - val_acc: 0.6861\n",
      "Epoch 64/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4346 - acc: 0.8278 - val_loss: 1.2349 - val_acc: 0.6608\n",
      "Epoch 65/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4330 - acc: 0.8285 - val_loss: 1.2780 - val_acc: 0.6571\n",
      "Epoch 66/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4313 - acc: 0.8310 - val_loss: 1.0789 - val_acc: 0.6889\n",
      "Epoch 67/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4333 - acc: 0.8287 - val_loss: 1.1901 - val_acc: 0.6823\n",
      "Epoch 68/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4280 - acc: 0.8311 - val_loss: 1.0277 - val_acc: 0.6951\n",
      "Epoch 69/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4264 - acc: 0.8320 - val_loss: 0.9480 - val_acc: 0.6870\n",
      "Epoch 70/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4273 - acc: 0.8313 - val_loss: 1.2623 - val_acc: 0.6624\n",
      "Epoch 71/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4274 - acc: 0.8324 - val_loss: 1.0128 - val_acc: 0.6896\n",
      "Epoch 72/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4258 - acc: 0.8320 - val_loss: 0.9890 - val_acc: 0.6940\n",
      "Epoch 73/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4232 - acc: 0.8335 - val_loss: 1.0591 - val_acc: 0.6844\n",
      "Epoch 74/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4262 - acc: 0.8315 - val_loss: 1.1798 - val_acc: 0.6870\n",
      "Epoch 75/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4190 - acc: 0.8340 - val_loss: 0.9695 - val_acc: 0.6958\n",
      "Epoch 76/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4174 - acc: 0.8348 - val_loss: 0.9694 - val_acc: 0.6923\n",
      "Epoch 77/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4171 - acc: 0.8336 - val_loss: 1.0244 - val_acc: 0.6908\n",
      "Epoch 78/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4183 - acc: 0.8346 - val_loss: 1.1978 - val_acc: 0.6814\n",
      "Epoch 79/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4154 - acc: 0.8349 - val_loss: 1.0725 - val_acc: 0.6925\n",
      "Epoch 80/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4157 - acc: 0.8353 - val_loss: 1.1262 - val_acc: 0.6836\n",
      "Epoch 81/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4126 - acc: 0.8368 - val_loss: 1.1349 - val_acc: 0.6902\n",
      "Epoch 82/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4132 - acc: 0.8365 - val_loss: 1.5891 - val_acc: 0.6415\n",
      "Epoch 83/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4104 - acc: 0.8376 - val_loss: 1.0555 - val_acc: 0.6901\n",
      "Epoch 84/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4058 - acc: 0.8390 - val_loss: 1.1062 - val_acc: 0.6858\n",
      "Epoch 85/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4077 - acc: 0.8384 - val_loss: 1.4375 - val_acc: 0.6443\n",
      "Epoch 86/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4068 - acc: 0.8390 - val_loss: 1.0642 - val_acc: 0.6842\n",
      "Epoch 87/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4068 - acc: 0.8390 - val_loss: 1.0065 - val_acc: 0.6976\n",
      "Epoch 88/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4047 - acc: 0.8390 - val_loss: 1.1887 - val_acc: 0.6902\n",
      "Epoch 89/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4027 - acc: 0.8396 - val_loss: 0.9562 - val_acc: 0.7047\n",
      "Epoch 90/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4005 - acc: 0.8415 - val_loss: 1.0322 - val_acc: 0.7042\n",
      "Epoch 91/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4019 - acc: 0.8411 - val_loss: 0.9627 - val_acc: 0.7045\n",
      "Epoch 92/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3982 - acc: 0.8412 - val_loss: 1.2162 - val_acc: 0.6593\n",
      "Epoch 93/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3994 - acc: 0.8418 - val_loss: 1.0483 - val_acc: 0.7138\n",
      "Epoch 94/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3987 - acc: 0.8421 - val_loss: 1.0823 - val_acc: 0.6999\n",
      "Epoch 95/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3993 - acc: 0.8418 - val_loss: 1.0896 - val_acc: 0.6984\n",
      "Epoch 96/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3960 - acc: 0.8435 - val_loss: 0.9779 - val_acc: 0.7049\n",
      "Epoch 97/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3942 - acc: 0.8437 - val_loss: 0.9627 - val_acc: 0.7086\n",
      "Epoch 98/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3991 - acc: 0.8418 - val_loss: 1.3088 - val_acc: 0.6537\n",
      "Epoch 99/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3956 - acc: 0.8421 - val_loss: 1.1384 - val_acc: 0.6820\n",
      "Epoch 100/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3910 - acc: 0.8449 - val_loss: 1.3461 - val_acc: 0.6595\n",
      "Epoch 101/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3895 - acc: 0.8455 - val_loss: 1.1443 - val_acc: 0.6861\n",
      "Epoch 102/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3914 - acc: 0.8447 - val_loss: 1.4645 - val_acc: 0.6490\n",
      "Epoch 103/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3877 - acc: 0.8458 - val_loss: 1.1506 - val_acc: 0.6820\n",
      "Epoch 104/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3900 - acc: 0.8443 - val_loss: 1.2945 - val_acc: 0.6779\n",
      "Epoch 105/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3883 - acc: 0.8446 - val_loss: 1.0731 - val_acc: 0.7015\n",
      "Epoch 106/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3831 - acc: 0.8473 - val_loss: 1.1524 - val_acc: 0.7006\n",
      "Epoch 107/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3866 - acc: 0.8471 - val_loss: 0.9925 - val_acc: 0.7001\n",
      "Epoch 108/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3853 - acc: 0.8478 - val_loss: 1.3615 - val_acc: 0.6732\n",
      "Epoch 109/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3833 - acc: 0.8471 - val_loss: 1.1521 - val_acc: 0.6937\n",
      "Epoch 110/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3846 - acc: 0.8470 - val_loss: 1.0893 - val_acc: 0.6978\n",
      "Epoch 111/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3799 - acc: 0.8489 - val_loss: 1.0515 - val_acc: 0.6942\n",
      "Epoch 112/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3781 - acc: 0.8503 - val_loss: 0.9735 - val_acc: 0.7100\n",
      "Epoch 113/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3812 - acc: 0.8491 - val_loss: 1.0854 - val_acc: 0.6989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3839 - acc: 0.8468 - val_loss: 1.1239 - val_acc: 0.6794\n",
      "Epoch 115/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3811 - acc: 0.8488 - val_loss: 1.0307 - val_acc: 0.7047\n",
      "Epoch 116/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3783 - acc: 0.8489 - val_loss: 1.0766 - val_acc: 0.7044\n",
      "Epoch 117/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3757 - acc: 0.8506 - val_loss: 1.1548 - val_acc: 0.6967\n",
      "Epoch 118/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3782 - acc: 0.8497 - val_loss: 1.0534 - val_acc: 0.6973\n",
      "Epoch 119/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3781 - acc: 0.8480 - val_loss: 1.2178 - val_acc: 0.6866\n",
      "Epoch 120/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3736 - acc: 0.8515 - val_loss: 1.1275 - val_acc: 0.7075\n",
      "Epoch 121/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3745 - acc: 0.8498 - val_loss: 1.0420 - val_acc: 0.6999\n",
      "Epoch 122/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3704 - acc: 0.8516 - val_loss: 1.0927 - val_acc: 0.6958\n",
      "Epoch 123/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3709 - acc: 0.8517 - val_loss: 1.1969 - val_acc: 0.7029\n",
      "Epoch 124/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3722 - acc: 0.8523 - val_loss: 1.4256 - val_acc: 0.6616\n",
      "Epoch 125/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3681 - acc: 0.8528 - val_loss: 1.1720 - val_acc: 0.6815\n",
      "Epoch 126/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3706 - acc: 0.8532 - val_loss: 1.2943 - val_acc: 0.6661\n",
      "Epoch 127/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3683 - acc: 0.8533 - val_loss: 1.1813 - val_acc: 0.6908\n",
      "Epoch 128/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3705 - acc: 0.8520 - val_loss: 1.1818 - val_acc: 0.6959\n",
      "Epoch 129/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3681 - acc: 0.8531 - val_loss: 1.1417 - val_acc: 0.6919\n",
      "Epoch 130/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3672 - acc: 0.8543 - val_loss: 1.1137 - val_acc: 0.7120\n",
      "Epoch 131/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3669 - acc: 0.8540 - val_loss: 1.1161 - val_acc: 0.7160\n",
      "Epoch 132/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3664 - acc: 0.8540 - val_loss: 1.0817 - val_acc: 0.7067\n",
      "Epoch 133/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3645 - acc: 0.8543 - val_loss: 1.3715 - val_acc: 0.6776\n",
      "Epoch 134/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3615 - acc: 0.8556 - val_loss: 1.0786 - val_acc: 0.7010\n",
      "Epoch 135/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3612 - acc: 0.8572 - val_loss: 1.2492 - val_acc: 0.6794\n",
      "Epoch 136/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3640 - acc: 0.8550 - val_loss: 1.2249 - val_acc: 0.7013\n",
      "Epoch 137/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3628 - acc: 0.8541 - val_loss: 1.2998 - val_acc: 0.6777\n",
      "Epoch 138/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3611 - acc: 0.8557 - val_loss: 1.3016 - val_acc: 0.6844\n",
      "Epoch 139/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3614 - acc: 0.8553 - val_loss: 1.1078 - val_acc: 0.7052\n",
      "Epoch 140/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3581 - acc: 0.8574 - val_loss: 1.1949 - val_acc: 0.6996\n",
      "Epoch 141/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3553 - acc: 0.8582 - val_loss: 1.1543 - val_acc: 0.7069\n",
      "Epoch 142/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3585 - acc: 0.8565 - val_loss: 1.1966 - val_acc: 0.6718\n",
      "Epoch 143/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3583 - acc: 0.8569 - val_loss: 1.2505 - val_acc: 0.6825\n",
      "Epoch 144/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3564 - acc: 0.8576 - val_loss: 1.0043 - val_acc: 0.7078\n",
      "Epoch 145/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3563 - acc: 0.8585 - val_loss: 1.1992 - val_acc: 0.7014\n",
      "Epoch 146/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3554 - acc: 0.8590 - val_loss: 1.3929 - val_acc: 0.6658\n",
      "Epoch 147/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3546 - acc: 0.8577 - val_loss: 1.1265 - val_acc: 0.7049\n",
      "Epoch 148/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3560 - acc: 0.8571 - val_loss: 1.1358 - val_acc: 0.7005\n",
      "Epoch 149/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3586 - acc: 0.8567 - val_loss: 1.3905 - val_acc: 0.6699\n",
      "Epoch 150/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3544 - acc: 0.8581 - val_loss: 1.5919 - val_acc: 0.6724\n",
      "Epoch 151/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3513 - acc: 0.8601 - val_loss: 1.2606 - val_acc: 0.6970\n",
      "Epoch 152/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3479 - acc: 0.8612 - val_loss: 1.1614 - val_acc: 0.6968\n",
      "Epoch 153/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3531 - acc: 0.8586 - val_loss: 1.0758 - val_acc: 0.7206\n",
      "Epoch 154/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3523 - acc: 0.8591 - val_loss: 1.0656 - val_acc: 0.7213\n",
      "Epoch 155/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3512 - acc: 0.8588 - val_loss: 1.3293 - val_acc: 0.6692\n",
      "Epoch 156/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3536 - acc: 0.8580 - val_loss: 1.1864 - val_acc: 0.6968\n",
      "Epoch 157/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3472 - acc: 0.8610 - val_loss: 1.2535 - val_acc: 0.6846\n",
      "Epoch 158/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3494 - acc: 0.8609 - val_loss: 1.0645 - val_acc: 0.7135\n",
      "Epoch 159/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3473 - acc: 0.8611 - val_loss: 1.1640 - val_acc: 0.7065\n",
      "Epoch 160/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3483 - acc: 0.8610 - val_loss: 1.3439 - val_acc: 0.6637\n",
      "Epoch 161/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3469 - acc: 0.8606 - val_loss: 1.1025 - val_acc: 0.7061\n",
      "Epoch 162/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3496 - acc: 0.8598 - val_loss: 1.2293 - val_acc: 0.7058\n",
      "Epoch 163/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3474 - acc: 0.8615 - val_loss: 1.1738 - val_acc: 0.7023\n",
      "Epoch 164/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3451 - acc: 0.8622 - val_loss: 1.5224 - val_acc: 0.6340\n",
      "Epoch 165/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3400 - acc: 0.8637 - val_loss: 1.4929 - val_acc: 0.6751\n",
      "Epoch 166/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3420 - acc: 0.8633 - val_loss: 1.2607 - val_acc: 0.6682\n",
      "Epoch 167/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3409 - acc: 0.8637 - val_loss: 1.0651 - val_acc: 0.7155\n",
      "Epoch 168/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3428 - acc: 0.8631 - val_loss: 1.1873 - val_acc: 0.7085\n",
      "Epoch 169/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3428 - acc: 0.8620 - val_loss: 1.1977 - val_acc: 0.6861\n",
      "Epoch 170/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3432 - acc: 0.8625 - val_loss: 1.4185 - val_acc: 0.6691\n",
      "Epoch 171/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3405 - acc: 0.8641 - val_loss: 1.2568 - val_acc: 0.7008\n",
      "Epoch 172/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3414 - acc: 0.8631 - val_loss: 1.1889 - val_acc: 0.7074\n",
      "Epoch 173/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3376 - acc: 0.8645 - val_loss: 1.3093 - val_acc: 0.6901\n",
      "Epoch 174/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3369 - acc: 0.8656 - val_loss: 1.3330 - val_acc: 0.7033\n",
      "Epoch 175/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3407 - acc: 0.8639 - val_loss: 1.1200 - val_acc: 0.6935\n",
      "Epoch 176/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3382 - acc: 0.8638 - val_loss: 1.3127 - val_acc: 0.6959\n",
      "Epoch 177/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3416 - acc: 0.8638 - val_loss: 1.2059 - val_acc: 0.7040\n",
      "Epoch 178/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3368 - acc: 0.8652 - val_loss: 1.1331 - val_acc: 0.7154\n",
      "Epoch 179/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3360 - acc: 0.8654 - val_loss: 1.0919 - val_acc: 0.7120\n",
      "Epoch 180/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3350 - acc: 0.8649 - val_loss: 1.4848 - val_acc: 0.6720\n",
      "Epoch 181/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3353 - acc: 0.8654 - val_loss: 1.3658 - val_acc: 0.6921\n",
      "Epoch 182/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3328 - acc: 0.8678 - val_loss: 1.1370 - val_acc: 0.7193\n",
      "Epoch 183/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3327 - acc: 0.8674 - val_loss: 1.2736 - val_acc: 0.6943\n",
      "Epoch 184/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3317 - acc: 0.8672 - val_loss: 1.2991 - val_acc: 0.6819\n",
      "Epoch 185/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3347 - acc: 0.8663 - val_loss: 1.1077 - val_acc: 0.7263\n",
      "Epoch 186/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3314 - acc: 0.8667 - val_loss: 1.2959 - val_acc: 0.6941\n",
      "Epoch 187/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3362 - acc: 0.8648 - val_loss: 1.6068 - val_acc: 0.6623\n",
      "Epoch 188/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3310 - acc: 0.8675 - val_loss: 1.3872 - val_acc: 0.6929\n",
      "Epoch 189/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3344 - acc: 0.8657 - val_loss: 1.3033 - val_acc: 0.6951\n",
      "Epoch 190/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3300 - acc: 0.8675 - val_loss: 1.2566 - val_acc: 0.7132\n",
      "Epoch 191/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3312 - acc: 0.8668 - val_loss: 1.2282 - val_acc: 0.7092\n",
      "Epoch 192/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3266 - acc: 0.8698 - val_loss: 1.1945 - val_acc: 0.7046\n",
      "Epoch 193/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3282 - acc: 0.8679 - val_loss: 1.1745 - val_acc: 0.7115\n",
      "Epoch 194/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3283 - acc: 0.8680 - val_loss: 1.5302 - val_acc: 0.6878\n",
      "Epoch 195/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3281 - acc: 0.8689 - val_loss: 1.4361 - val_acc: 0.6930\n",
      "Epoch 196/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3266 - acc: 0.8698 - val_loss: 1.1389 - val_acc: 0.7194\n",
      "Epoch 197/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3250 - acc: 0.8694 - val_loss: 1.2684 - val_acc: 0.6766\n",
      "Epoch 198/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3279 - acc: 0.8683 - val_loss: 1.1748 - val_acc: 0.7111\n",
      "Epoch 199/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3277 - acc: 0.8689 - val_loss: 1.0595 - val_acc: 0.7233\n",
      "Epoch 200/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3251 - acc: 0.8702 - val_loss: 1.1701 - val_acc: 0.7125\n",
      "Epoch 201/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3236 - acc: 0.8702 - val_loss: 1.2017 - val_acc: 0.7154\n",
      "Epoch 202/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3238 - acc: 0.8698 - val_loss: 1.0459 - val_acc: 0.7227\n",
      "Epoch 203/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3232 - acc: 0.8701 - val_loss: 1.2703 - val_acc: 0.6996\n",
      "Epoch 204/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3215 - acc: 0.8716 - val_loss: 1.2666 - val_acc: 0.7090\n",
      "Epoch 205/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3239 - acc: 0.8695 - val_loss: 1.2873 - val_acc: 0.6935\n",
      "Epoch 206/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3229 - acc: 0.8693 - val_loss: 1.3533 - val_acc: 0.6973\n",
      "Epoch 207/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3243 - acc: 0.8708 - val_loss: 1.2643 - val_acc: 0.7015\n",
      "Epoch 208/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3231 - acc: 0.8712 - val_loss: 1.4716 - val_acc: 0.6842\n",
      "Epoch 209/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3196 - acc: 0.8716 - val_loss: 1.1542 - val_acc: 0.7283\n",
      "Epoch 210/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3219 - acc: 0.8712 - val_loss: 1.2975 - val_acc: 0.7036\n",
      "Epoch 211/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3242 - acc: 0.8702 - val_loss: 1.3630 - val_acc: 0.7003\n",
      "Epoch 212/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3199 - acc: 0.8723 - val_loss: 1.2939 - val_acc: 0.6967\n",
      "Epoch 213/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3208 - acc: 0.8710 - val_loss: 1.1327 - val_acc: 0.7164\n",
      "Epoch 214/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3178 - acc: 0.8735 - val_loss: 1.1101 - val_acc: 0.7110\n",
      "Epoch 215/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3139 - acc: 0.8741 - val_loss: 1.1955 - val_acc: 0.6956\n",
      "Epoch 216/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3171 - acc: 0.8728 - val_loss: 1.1476 - val_acc: 0.7108\n",
      "Epoch 217/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3174 - acc: 0.8722 - val_loss: 1.4555 - val_acc: 0.6973\n",
      "Epoch 218/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3167 - acc: 0.8725 - val_loss: 1.0668 - val_acc: 0.7122\n",
      "Epoch 219/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3172 - acc: 0.8732 - val_loss: 1.2316 - val_acc: 0.7144\n",
      "Epoch 220/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3180 - acc: 0.8728 - val_loss: 1.3728 - val_acc: 0.7067\n",
      "Epoch 221/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3172 - acc: 0.8727 - val_loss: 1.2380 - val_acc: 0.6999\n",
      "Epoch 222/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3187 - acc: 0.8715 - val_loss: 1.2087 - val_acc: 0.6932\n",
      "Epoch 223/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3154 - acc: 0.8736 - val_loss: 1.1515 - val_acc: 0.7079\n",
      "Epoch 224/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3127 - acc: 0.8743 - val_loss: 1.2874 - val_acc: 0.6923\n",
      "Epoch 225/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3119 - acc: 0.8755 - val_loss: 1.2663 - val_acc: 0.7112\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3177 - acc: 0.8729 - val_loss: 1.3057 - val_acc: 0.7086\n",
      "Epoch 227/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3125 - acc: 0.8752 - val_loss: 1.1707 - val_acc: 0.7202\n",
      "Epoch 228/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3140 - acc: 0.8744 - val_loss: 1.4543 - val_acc: 0.6844\n",
      "Epoch 229/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3127 - acc: 0.8736 - val_loss: 1.3068 - val_acc: 0.7022\n",
      "Epoch 230/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3088 - acc: 0.8758 - val_loss: 1.1952 - val_acc: 0.7167\n",
      "Epoch 231/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3102 - acc: 0.8762 - val_loss: 1.3530 - val_acc: 0.7057\n",
      "Epoch 232/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3087 - acc: 0.8758 - val_loss: 1.2724 - val_acc: 0.7090\n",
      "Epoch 233/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3096 - acc: 0.8754 - val_loss: 1.1858 - val_acc: 0.7152\n",
      "Epoch 234/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3087 - acc: 0.8766 - val_loss: 1.2763 - val_acc: 0.7130\n",
      "Epoch 235/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3126 - acc: 0.8754 - val_loss: 1.1978 - val_acc: 0.7156\n",
      "Epoch 236/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3105 - acc: 0.8743 - val_loss: 1.4234 - val_acc: 0.6663\n",
      "Epoch 237/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.3078 - acc: 0.8758 - val_loss: 1.1493 - val_acc: 0.7165\n",
      "Epoch 238/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3042 - acc: 0.8779 - val_loss: 1.2287 - val_acc: 0.7138\n",
      "Epoch 239/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3080 - acc: 0.8752 - val_loss: 1.2602 - val_acc: 0.7154\n",
      "Epoch 240/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3064 - acc: 0.8763 - val_loss: 1.9216 - val_acc: 0.6495\n",
      "Epoch 241/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3055 - acc: 0.8781 - val_loss: 1.1420 - val_acc: 0.7249\n",
      "Epoch 242/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3041 - acc: 0.8773 - val_loss: 1.1636 - val_acc: 0.7230\n",
      "Epoch 243/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3019 - acc: 0.8793 - val_loss: 1.2614 - val_acc: 0.7109\n",
      "Epoch 244/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3052 - acc: 0.8773 - val_loss: 1.1338 - val_acc: 0.7223\n",
      "Epoch 245/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3076 - acc: 0.8771 - val_loss: 1.1672 - val_acc: 0.7108\n",
      "Epoch 246/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3022 - acc: 0.8787 - val_loss: 1.4399 - val_acc: 0.6911\n",
      "Epoch 247/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3068 - acc: 0.8764 - val_loss: 1.1154 - val_acc: 0.7199\n",
      "Epoch 248/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3027 - acc: 0.8789 - val_loss: 1.2561 - val_acc: 0.7146\n",
      "Epoch 249/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3031 - acc: 0.8776 - val_loss: 1.2100 - val_acc: 0.7135\n",
      "Epoch 250/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3031 - acc: 0.8780 - val_loss: 1.0991 - val_acc: 0.7146\n",
      "Epoch 251/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3030 - acc: 0.8799 - val_loss: 1.2262 - val_acc: 0.7165\n",
      "Epoch 252/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3004 - acc: 0.8798 - val_loss: 1.2885 - val_acc: 0.6920\n",
      "Epoch 253/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3009 - acc: 0.8786 - val_loss: 1.2232 - val_acc: 0.7170\n",
      "Epoch 254/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3039 - acc: 0.8779 - val_loss: 1.3236 - val_acc: 0.7061\n",
      "Epoch 255/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2998 - acc: 0.8792 - val_loss: 1.2523 - val_acc: 0.7104\n",
      "Epoch 256/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3019 - acc: 0.8781 - val_loss: 1.1600 - val_acc: 0.7201\n",
      "Epoch 257/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2986 - acc: 0.8801 - val_loss: 1.2186 - val_acc: 0.7204\n",
      "Epoch 258/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2983 - acc: 0.8794 - val_loss: 1.4438 - val_acc: 0.7010\n",
      "Epoch 259/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3012 - acc: 0.8785 - val_loss: 1.3026 - val_acc: 0.7090\n",
      "Epoch 260/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3035 - acc: 0.8777 - val_loss: 1.3693 - val_acc: 0.6963\n",
      "Epoch 261/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3000 - acc: 0.8792 - val_loss: 1.2614 - val_acc: 0.7078\n",
      "Epoch 262/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2992 - acc: 0.8797 - val_loss: 1.4118 - val_acc: 0.6883\n",
      "Epoch 263/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2943 - acc: 0.8814 - val_loss: 1.1370 - val_acc: 0.7231\n",
      "Epoch 264/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2980 - acc: 0.8801 - val_loss: 1.2100 - val_acc: 0.7098\n",
      "Epoch 265/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2953 - acc: 0.8812 - val_loss: 1.2605 - val_acc: 0.7194\n",
      "Epoch 266/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2945 - acc: 0.8816 - val_loss: 1.2169 - val_acc: 0.7239\n",
      "Epoch 267/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2934 - acc: 0.8824 - val_loss: 1.2152 - val_acc: 0.7172\n",
      "Epoch 268/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2964 - acc: 0.8802 - val_loss: 1.3889 - val_acc: 0.7035\n",
      "Epoch 269/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2925 - acc: 0.8817 - val_loss: 1.2825 - val_acc: 0.7139\n",
      "Epoch 270/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2963 - acc: 0.8805 - val_loss: 1.3977 - val_acc: 0.7146\n",
      "Epoch 271/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2956 - acc: 0.8820 - val_loss: 1.2109 - val_acc: 0.7032\n",
      "Epoch 272/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2907 - acc: 0.8825 - val_loss: 1.4504 - val_acc: 0.7047\n",
      "Epoch 273/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2934 - acc: 0.8821 - val_loss: 1.2957 - val_acc: 0.7118\n",
      "Epoch 274/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2929 - acc: 0.8828 - val_loss: 1.1900 - val_acc: 0.7278\n",
      "Epoch 275/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2916 - acc: 0.8819 - val_loss: 1.1368 - val_acc: 0.7290\n",
      "Epoch 276/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2926 - acc: 0.8820 - val_loss: 1.1698 - val_acc: 0.7201\n",
      "Epoch 277/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2919 - acc: 0.8820 - val_loss: 1.1724 - val_acc: 0.7239\n",
      "Epoch 278/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2930 - acc: 0.8826 - val_loss: 1.2816 - val_acc: 0.7180\n",
      "Epoch 279/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2912 - acc: 0.8833 - val_loss: 1.3370 - val_acc: 0.7198\n",
      "Epoch 280/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2900 - acc: 0.8829 - val_loss: 1.5419 - val_acc: 0.6865\n",
      "Epoch 281/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2930 - acc: 0.8831 - val_loss: 1.2338 - val_acc: 0.7184\n",
      "Epoch 282/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2903 - acc: 0.8842 - val_loss: 1.2414 - val_acc: 0.7182\n",
      "Epoch 283/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2916 - acc: 0.8830 - val_loss: 1.3447 - val_acc: 0.7106\n",
      "Epoch 284/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2903 - acc: 0.8845 - val_loss: 1.3862 - val_acc: 0.7130\n",
      "Epoch 285/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2912 - acc: 0.8830 - val_loss: 1.1355 - val_acc: 0.7304\n",
      "Epoch 286/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2889 - acc: 0.8837 - val_loss: 1.4200 - val_acc: 0.7043\n",
      "Epoch 287/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2920 - acc: 0.8826 - val_loss: 1.2956 - val_acc: 0.7127\n",
      "Epoch 288/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2912 - acc: 0.8820 - val_loss: 1.5747 - val_acc: 0.7011\n",
      "Epoch 289/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2889 - acc: 0.8841 - val_loss: 1.4140 - val_acc: 0.7067\n",
      "Epoch 290/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2868 - acc: 0.8849 - val_loss: 1.6598 - val_acc: 0.6802\n",
      "Epoch 291/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2876 - acc: 0.8846 - val_loss: 1.1961 - val_acc: 0.7275\n",
      "Epoch 292/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2860 - acc: 0.8843 - val_loss: 1.4051 - val_acc: 0.7100\n",
      "Epoch 293/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2859 - acc: 0.8847 - val_loss: 1.3489 - val_acc: 0.7113\n",
      "Epoch 294/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2870 - acc: 0.8845 - val_loss: 1.3121 - val_acc: 0.7109\n",
      "Epoch 295/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2834 - acc: 0.8861 - val_loss: 1.2602 - val_acc: 0.7213\n",
      "Epoch 296/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2861 - acc: 0.8848 - val_loss: 1.4012 - val_acc: 0.7177\n",
      "Epoch 297/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2849 - acc: 0.8861 - val_loss: 1.5077 - val_acc: 0.7064\n",
      "Epoch 298/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2806 - acc: 0.8879 - val_loss: 1.4749 - val_acc: 0.6942\n",
      "Epoch 299/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2835 - acc: 0.8864 - val_loss: 1.4539 - val_acc: 0.7087\n",
      "Epoch 300/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2841 - acc: 0.8854 - val_loss: 1.5327 - val_acc: 0.6867\n",
      "Epoch 301/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2804 - acc: 0.8879 - val_loss: 1.3373 - val_acc: 0.7119\n",
      "Epoch 302/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2848 - acc: 0.8862 - val_loss: 1.4340 - val_acc: 0.7066\n",
      "Epoch 303/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2829 - acc: 0.8865 - val_loss: 1.3174 - val_acc: 0.7189\n",
      "Epoch 304/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2820 - acc: 0.8871 - val_loss: 1.4738 - val_acc: 0.6963\n",
      "Epoch 305/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2811 - acc: 0.8869 - val_loss: 1.4049 - val_acc: 0.7046\n",
      "Epoch 306/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2840 - acc: 0.8863 - val_loss: 1.2737 - val_acc: 0.7285\n",
      "Epoch 307/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2810 - acc: 0.8870 - val_loss: 1.3340 - val_acc: 0.7095\n",
      "Epoch 308/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2788 - acc: 0.8879 - val_loss: 1.4428 - val_acc: 0.7061\n",
      "Epoch 309/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2805 - acc: 0.8878 - val_loss: 1.1886 - val_acc: 0.7200\n",
      "Epoch 310/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2779 - acc: 0.8877 - val_loss: 1.5175 - val_acc: 0.6995\n",
      "Epoch 311/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2796 - acc: 0.8872 - val_loss: 1.2603 - val_acc: 0.7170\n",
      "Epoch 312/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2801 - acc: 0.8875 - val_loss: 1.4277 - val_acc: 0.7071\n",
      "Epoch 313/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2801 - acc: 0.8878 - val_loss: 1.2366 - val_acc: 0.7285\n",
      "Epoch 314/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2801 - acc: 0.8872 - val_loss: 1.4014 - val_acc: 0.7083\n",
      "Epoch 315/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2780 - acc: 0.8892 - val_loss: 1.3041 - val_acc: 0.7189\n",
      "Epoch 316/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2773 - acc: 0.8882 - val_loss: 1.2985 - val_acc: 0.7106\n",
      "Epoch 317/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2798 - acc: 0.8867 - val_loss: 1.5160 - val_acc: 0.6968\n",
      "Epoch 318/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2808 - acc: 0.8875 - val_loss: 1.2027 - val_acc: 0.7281\n",
      "Epoch 319/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2768 - acc: 0.8880 - val_loss: 1.4406 - val_acc: 0.7099\n",
      "Epoch 320/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2776 - acc: 0.8878 - val_loss: 1.3666 - val_acc: 0.7099\n",
      "Epoch 321/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2735 - acc: 0.8898 - val_loss: 1.2731 - val_acc: 0.7237\n",
      "Epoch 322/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2770 - acc: 0.8884 - val_loss: 1.3683 - val_acc: 0.7124\n",
      "Epoch 323/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2755 - acc: 0.8898 - val_loss: 1.4570 - val_acc: 0.7055\n",
      "Epoch 324/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2765 - acc: 0.8895 - val_loss: 1.4448 - val_acc: 0.7044\n",
      "Epoch 325/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2757 - acc: 0.8888 - val_loss: 1.1886 - val_acc: 0.7312\n",
      "Epoch 326/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2742 - acc: 0.8904 - val_loss: 1.4151 - val_acc: 0.7185\n",
      "Epoch 327/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2744 - acc: 0.8911 - val_loss: 1.3675 - val_acc: 0.7087\n",
      "Epoch 328/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2737 - acc: 0.8901 - val_loss: 1.3054 - val_acc: 0.7135\n",
      "Epoch 329/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2755 - acc: 0.8892 - val_loss: 1.3746 - val_acc: 0.7118\n",
      "Epoch 330/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2759 - acc: 0.8894 - val_loss: 1.3441 - val_acc: 0.7168\n",
      "Epoch 331/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2719 - acc: 0.8899 - val_loss: 1.2942 - val_acc: 0.7172\n",
      "Epoch 332/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2664 - acc: 0.8929 - val_loss: 1.2953 - val_acc: 0.7183\n",
      "Epoch 333/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2727 - acc: 0.8910 - val_loss: 1.2400 - val_acc: 0.7293\n",
      "Epoch 334/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2736 - acc: 0.8900 - val_loss: 1.2864 - val_acc: 0.7214\n",
      "Epoch 335/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2715 - acc: 0.8907 - val_loss: 1.4128 - val_acc: 0.7177\n",
      "Epoch 336/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2750 - acc: 0.8903 - val_loss: 1.3582 - val_acc: 0.7197\n",
      "Epoch 337/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2697 - acc: 0.8919 - val_loss: 1.3852 - val_acc: 0.7084\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2699 - acc: 0.8920 - val_loss: 1.3618 - val_acc: 0.7132\n",
      "Epoch 339/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2703 - acc: 0.8920 - val_loss: 1.5637 - val_acc: 0.6942\n",
      "Epoch 340/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2683 - acc: 0.8920 - val_loss: 1.1920 - val_acc: 0.7256\n",
      "Epoch 341/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2681 - acc: 0.8927 - val_loss: 1.4428 - val_acc: 0.7058\n",
      "Epoch 342/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2718 - acc: 0.8907 - val_loss: 1.3139 - val_acc: 0.7146\n",
      "Epoch 343/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2678 - acc: 0.8932 - val_loss: 1.2535 - val_acc: 0.7296\n",
      "Epoch 344/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2673 - acc: 0.8925 - val_loss: 1.3991 - val_acc: 0.7189\n",
      "Epoch 345/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2672 - acc: 0.8923 - val_loss: 1.3367 - val_acc: 0.7161\n",
      "Epoch 346/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2698 - acc: 0.8915 - val_loss: 1.4470 - val_acc: 0.7058\n",
      "Epoch 347/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2657 - acc: 0.8928 - val_loss: 1.3594 - val_acc: 0.7144\n",
      "Epoch 348/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2680 - acc: 0.8924 - val_loss: 1.2704 - val_acc: 0.7200\n",
      "Epoch 349/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2684 - acc: 0.8927 - val_loss: 1.5310 - val_acc: 0.7011\n",
      "Epoch 350/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2661 - acc: 0.8921 - val_loss: 1.4764 - val_acc: 0.7128\n",
      "Epoch 351/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2672 - acc: 0.8930 - val_loss: 1.2309 - val_acc: 0.7345\n",
      "Epoch 352/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2669 - acc: 0.8932 - val_loss: 1.3014 - val_acc: 0.7296\n",
      "Epoch 353/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2670 - acc: 0.8930 - val_loss: 1.4109 - val_acc: 0.7043\n",
      "Epoch 354/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2681 - acc: 0.8933 - val_loss: 1.2455 - val_acc: 0.7323\n",
      "Epoch 355/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2689 - acc: 0.8927 - val_loss: 1.3589 - val_acc: 0.7169\n",
      "Epoch 356/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2668 - acc: 0.8930 - val_loss: 1.3707 - val_acc: 0.7080\n",
      "Epoch 357/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2660 - acc: 0.8930 - val_loss: 1.3769 - val_acc: 0.7126\n",
      "Epoch 358/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2636 - acc: 0.8943 - val_loss: 1.6012 - val_acc: 0.7043\n",
      "Epoch 359/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2651 - acc: 0.8927 - val_loss: 1.1631 - val_acc: 0.7363\n",
      "Epoch 360/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2653 - acc: 0.8941 - val_loss: 1.2360 - val_acc: 0.7363\n",
      "Epoch 361/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2643 - acc: 0.8951 - val_loss: 1.3336 - val_acc: 0.7118\n",
      "Epoch 362/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2649 - acc: 0.8933 - val_loss: 1.3113 - val_acc: 0.7199\n",
      "Epoch 363/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2610 - acc: 0.8944 - val_loss: 1.3258 - val_acc: 0.7233\n",
      "Epoch 364/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2616 - acc: 0.8943 - val_loss: 1.3202 - val_acc: 0.7179\n",
      "Epoch 365/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2648 - acc: 0.8936 - val_loss: 1.2034 - val_acc: 0.7337\n",
      "Epoch 366/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2655 - acc: 0.8933 - val_loss: 1.3041 - val_acc: 0.7213\n",
      "Epoch 367/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2639 - acc: 0.8935 - val_loss: 1.3941 - val_acc: 0.7238\n",
      "Epoch 368/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2615 - acc: 0.8951 - val_loss: 1.1403 - val_acc: 0.7329\n",
      "Epoch 369/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2607 - acc: 0.8949 - val_loss: 1.3805 - val_acc: 0.7194\n",
      "Epoch 370/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2596 - acc: 0.8943 - val_loss: 1.5650 - val_acc: 0.7046\n",
      "Epoch 371/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2642 - acc: 0.8944 - val_loss: 1.4323 - val_acc: 0.7136\n",
      "Epoch 372/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2618 - acc: 0.8952 - val_loss: 1.2205 - val_acc: 0.7290\n",
      "Epoch 373/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2603 - acc: 0.8952 - val_loss: 1.3145 - val_acc: 0.7242\n",
      "Epoch 374/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2592 - acc: 0.8967 - val_loss: 1.1972 - val_acc: 0.7300\n",
      "Epoch 375/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2592 - acc: 0.8954 - val_loss: 1.6726 - val_acc: 0.6870\n",
      "Epoch 376/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2561 - acc: 0.8975 - val_loss: 1.2987 - val_acc: 0.7340\n",
      "Epoch 377/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2592 - acc: 0.8960 - val_loss: 1.6090 - val_acc: 0.6823\n",
      "Epoch 378/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2571 - acc: 0.8966 - val_loss: 1.2542 - val_acc: 0.7231\n",
      "Epoch 379/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2565 - acc: 0.8970 - val_loss: 1.2018 - val_acc: 0.7289\n",
      "Epoch 380/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2580 - acc: 0.8970 - val_loss: 1.3658 - val_acc: 0.7196\n",
      "Epoch 381/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2588 - acc: 0.8964 - val_loss: 1.2599 - val_acc: 0.7322\n",
      "Epoch 382/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2579 - acc: 0.8958 - val_loss: 1.3192 - val_acc: 0.7267\n",
      "Epoch 383/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2603 - acc: 0.8953 - val_loss: 1.2609 - val_acc: 0.7293\n",
      "Epoch 384/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2551 - acc: 0.8970 - val_loss: 1.4733 - val_acc: 0.7112\n",
      "Epoch 385/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2559 - acc: 0.8975 - val_loss: 1.4303 - val_acc: 0.7163\n",
      "Epoch 386/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2603 - acc: 0.8952 - val_loss: 1.2630 - val_acc: 0.7295\n",
      "Epoch 387/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2564 - acc: 0.8965 - val_loss: 1.3293 - val_acc: 0.7054\n",
      "Epoch 388/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2572 - acc: 0.8970 - val_loss: 1.5137 - val_acc: 0.7020\n",
      "Epoch 389/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2566 - acc: 0.8973 - val_loss: 1.3692 - val_acc: 0.7271\n",
      "Epoch 390/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2548 - acc: 0.8976 - val_loss: 1.5382 - val_acc: 0.6975\n",
      "Epoch 391/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2576 - acc: 0.8959 - val_loss: 1.2416 - val_acc: 0.7250\n",
      "Epoch 392/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2557 - acc: 0.8976 - val_loss: 1.4799 - val_acc: 0.7081\n",
      "Epoch 393/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2546 - acc: 0.8981 - val_loss: 1.4134 - val_acc: 0.7139\n",
      "Epoch 394/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2560 - acc: 0.8973 - val_loss: 1.6084 - val_acc: 0.7081\n",
      "Epoch 395/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2562 - acc: 0.8964 - val_loss: 1.3592 - val_acc: 0.7154\n",
      "Epoch 396/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2530 - acc: 0.8985 - val_loss: 1.1675 - val_acc: 0.7392\n",
      "Epoch 397/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2560 - acc: 0.8964 - val_loss: 1.3935 - val_acc: 0.7136\n",
      "Epoch 398/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2531 - acc: 0.8974 - val_loss: 1.3445 - val_acc: 0.7244\n",
      "Epoch 399/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2551 - acc: 0.8969 - val_loss: 1.2915 - val_acc: 0.7285\n",
      "Epoch 400/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2523 - acc: 0.8984 - val_loss: 1.4574 - val_acc: 0.7060\n",
      "Epoch 401/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2499 - acc: 0.8996 - val_loss: 1.3083 - val_acc: 0.7234\n",
      "Epoch 402/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2533 - acc: 0.8990 - val_loss: 1.2979 - val_acc: 0.7317\n",
      "Epoch 403/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2505 - acc: 0.8988 - val_loss: 1.4467 - val_acc: 0.7042\n",
      "Epoch 404/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2496 - acc: 0.9003 - val_loss: 1.2396 - val_acc: 0.7326\n",
      "Epoch 405/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2528 - acc: 0.8979 - val_loss: 1.5528 - val_acc: 0.7085\n",
      "Epoch 406/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2500 - acc: 0.8994 - val_loss: 1.2126 - val_acc: 0.7311\n",
      "Epoch 407/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2515 - acc: 0.8987 - val_loss: 1.2949 - val_acc: 0.7257\n",
      "Epoch 408/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2502 - acc: 0.8986 - val_loss: 1.6948 - val_acc: 0.6935\n",
      "Epoch 409/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2538 - acc: 0.8976 - val_loss: 1.5008 - val_acc: 0.7032\n",
      "Epoch 410/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2510 - acc: 0.8992 - val_loss: 1.3987 - val_acc: 0.7103\n",
      "Epoch 411/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2504 - acc: 0.9004 - val_loss: 1.5056 - val_acc: 0.7026\n",
      "Epoch 412/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2480 - acc: 0.9005 - val_loss: 1.3751 - val_acc: 0.7142\n",
      "Epoch 413/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2503 - acc: 0.8994 - val_loss: 1.3588 - val_acc: 0.7201\n",
      "Epoch 414/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2532 - acc: 0.8985 - val_loss: 1.3718 - val_acc: 0.6949\n",
      "Epoch 415/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2494 - acc: 0.8994 - val_loss: 1.2967 - val_acc: 0.7292\n",
      "Epoch 416/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2502 - acc: 0.9000 - val_loss: 1.4044 - val_acc: 0.7277\n",
      "Epoch 417/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2522 - acc: 0.8983 - val_loss: 1.3878 - val_acc: 0.7216\n",
      "Epoch 418/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2434 - acc: 0.9016 - val_loss: 1.2367 - val_acc: 0.7280\n",
      "Epoch 419/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2471 - acc: 0.9012 - val_loss: 1.3189 - val_acc: 0.7265\n",
      "Epoch 420/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2446 - acc: 0.9015 - val_loss: 1.4648 - val_acc: 0.7147\n",
      "Epoch 421/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2474 - acc: 0.9013 - val_loss: 1.4006 - val_acc: 0.7179\n",
      "Epoch 422/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2475 - acc: 0.8999 - val_loss: 1.2420 - val_acc: 0.7305\n",
      "Epoch 423/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2465 - acc: 0.9010 - val_loss: 1.4130 - val_acc: 0.7190\n",
      "Epoch 424/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2435 - acc: 0.9024 - val_loss: 1.3767 - val_acc: 0.7219\n",
      "Epoch 425/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2496 - acc: 0.9006 - val_loss: 1.3745 - val_acc: 0.7295\n",
      "Epoch 426/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2492 - acc: 0.9009 - val_loss: 1.4380 - val_acc: 0.7248\n",
      "Epoch 427/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2470 - acc: 0.9010 - val_loss: 1.5143 - val_acc: 0.7170\n",
      "Epoch 428/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2464 - acc: 0.9003 - val_loss: 1.3575 - val_acc: 0.7196\n",
      "Epoch 429/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2429 - acc: 0.9025 - val_loss: 1.3239 - val_acc: 0.7288\n",
      "Epoch 430/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2442 - acc: 0.9016 - val_loss: 1.4626 - val_acc: 0.7211\n",
      "Epoch 431/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2454 - acc: 0.9014 - val_loss: 1.4446 - val_acc: 0.7205\n",
      "Epoch 432/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2458 - acc: 0.9013 - val_loss: 1.3864 - val_acc: 0.7236\n",
      "Epoch 433/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2450 - acc: 0.9011 - val_loss: 1.4367 - val_acc: 0.7208\n",
      "Epoch 434/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2449 - acc: 0.9021 - val_loss: 1.6533 - val_acc: 0.7113\n",
      "Epoch 435/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2440 - acc: 0.9027 - val_loss: 1.4354 - val_acc: 0.7227\n",
      "Epoch 436/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2433 - acc: 0.9025 - val_loss: 1.2859 - val_acc: 0.7277\n",
      "Epoch 437/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2437 - acc: 0.9025 - val_loss: 1.4035 - val_acc: 0.7306\n",
      "Epoch 438/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2468 - acc: 0.9007 - val_loss: 1.4481 - val_acc: 0.7173\n",
      "Epoch 439/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2448 - acc: 0.9023 - val_loss: 1.4467 - val_acc: 0.7175\n",
      "Epoch 440/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2427 - acc: 0.9028 - val_loss: 1.3358 - val_acc: 0.7258\n",
      "Epoch 441/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2412 - acc: 0.9023 - val_loss: 1.2249 - val_acc: 0.7382\n",
      "Epoch 442/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2401 - acc: 0.9033 - val_loss: 1.2652 - val_acc: 0.7177\n",
      "Epoch 443/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2458 - acc: 0.9016 - val_loss: 1.4143 - val_acc: 0.7263\n",
      "Epoch 444/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2423 - acc: 0.9024 - val_loss: 1.5473 - val_acc: 0.7060\n",
      "Epoch 445/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2451 - acc: 0.9014 - val_loss: 1.2479 - val_acc: 0.7363\n",
      "Epoch 446/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2445 - acc: 0.9020 - val_loss: 1.5993 - val_acc: 0.7077\n",
      "Epoch 447/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2411 - acc: 0.9031 - val_loss: 1.2158 - val_acc: 0.7363\n",
      "Epoch 448/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2389 - acc: 0.9035 - val_loss: 1.3969 - val_acc: 0.7229\n",
      "Epoch 449/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2387 - acc: 0.9041 - val_loss: 1.5275 - val_acc: 0.7154\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2439 - acc: 0.9017 - val_loss: 1.4361 - val_acc: 0.7180\n",
      "Epoch 451/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2402 - acc: 0.9031 - val_loss: 1.4477 - val_acc: 0.7202\n",
      "Epoch 452/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2399 - acc: 0.9044 - val_loss: 1.3395 - val_acc: 0.7250\n",
      "Epoch 453/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2416 - acc: 0.9030 - val_loss: 1.4750 - val_acc: 0.7160\n",
      "Epoch 454/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2394 - acc: 0.9046 - val_loss: 1.3947 - val_acc: 0.7291\n",
      "Epoch 455/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2379 - acc: 0.9045 - val_loss: 1.3165 - val_acc: 0.7394\n",
      "Epoch 456/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2367 - acc: 0.9036 - val_loss: 1.4133 - val_acc: 0.7125\n",
      "Epoch 457/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2402 - acc: 0.9030 - val_loss: 1.5889 - val_acc: 0.6903\n",
      "Epoch 458/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2419 - acc: 0.9029 - val_loss: 1.4795 - val_acc: 0.7193\n",
      "Epoch 459/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2404 - acc: 0.9036 - val_loss: 1.4337 - val_acc: 0.7265\n",
      "Epoch 460/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2370 - acc: 0.9052 - val_loss: 1.3064 - val_acc: 0.7362\n",
      "Epoch 461/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2409 - acc: 0.9038 - val_loss: 1.4910 - val_acc: 0.7296\n",
      "Epoch 462/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2371 - acc: 0.9049 - val_loss: 1.2955 - val_acc: 0.7371\n",
      "Epoch 463/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2370 - acc: 0.9047 - val_loss: 1.2700 - val_acc: 0.7337\n",
      "Epoch 464/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2392 - acc: 0.9038 - val_loss: 1.4919 - val_acc: 0.7179\n",
      "Epoch 465/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2402 - acc: 0.9041 - val_loss: 1.3954 - val_acc: 0.7263\n",
      "Epoch 466/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2340 - acc: 0.9057 - val_loss: 1.3097 - val_acc: 0.7347\n",
      "Epoch 467/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2400 - acc: 0.9042 - val_loss: 1.2891 - val_acc: 0.7326\n",
      "Epoch 468/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2341 - acc: 0.9064 - val_loss: 1.2780 - val_acc: 0.7330\n",
      "Epoch 469/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2389 - acc: 0.9043 - val_loss: 1.3282 - val_acc: 0.7242\n",
      "Epoch 470/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2340 - acc: 0.9064 - val_loss: 1.5271 - val_acc: 0.7090\n",
      "Epoch 471/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2322 - acc: 0.9071 - val_loss: 1.3789 - val_acc: 0.7275\n",
      "Epoch 472/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2331 - acc: 0.9070 - val_loss: 1.4572 - val_acc: 0.7152\n",
      "Epoch 473/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2353 - acc: 0.9054 - val_loss: 1.4130 - val_acc: 0.7249\n",
      "Epoch 474/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2337 - acc: 0.9056 - val_loss: 1.2705 - val_acc: 0.7303\n",
      "Epoch 475/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2354 - acc: 0.9051 - val_loss: 1.4815 - val_acc: 0.7047\n",
      "Epoch 476/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2378 - acc: 0.9042 - val_loss: 1.6329 - val_acc: 0.7193\n",
      "Epoch 477/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2318 - acc: 0.9074 - val_loss: 1.1703 - val_acc: 0.7406\n",
      "Epoch 478/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2357 - acc: 0.9056 - val_loss: 1.5144 - val_acc: 0.7275\n",
      "Epoch 479/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2334 - acc: 0.9063 - val_loss: 1.3055 - val_acc: 0.7381\n",
      "Epoch 480/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2315 - acc: 0.9076 - val_loss: 1.3593 - val_acc: 0.7275\n",
      "Epoch 481/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2322 - acc: 0.9071 - val_loss: 1.4366 - val_acc: 0.7118\n",
      "Epoch 482/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2335 - acc: 0.9066 - val_loss: 1.4217 - val_acc: 0.7201\n",
      "Epoch 483/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2325 - acc: 0.9064 - val_loss: 1.2932 - val_acc: 0.7327\n",
      "Epoch 484/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2296 - acc: 0.9082 - val_loss: 1.3244 - val_acc: 0.7334\n",
      "Epoch 485/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2342 - acc: 0.9069 - val_loss: 1.4639 - val_acc: 0.7087\n",
      "Epoch 486/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2336 - acc: 0.9061 - val_loss: 1.4126 - val_acc: 0.7294\n",
      "Epoch 487/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2343 - acc: 0.9056 - val_loss: 1.4967 - val_acc: 0.7215\n",
      "Epoch 488/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2348 - acc: 0.9047 - val_loss: 1.4240 - val_acc: 0.7237\n",
      "Epoch 489/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2335 - acc: 0.9066 - val_loss: 1.3399 - val_acc: 0.7337\n",
      "Epoch 490/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2306 - acc: 0.9079 - val_loss: 1.3975 - val_acc: 0.7258\n",
      "Epoch 491/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2287 - acc: 0.9089 - val_loss: 1.3411 - val_acc: 0.7367\n",
      "Epoch 492/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2295 - acc: 0.9081 - val_loss: 1.5486 - val_acc: 0.7185\n",
      "Epoch 493/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2314 - acc: 0.9075 - val_loss: 1.4135 - val_acc: 0.7344\n",
      "Epoch 494/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2296 - acc: 0.9073 - val_loss: 1.2868 - val_acc: 0.7356\n",
      "Epoch 495/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2325 - acc: 0.9068 - val_loss: 1.3160 - val_acc: 0.7379\n",
      "Epoch 496/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2327 - acc: 0.9065 - val_loss: 1.3075 - val_acc: 0.7210\n",
      "Epoch 497/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2281 - acc: 0.9085 - val_loss: 1.3972 - val_acc: 0.7285\n",
      "Epoch 498/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2285 - acc: 0.9083 - val_loss: 1.2832 - val_acc: 0.7365\n",
      "Epoch 499/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2305 - acc: 0.9071 - val_loss: 1.3978 - val_acc: 0.7299\n",
      "Epoch 500/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2279 - acc: 0.9083 - val_loss: 1.4944 - val_acc: 0.7330\n",
      "Epoch 501/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2287 - acc: 0.9087 - val_loss: 1.5210 - val_acc: 0.7188\n",
      "Epoch 502/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2299 - acc: 0.9074 - val_loss: 1.4446 - val_acc: 0.7217\n",
      "Epoch 503/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2288 - acc: 0.9082 - val_loss: 1.2841 - val_acc: 0.7430\n",
      "Epoch 504/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2320 - acc: 0.9061 - val_loss: 1.6545 - val_acc: 0.7096\n",
      "Epoch 505/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2320 - acc: 0.9072 - val_loss: 1.4458 - val_acc: 0.7228\n",
      "Epoch 506/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2292 - acc: 0.9088 - val_loss: 1.3133 - val_acc: 0.7382\n",
      "Epoch 507/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2253 - acc: 0.9091 - val_loss: 1.3154 - val_acc: 0.7435\n",
      "Epoch 508/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2294 - acc: 0.9076 - val_loss: 1.4967 - val_acc: 0.7086\n",
      "Epoch 509/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2283 - acc: 0.9082 - val_loss: 1.4418 - val_acc: 0.7380\n",
      "Epoch 510/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2293 - acc: 0.9080 - val_loss: 1.2996 - val_acc: 0.7330\n",
      "Epoch 511/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2255 - acc: 0.9095 - val_loss: 1.3748 - val_acc: 0.7369\n",
      "Epoch 512/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2273 - acc: 0.9088 - val_loss: 1.4187 - val_acc: 0.7226\n",
      "Epoch 513/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2255 - acc: 0.9090 - val_loss: 1.4122 - val_acc: 0.7323\n",
      "Epoch 514/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2263 - acc: 0.9089 - val_loss: 1.3689 - val_acc: 0.7338\n",
      "Epoch 515/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2235 - acc: 0.9099 - val_loss: 1.4803 - val_acc: 0.7342\n",
      "Epoch 516/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2233 - acc: 0.9103 - val_loss: 1.4384 - val_acc: 0.7326\n",
      "Epoch 517/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2289 - acc: 0.9078 - val_loss: 1.3048 - val_acc: 0.7350\n",
      "Epoch 518/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2264 - acc: 0.9086 - val_loss: 1.2824 - val_acc: 0.7300\n",
      "Epoch 519/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2270 - acc: 0.9088 - val_loss: 1.4837 - val_acc: 0.7301\n",
      "Epoch 520/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2255 - acc: 0.9100 - val_loss: 1.7000 - val_acc: 0.6955\n",
      "Epoch 521/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2242 - acc: 0.9099 - val_loss: 1.4992 - val_acc: 0.7202\n",
      "Epoch 522/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2239 - acc: 0.9114 - val_loss: 1.6151 - val_acc: 0.7101\n",
      "Epoch 523/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2238 - acc: 0.9105 - val_loss: 1.6275 - val_acc: 0.7090\n",
      "Epoch 524/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2227 - acc: 0.9106 - val_loss: 1.3958 - val_acc: 0.7301\n",
      "Epoch 525/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2240 - acc: 0.9101 - val_loss: 1.3682 - val_acc: 0.7219\n",
      "Epoch 526/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2217 - acc: 0.9110 - val_loss: 1.8075 - val_acc: 0.7044\n",
      "Epoch 527/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2231 - acc: 0.9104 - val_loss: 1.4830 - val_acc: 0.7268\n",
      "Epoch 528/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2209 - acc: 0.9110 - val_loss: 1.3839 - val_acc: 0.7363\n",
      "Epoch 529/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2237 - acc: 0.9099 - val_loss: 1.3653 - val_acc: 0.7354\n",
      "Epoch 530/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2241 - acc: 0.9103 - val_loss: 1.4203 - val_acc: 0.7299\n",
      "Epoch 531/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2226 - acc: 0.9106 - val_loss: 1.5437 - val_acc: 0.7101\n",
      "Epoch 532/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2219 - acc: 0.9109 - val_loss: 1.6395 - val_acc: 0.7129\n",
      "Epoch 533/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2225 - acc: 0.9109 - val_loss: 1.6258 - val_acc: 0.7079\n",
      "Epoch 534/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2206 - acc: 0.9118 - val_loss: 1.3302 - val_acc: 0.7372\n",
      "Epoch 535/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2206 - acc: 0.9113 - val_loss: 1.4650 - val_acc: 0.7285\n",
      "Epoch 536/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2211 - acc: 0.9118 - val_loss: 1.4329 - val_acc: 0.7204\n",
      "Epoch 537/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2222 - acc: 0.9106 - val_loss: 1.4078 - val_acc: 0.7295\n",
      "Epoch 538/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2198 - acc: 0.9117 - val_loss: 1.4874 - val_acc: 0.7225\n",
      "Epoch 539/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2216 - acc: 0.9111 - val_loss: 1.4413 - val_acc: 0.7207\n",
      "Epoch 540/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2211 - acc: 0.9118 - val_loss: 1.4196 - val_acc: 0.7288\n",
      "Epoch 541/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2201 - acc: 0.9124 - val_loss: 1.5407 - val_acc: 0.7220\n",
      "Epoch 542/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2179 - acc: 0.9126 - val_loss: 1.3026 - val_acc: 0.7387\n",
      "Epoch 543/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2201 - acc: 0.9108 - val_loss: 1.4443 - val_acc: 0.7332\n",
      "Epoch 544/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2204 - acc: 0.9114 - val_loss: 1.5469 - val_acc: 0.7187\n",
      "Epoch 545/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2194 - acc: 0.9114 - val_loss: 1.6283 - val_acc: 0.7121\n",
      "Epoch 546/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2209 - acc: 0.9112 - val_loss: 1.5353 - val_acc: 0.7135\n",
      "Epoch 547/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2218 - acc: 0.9111 - val_loss: 1.4948 - val_acc: 0.7208\n",
      "Epoch 548/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2154 - acc: 0.9138 - val_loss: 1.3747 - val_acc: 0.7400\n",
      "Epoch 549/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2157 - acc: 0.9143 - val_loss: 1.4305 - val_acc: 0.7311\n",
      "Epoch 550/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2190 - acc: 0.9121 - val_loss: 1.3437 - val_acc: 0.7306\n",
      "Epoch 551/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2193 - acc: 0.9125 - val_loss: 1.5347 - val_acc: 0.7272\n",
      "Epoch 552/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2167 - acc: 0.9134 - val_loss: 1.6099 - val_acc: 0.7117\n",
      "Epoch 553/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2172 - acc: 0.9137 - val_loss: 1.5090 - val_acc: 0.7287\n",
      "Epoch 554/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2153 - acc: 0.9143 - val_loss: 1.4420 - val_acc: 0.7315\n",
      "Epoch 555/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2179 - acc: 0.9125 - val_loss: 1.6405 - val_acc: 0.7215\n",
      "Epoch 556/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2165 - acc: 0.9133 - val_loss: 1.5453 - val_acc: 0.7144\n",
      "Epoch 557/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2195 - acc: 0.9119 - val_loss: 1.5170 - val_acc: 0.7117\n",
      "Epoch 558/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2184 - acc: 0.9120 - val_loss: 1.4331 - val_acc: 0.7292\n",
      "Epoch 559/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2153 - acc: 0.9135 - val_loss: 1.3434 - val_acc: 0.7302\n",
      "Epoch 560/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2188 - acc: 0.9125 - val_loss: 1.3902 - val_acc: 0.7373\n",
      "Epoch 561/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2177 - acc: 0.9123 - val_loss: 1.4043 - val_acc: 0.7193\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2170 - acc: 0.9129 - val_loss: 1.4366 - val_acc: 0.7389\n",
      "Epoch 563/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2134 - acc: 0.9150 - val_loss: 1.4918 - val_acc: 0.7323\n",
      "Epoch 564/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2160 - acc: 0.9124 - val_loss: 1.4190 - val_acc: 0.7308\n",
      "Epoch 565/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2172 - acc: 0.9117 - val_loss: 1.5773 - val_acc: 0.7200\n",
      "Epoch 566/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2161 - acc: 0.9136 - val_loss: 1.4799 - val_acc: 0.7230\n",
      "Epoch 567/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2156 - acc: 0.9142 - val_loss: 1.6274 - val_acc: 0.7170\n",
      "Epoch 568/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2158 - acc: 0.9132 - val_loss: 1.4056 - val_acc: 0.7263\n",
      "Epoch 569/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2161 - acc: 0.9142 - val_loss: 1.3514 - val_acc: 0.7228\n",
      "Epoch 570/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2155 - acc: 0.9146 - val_loss: 1.5077 - val_acc: 0.7207\n",
      "Epoch 571/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2140 - acc: 0.9143 - val_loss: 1.5562 - val_acc: 0.7224\n",
      "Epoch 572/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2119 - acc: 0.9145 - val_loss: 1.6481 - val_acc: 0.7229\n",
      "Epoch 573/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2154 - acc: 0.9129 - val_loss: 1.3128 - val_acc: 0.7475\n",
      "Epoch 574/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2143 - acc: 0.9131 - val_loss: 1.5908 - val_acc: 0.7177\n",
      "Epoch 575/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2149 - acc: 0.9135 - val_loss: 1.5618 - val_acc: 0.7173\n",
      "Epoch 576/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2120 - acc: 0.9155 - val_loss: 1.4446 - val_acc: 0.7337\n",
      "Epoch 577/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2141 - acc: 0.9133 - val_loss: 1.3511 - val_acc: 0.7447\n",
      "Epoch 578/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2158 - acc: 0.9133 - val_loss: 1.4134 - val_acc: 0.7411\n",
      "Epoch 579/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2136 - acc: 0.9143 - val_loss: 1.6032 - val_acc: 0.7122\n",
      "Epoch 580/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2123 - acc: 0.9156 - val_loss: 1.3541 - val_acc: 0.7396\n",
      "Epoch 581/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2085 - acc: 0.9160 - val_loss: 1.5667 - val_acc: 0.7189\n",
      "Epoch 582/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2100 - acc: 0.9153 - val_loss: 1.4187 - val_acc: 0.7384\n",
      "Epoch 583/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2093 - acc: 0.9162 - val_loss: 1.4404 - val_acc: 0.7377\n",
      "Epoch 584/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2112 - acc: 0.9168 - val_loss: 1.5564 - val_acc: 0.7179\n",
      "Epoch 585/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2142 - acc: 0.9139 - val_loss: 1.7422 - val_acc: 0.7106\n",
      "Epoch 586/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2117 - acc: 0.9157 - val_loss: 1.5861 - val_acc: 0.7261\n",
      "Epoch 587/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2130 - acc: 0.9150 - val_loss: 1.5026 - val_acc: 0.7220\n",
      "Epoch 588/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2114 - acc: 0.9157 - val_loss: 1.3756 - val_acc: 0.7325\n",
      "Epoch 589/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2094 - acc: 0.9159 - val_loss: 1.4130 - val_acc: 0.7326\n",
      "Epoch 590/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2160 - acc: 0.9131 - val_loss: 1.5713 - val_acc: 0.7269\n",
      "Epoch 591/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2105 - acc: 0.9159 - val_loss: 1.6657 - val_acc: 0.7258\n",
      "Epoch 592/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2136 - acc: 0.9149 - val_loss: 1.5207 - val_acc: 0.7212\n",
      "Epoch 593/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2110 - acc: 0.9149 - val_loss: 1.5710 - val_acc: 0.7249\n",
      "Epoch 594/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2131 - acc: 0.9146 - val_loss: 1.4786 - val_acc: 0.7268\n",
      "Epoch 595/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2131 - acc: 0.9149 - val_loss: 1.6487 - val_acc: 0.6951\n",
      "Epoch 596/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2124 - acc: 0.9146 - val_loss: 1.4150 - val_acc: 0.7413\n",
      "Epoch 597/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2089 - acc: 0.9169 - val_loss: 1.4442 - val_acc: 0.7305\n",
      "Epoch 598/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2112 - acc: 0.9156 - val_loss: 1.7508 - val_acc: 0.7130\n",
      "Epoch 599/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2075 - acc: 0.9173 - val_loss: 1.3438 - val_acc: 0.7431\n",
      "Epoch 600/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2105 - acc: 0.9148 - val_loss: 1.4739 - val_acc: 0.7235\n",
      "Epoch 601/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2108 - acc: 0.9152 - val_loss: 1.4570 - val_acc: 0.7293\n",
      "Epoch 602/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2109 - acc: 0.9157 - val_loss: 1.4332 - val_acc: 0.7365\n",
      "Epoch 603/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2077 - acc: 0.9171 - val_loss: 1.4617 - val_acc: 0.7267\n",
      "Epoch 604/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2117 - acc: 0.9151 - val_loss: 1.3912 - val_acc: 0.7271\n",
      "Epoch 605/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2121 - acc: 0.9151 - val_loss: 1.3772 - val_acc: 0.7404\n",
      "Epoch 606/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2078 - acc: 0.9172 - val_loss: 1.4520 - val_acc: 0.7332\n",
      "Epoch 607/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2100 - acc: 0.9158 - val_loss: 1.4490 - val_acc: 0.7289\n",
      "Epoch 608/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2134 - acc: 0.9143 - val_loss: 1.4611 - val_acc: 0.7254\n",
      "Epoch 609/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2068 - acc: 0.9171 - val_loss: 1.7306 - val_acc: 0.7137\n",
      "Epoch 610/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2061 - acc: 0.9167 - val_loss: 1.3806 - val_acc: 0.7349\n",
      "Epoch 611/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2057 - acc: 0.9173 - val_loss: 1.6744 - val_acc: 0.7131\n",
      "Epoch 612/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2066 - acc: 0.9168 - val_loss: 1.2955 - val_acc: 0.7392\n",
      "Epoch 613/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2080 - acc: 0.9167 - val_loss: 1.4414 - val_acc: 0.7320\n",
      "Epoch 614/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2057 - acc: 0.9176 - val_loss: 1.4434 - val_acc: 0.7347\n",
      "Epoch 615/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2046 - acc: 0.9177 - val_loss: 1.3980 - val_acc: 0.7322\n",
      "Epoch 616/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2043 - acc: 0.9174 - val_loss: 1.6857 - val_acc: 0.7087\n",
      "Epoch 617/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2115 - acc: 0.9154 - val_loss: 1.4750 - val_acc: 0.7366\n",
      "Epoch 618/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2106 - acc: 0.9146 - val_loss: 1.4472 - val_acc: 0.7357\n",
      "Epoch 619/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2053 - acc: 0.9173 - val_loss: 1.2965 - val_acc: 0.7366\n",
      "Epoch 620/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2073 - acc: 0.9176 - val_loss: 1.5241 - val_acc: 0.7243\n",
      "Epoch 621/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2056 - acc: 0.9175 - val_loss: 1.4538 - val_acc: 0.7386\n",
      "Epoch 622/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2082 - acc: 0.9165 - val_loss: 1.5854 - val_acc: 0.7113\n",
      "Epoch 623/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2091 - acc: 0.9166 - val_loss: 1.5495 - val_acc: 0.7287\n",
      "Epoch 624/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2072 - acc: 0.9165 - val_loss: 1.5161 - val_acc: 0.7298\n",
      "Epoch 625/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2055 - acc: 0.9177 - val_loss: 1.5575 - val_acc: 0.7248\n",
      "Epoch 626/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2011 - acc: 0.9199 - val_loss: 1.4561 - val_acc: 0.7334\n",
      "Epoch 627/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2057 - acc: 0.9171 - val_loss: 1.4281 - val_acc: 0.7336\n",
      "Epoch 628/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2047 - acc: 0.9174 - val_loss: 1.5266 - val_acc: 0.7328\n",
      "Epoch 629/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2032 - acc: 0.9188 - val_loss: 1.3471 - val_acc: 0.7418\n",
      "Epoch 630/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2067 - acc: 0.9172 - val_loss: 1.5576 - val_acc: 0.7251\n",
      "Epoch 631/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2050 - acc: 0.9170 - val_loss: 1.5348 - val_acc: 0.7326\n",
      "Epoch 632/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2023 - acc: 0.9188 - val_loss: 1.5818 - val_acc: 0.7261\n",
      "Epoch 633/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2044 - acc: 0.9182 - val_loss: 1.4682 - val_acc: 0.7238\n",
      "Epoch 634/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2044 - acc: 0.9179 - val_loss: 1.4076 - val_acc: 0.7388\n",
      "Epoch 635/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2033 - acc: 0.9185 - val_loss: 1.3932 - val_acc: 0.7429\n",
      "Epoch 636/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2016 - acc: 0.9191 - val_loss: 1.4738 - val_acc: 0.7300\n",
      "Epoch 637/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2052 - acc: 0.9185 - val_loss: 1.6573 - val_acc: 0.7239\n",
      "Epoch 638/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2056 - acc: 0.9174 - val_loss: 1.5336 - val_acc: 0.7195\n",
      "Epoch 639/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2043 - acc: 0.9192 - val_loss: 1.3736 - val_acc: 0.7407\n",
      "Epoch 640/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2058 - acc: 0.9175 - val_loss: 1.7272 - val_acc: 0.6960\n",
      "Epoch 641/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2029 - acc: 0.9194 - val_loss: 1.6004 - val_acc: 0.7127\n",
      "Epoch 642/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2031 - acc: 0.9182 - val_loss: 1.4513 - val_acc: 0.7387\n",
      "Epoch 643/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2026 - acc: 0.9186 - val_loss: 1.3842 - val_acc: 0.7337\n",
      "Epoch 644/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2015 - acc: 0.9187 - val_loss: 1.7404 - val_acc: 0.7013\n",
      "Epoch 645/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2054 - acc: 0.9179 - val_loss: 1.4917 - val_acc: 0.7337\n",
      "Epoch 646/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2028 - acc: 0.9191 - val_loss: 1.5497 - val_acc: 0.7284\n",
      "Epoch 647/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1995 - acc: 0.9209 - val_loss: 1.3516 - val_acc: 0.7342\n",
      "Epoch 648/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2012 - acc: 0.9203 - val_loss: 1.4721 - val_acc: 0.7290\n",
      "Epoch 649/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2023 - acc: 0.9191 - val_loss: 1.4748 - val_acc: 0.7358\n",
      "Epoch 650/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2024 - acc: 0.9194 - val_loss: 1.4499 - val_acc: 0.7303\n",
      "Epoch 651/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2018 - acc: 0.9196 - val_loss: 1.3951 - val_acc: 0.7445\n",
      "Epoch 652/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2023 - acc: 0.9186 - val_loss: 1.3468 - val_acc: 0.7339\n",
      "Epoch 653/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2016 - acc: 0.9185 - val_loss: 1.6294 - val_acc: 0.7343\n",
      "Epoch 654/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2021 - acc: 0.9190 - val_loss: 1.7275 - val_acc: 0.7056\n",
      "Epoch 655/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2020 - acc: 0.9191 - val_loss: 1.3633 - val_acc: 0.7468\n",
      "Epoch 656/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1975 - acc: 0.9204 - val_loss: 1.7128 - val_acc: 0.7196\n",
      "Epoch 657/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2021 - acc: 0.9194 - val_loss: 1.5066 - val_acc: 0.7257\n",
      "Epoch 658/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2026 - acc: 0.9187 - val_loss: 1.7347 - val_acc: 0.7037\n",
      "Epoch 659/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1999 - acc: 0.9198 - val_loss: 1.4993 - val_acc: 0.7396\n",
      "Epoch 660/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1970 - acc: 0.9203 - val_loss: 1.5847 - val_acc: 0.7281\n",
      "Epoch 661/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2013 - acc: 0.9197 - val_loss: 1.5254 - val_acc: 0.7132\n",
      "Epoch 662/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2006 - acc: 0.9192 - val_loss: 1.6703 - val_acc: 0.7258\n",
      "Epoch 663/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1973 - acc: 0.9210 - val_loss: 1.4746 - val_acc: 0.7213\n",
      "Epoch 664/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2010 - acc: 0.9193 - val_loss: 1.3446 - val_acc: 0.7429\n",
      "Epoch 665/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1981 - acc: 0.9209 - val_loss: 1.4704 - val_acc: 0.7420\n",
      "Epoch 666/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2001 - acc: 0.9198 - val_loss: 1.8001 - val_acc: 0.7089\n",
      "Epoch 667/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2015 - acc: 0.9198 - val_loss: 1.4223 - val_acc: 0.7394\n",
      "Epoch 668/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1977 - acc: 0.9217 - val_loss: 1.5782 - val_acc: 0.7306\n",
      "Epoch 669/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1992 - acc: 0.9201 - val_loss: 1.5610 - val_acc: 0.7256\n",
      "Epoch 670/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1974 - acc: 0.9213 - val_loss: 1.4880 - val_acc: 0.7322\n",
      "Epoch 671/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2004 - acc: 0.9192 - val_loss: 1.4733 - val_acc: 0.7288\n",
      "Epoch 672/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1986 - acc: 0.9204 - val_loss: 1.5281 - val_acc: 0.7336\n",
      "Epoch 673/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1963 - acc: 0.9215 - val_loss: 1.4278 - val_acc: 0.7336\n",
      "Epoch 674/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1952 - acc: 0.9214 - val_loss: 1.6054 - val_acc: 0.7196\n",
      "Epoch 675/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1988 - acc: 0.9202 - val_loss: 1.6482 - val_acc: 0.7142\n",
      "Epoch 676/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1992 - acc: 0.9204 - val_loss: 1.5027 - val_acc: 0.7371\n",
      "Epoch 677/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1958 - acc: 0.9215 - val_loss: 1.6231 - val_acc: 0.7176\n",
      "Epoch 678/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1985 - acc: 0.9215 - val_loss: 1.4721 - val_acc: 0.7356\n",
      "Epoch 679/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1965 - acc: 0.9217 - val_loss: 1.6304 - val_acc: 0.7223\n",
      "Epoch 680/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1959 - acc: 0.9213 - val_loss: 1.5385 - val_acc: 0.7333\n",
      "Epoch 681/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1953 - acc: 0.9222 - val_loss: 1.5635 - val_acc: 0.7186\n",
      "Epoch 682/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1988 - acc: 0.9200 - val_loss: 1.6038 - val_acc: 0.7278\n",
      "Epoch 683/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1976 - acc: 0.9201 - val_loss: 1.6135 - val_acc: 0.7274\n",
      "Epoch 684/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1969 - acc: 0.9211 - val_loss: 1.6259 - val_acc: 0.7215\n",
      "Epoch 685/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1988 - acc: 0.9202 - val_loss: 1.7117 - val_acc: 0.7015\n",
      "Epoch 686/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1954 - acc: 0.9215 - val_loss: 1.6561 - val_acc: 0.7278\n",
      "Epoch 687/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1970 - acc: 0.9207 - val_loss: 1.4883 - val_acc: 0.7292\n",
      "Epoch 688/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1980 - acc: 0.9210 - val_loss: 1.5732 - val_acc: 0.7363\n",
      "Epoch 689/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1973 - acc: 0.9205 - val_loss: 1.8362 - val_acc: 0.7031\n",
      "Epoch 690/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1961 - acc: 0.9212 - val_loss: 1.5277 - val_acc: 0.7266\n",
      "Epoch 691/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1940 - acc: 0.9229 - val_loss: 2.0807 - val_acc: 0.6862\n",
      "Epoch 692/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1959 - acc: 0.9214 - val_loss: 1.4204 - val_acc: 0.7398\n",
      "Epoch 693/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1944 - acc: 0.9224 - val_loss: 1.6131 - val_acc: 0.7308\n",
      "Epoch 694/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1929 - acc: 0.9232 - val_loss: 1.5313 - val_acc: 0.7323\n",
      "Epoch 695/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1964 - acc: 0.9220 - val_loss: 1.4476 - val_acc: 0.7373\n",
      "Epoch 696/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1933 - acc: 0.9223 - val_loss: 1.6458 - val_acc: 0.7261\n",
      "Epoch 697/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1951 - acc: 0.9219 - val_loss: 1.4511 - val_acc: 0.7364\n",
      "Epoch 698/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1946 - acc: 0.9227 - val_loss: 1.6444 - val_acc: 0.7187\n",
      "Epoch 699/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1950 - acc: 0.9221 - val_loss: 1.5019 - val_acc: 0.7369\n",
      "Epoch 700/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1942 - acc: 0.9228 - val_loss: 1.5360 - val_acc: 0.7305\n",
      "Epoch 701/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1934 - acc: 0.9229 - val_loss: 1.5353 - val_acc: 0.7355\n",
      "Epoch 702/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1952 - acc: 0.9217 - val_loss: 1.8810 - val_acc: 0.7013\n",
      "Epoch 703/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1935 - acc: 0.9228 - val_loss: 1.4545 - val_acc: 0.7423\n",
      "Epoch 704/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1966 - acc: 0.9209 - val_loss: 1.6611 - val_acc: 0.7227\n",
      "Epoch 705/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1944 - acc: 0.9219 - val_loss: 1.6467 - val_acc: 0.7218\n",
      "Epoch 706/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1951 - acc: 0.9220 - val_loss: 1.6793 - val_acc: 0.7138\n",
      "Epoch 707/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1929 - acc: 0.9225 - val_loss: 1.5420 - val_acc: 0.7354\n",
      "Epoch 708/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1921 - acc: 0.9239 - val_loss: 1.4837 - val_acc: 0.7429\n",
      "Epoch 709/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1916 - acc: 0.9228 - val_loss: 1.5710 - val_acc: 0.7335\n",
      "Epoch 710/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1961 - acc: 0.9216 - val_loss: 1.5508 - val_acc: 0.7301\n",
      "Epoch 711/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1915 - acc: 0.9229 - val_loss: 1.4876 - val_acc: 0.7322\n",
      "Epoch 712/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1902 - acc: 0.9237 - val_loss: 1.5126 - val_acc: 0.7402\n",
      "Epoch 713/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1958 - acc: 0.9224 - val_loss: 1.4875 - val_acc: 0.7360\n",
      "Epoch 714/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1915 - acc: 0.9233 - val_loss: 1.7981 - val_acc: 0.7170\n",
      "Epoch 715/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1947 - acc: 0.9216 - val_loss: 1.4407 - val_acc: 0.7404\n",
      "Epoch 716/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1916 - acc: 0.9232 - val_loss: 1.7363 - val_acc: 0.6984\n",
      "Epoch 717/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1941 - acc: 0.9223 - val_loss: 1.5224 - val_acc: 0.7314\n",
      "Epoch 718/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1916 - acc: 0.9229 - val_loss: 1.3865 - val_acc: 0.7375\n",
      "Epoch 719/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1913 - acc: 0.9233 - val_loss: 1.4515 - val_acc: 0.7353\n",
      "Epoch 720/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1936 - acc: 0.9222 - val_loss: 1.6372 - val_acc: 0.7139\n",
      "Epoch 721/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1925 - acc: 0.9229 - val_loss: 1.7614 - val_acc: 0.7193\n",
      "Epoch 722/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1916 - acc: 0.9235 - val_loss: 1.6414 - val_acc: 0.7318\n",
      "Epoch 723/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1932 - acc: 0.9229 - val_loss: 1.4823 - val_acc: 0.7350\n",
      "Epoch 724/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1903 - acc: 0.9234 - val_loss: 1.4045 - val_acc: 0.7376\n",
      "Epoch 725/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1897 - acc: 0.9240 - val_loss: 1.5820 - val_acc: 0.7368\n",
      "Epoch 726/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1900 - acc: 0.9241 - val_loss: 1.6929 - val_acc: 0.7259\n",
      "Epoch 727/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1930 - acc: 0.9233 - val_loss: 1.6466 - val_acc: 0.7248\n",
      "Epoch 728/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1895 - acc: 0.9246 - val_loss: 1.5636 - val_acc: 0.7321\n",
      "Epoch 729/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1904 - acc: 0.9239 - val_loss: 1.8023 - val_acc: 0.7168\n",
      "Epoch 730/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1876 - acc: 0.9252 - val_loss: 1.3825 - val_acc: 0.7356\n",
      "Epoch 731/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1900 - acc: 0.9237 - val_loss: 1.5978 - val_acc: 0.7168\n",
      "Epoch 732/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1905 - acc: 0.9249 - val_loss: 1.4360 - val_acc: 0.7451\n",
      "Epoch 733/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1920 - acc: 0.9232 - val_loss: 1.8084 - val_acc: 0.7202\n",
      "Epoch 734/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1871 - acc: 0.9255 - val_loss: 1.6642 - val_acc: 0.7196\n",
      "Epoch 735/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1901 - acc: 0.9242 - val_loss: 1.4953 - val_acc: 0.7368\n",
      "Epoch 736/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1914 - acc: 0.9229 - val_loss: 1.8329 - val_acc: 0.7047\n",
      "Epoch 737/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1884 - acc: 0.9257 - val_loss: 1.6036 - val_acc: 0.7297\n",
      "Epoch 738/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1896 - acc: 0.9248 - val_loss: 1.4998 - val_acc: 0.7401\n",
      "Epoch 739/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1885 - acc: 0.9251 - val_loss: 1.4633 - val_acc: 0.7432\n",
      "Epoch 740/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1862 - acc: 0.9252 - val_loss: 1.6902 - val_acc: 0.7272\n",
      "Epoch 741/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1870 - acc: 0.9252 - val_loss: 1.5111 - val_acc: 0.7408\n",
      "Epoch 742/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1897 - acc: 0.9239 - val_loss: 1.5566 - val_acc: 0.7292\n",
      "Epoch 743/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1900 - acc: 0.9254 - val_loss: 1.5331 - val_acc: 0.7411\n",
      "Epoch 744/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1894 - acc: 0.9243 - val_loss: 1.5316 - val_acc: 0.7339\n",
      "Epoch 745/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1866 - acc: 0.9254 - val_loss: 1.3878 - val_acc: 0.7528\n",
      "Epoch 746/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1869 - acc: 0.9252 - val_loss: 1.6769 - val_acc: 0.7325\n",
      "Epoch 747/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1856 - acc: 0.9255 - val_loss: 1.5561 - val_acc: 0.7231\n",
      "Epoch 748/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1865 - acc: 0.9256 - val_loss: 1.6420 - val_acc: 0.7223\n",
      "Epoch 749/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1881 - acc: 0.9243 - val_loss: 1.5800 - val_acc: 0.7373\n",
      "Epoch 750/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1899 - acc: 0.9244 - val_loss: 1.5878 - val_acc: 0.7412\n",
      "Epoch 751/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1872 - acc: 0.9245 - val_loss: 1.7082 - val_acc: 0.7134\n",
      "Epoch 752/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1873 - acc: 0.9250 - val_loss: 1.5961 - val_acc: 0.7143\n",
      "Epoch 753/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1862 - acc: 0.9261 - val_loss: 1.5712 - val_acc: 0.7358\n",
      "Epoch 754/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1876 - acc: 0.9256 - val_loss: 1.7386 - val_acc: 0.7081\n",
      "Epoch 755/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1836 - acc: 0.9268 - val_loss: 1.4076 - val_acc: 0.7439\n",
      "Epoch 756/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1871 - acc: 0.9258 - val_loss: 1.5329 - val_acc: 0.7403\n",
      "Epoch 757/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1880 - acc: 0.9249 - val_loss: 1.6370 - val_acc: 0.7296\n",
      "Epoch 758/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1867 - acc: 0.9256 - val_loss: 1.5769 - val_acc: 0.7318\n",
      "Epoch 759/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1877 - acc: 0.9250 - val_loss: 1.6945 - val_acc: 0.7204\n",
      "Epoch 760/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1837 - acc: 0.9256 - val_loss: 1.4389 - val_acc: 0.7368\n",
      "Epoch 761/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1867 - acc: 0.9255 - val_loss: 1.4653 - val_acc: 0.7345\n",
      "Epoch 762/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1843 - acc: 0.9266 - val_loss: 1.7303 - val_acc: 0.7039\n",
      "Epoch 763/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1864 - acc: 0.9258 - val_loss: 1.6416 - val_acc: 0.7304\n",
      "Epoch 764/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1855 - acc: 0.9255 - val_loss: 1.3442 - val_acc: 0.7520\n",
      "Epoch 765/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1836 - acc: 0.9262 - val_loss: 1.6131 - val_acc: 0.7267\n",
      "Epoch 766/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1825 - acc: 0.9266 - val_loss: 1.9336 - val_acc: 0.7034\n",
      "Epoch 767/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1865 - acc: 0.9259 - val_loss: 1.6354 - val_acc: 0.7079\n",
      "Epoch 768/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1862 - acc: 0.9254 - val_loss: 1.7992 - val_acc: 0.7070\n",
      "Epoch 769/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1861 - acc: 0.9257 - val_loss: 1.6403 - val_acc: 0.7336\n",
      "Epoch 770/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1816 - acc: 0.9270 - val_loss: 1.5350 - val_acc: 0.7349\n",
      "Epoch 771/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1823 - acc: 0.9276 - val_loss: 1.6295 - val_acc: 0.7254\n",
      "Epoch 772/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1850 - acc: 0.9265 - val_loss: 1.7768 - val_acc: 0.7163\n",
      "Epoch 773/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1844 - acc: 0.9265 - val_loss: 1.5861 - val_acc: 0.7325\n",
      "Epoch 774/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1864 - acc: 0.9248 - val_loss: 1.5737 - val_acc: 0.7291\n",
      "Epoch 775/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1835 - acc: 0.9260 - val_loss: 1.6428 - val_acc: 0.7252\n",
      "Epoch 776/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1839 - acc: 0.9264 - val_loss: 1.4521 - val_acc: 0.7464\n",
      "Epoch 777/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1839 - acc: 0.9263 - val_loss: 1.5539 - val_acc: 0.7359\n",
      "Epoch 778/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1824 - acc: 0.9270 - val_loss: 1.6390 - val_acc: 0.7259\n",
      "Epoch 779/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1843 - acc: 0.9265 - val_loss: 1.5071 - val_acc: 0.7425\n",
      "Epoch 780/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1822 - acc: 0.9275 - val_loss: 1.5741 - val_acc: 0.7267\n",
      "Epoch 781/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1813 - acc: 0.9270 - val_loss: 1.5236 - val_acc: 0.7399\n",
      "Epoch 782/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1821 - acc: 0.9278 - val_loss: 1.6648 - val_acc: 0.7265\n",
      "Epoch 783/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1841 - acc: 0.9263 - val_loss: 1.8066 - val_acc: 0.7172\n",
      "Epoch 784/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1836 - acc: 0.9275 - val_loss: 1.6288 - val_acc: 0.7319\n",
      "Epoch 785/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1819 - acc: 0.9271 - val_loss: 1.6833 - val_acc: 0.7315\n",
      "Epoch 786/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1826 - acc: 0.9273 - val_loss: 1.5615 - val_acc: 0.7371\n",
      "Epoch 787/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1808 - acc: 0.9285 - val_loss: 1.9472 - val_acc: 0.6963\n",
      "Epoch 788/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1814 - acc: 0.9274 - val_loss: 1.7247 - val_acc: 0.7282\n",
      "Epoch 789/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1850 - acc: 0.9258 - val_loss: 1.4986 - val_acc: 0.7375\n",
      "Epoch 790/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1809 - acc: 0.9285 - val_loss: 1.7535 - val_acc: 0.7109\n",
      "Epoch 791/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1802 - acc: 0.9280 - val_loss: 1.5054 - val_acc: 0.7325\n",
      "Epoch 792/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1814 - acc: 0.9270 - val_loss: 1.7089 - val_acc: 0.7150\n",
      "Epoch 793/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1827 - acc: 0.9277 - val_loss: 1.4037 - val_acc: 0.7469\n",
      "Epoch 794/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1795 - acc: 0.9280 - val_loss: 1.6299 - val_acc: 0.7298\n",
      "Epoch 795/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1794 - acc: 0.9282 - val_loss: 1.8310 - val_acc: 0.7211\n",
      "Epoch 796/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1811 - acc: 0.9283 - val_loss: 1.6888 - val_acc: 0.7263\n",
      "Epoch 797/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1800 - acc: 0.9285 - val_loss: 1.9595 - val_acc: 0.7175\n",
      "Epoch 798/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1810 - acc: 0.9283 - val_loss: 1.9164 - val_acc: 0.7082\n",
      "Epoch 799/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1819 - acc: 0.9271 - val_loss: 1.6775 - val_acc: 0.7271\n",
      "Epoch 800/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1779 - acc: 0.9296 - val_loss: 1.5307 - val_acc: 0.7380\n",
      "Epoch 801/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1798 - acc: 0.9281 - val_loss: 1.6150 - val_acc: 0.7295\n",
      "Epoch 802/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1823 - acc: 0.9270 - val_loss: 1.5401 - val_acc: 0.7384\n",
      "Epoch 803/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1809 - acc: 0.9271 - val_loss: 1.7757 - val_acc: 0.7218\n",
      "Epoch 804/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1814 - acc: 0.9278 - val_loss: 1.6985 - val_acc: 0.7221\n",
      "Epoch 805/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1831 - acc: 0.9265 - val_loss: 1.7667 - val_acc: 0.7135\n",
      "Epoch 806/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1839 - acc: 0.9259 - val_loss: 1.3742 - val_acc: 0.7406\n",
      "Epoch 807/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1801 - acc: 0.9288 - val_loss: 1.4781 - val_acc: 0.7457\n",
      "Epoch 808/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1791 - acc: 0.9294 - val_loss: 1.7538 - val_acc: 0.7254\n",
      "Epoch 809/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1800 - acc: 0.9275 - val_loss: 1.4010 - val_acc: 0.7434\n",
      "Epoch 810/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1806 - acc: 0.9279 - val_loss: 1.5364 - val_acc: 0.7440\n",
      "Epoch 811/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1782 - acc: 0.9295 - val_loss: 1.5790 - val_acc: 0.7354\n",
      "Epoch 812/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1833 - acc: 0.9268 - val_loss: 1.5887 - val_acc: 0.7323\n",
      "Epoch 813/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1804 - acc: 0.9275 - val_loss: 1.6294 - val_acc: 0.7256\n",
      "Epoch 814/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1797 - acc: 0.9290 - val_loss: 1.5240 - val_acc: 0.7432\n",
      "Epoch 815/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1790 - acc: 0.9282 - val_loss: 1.9385 - val_acc: 0.7035\n",
      "Epoch 816/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1822 - acc: 0.9274 - val_loss: 1.8465 - val_acc: 0.7169\n",
      "Epoch 817/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1747 - acc: 0.9303 - val_loss: 1.4885 - val_acc: 0.7435\n",
      "Epoch 818/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1797 - acc: 0.9292 - val_loss: 1.7357 - val_acc: 0.7289\n",
      "Epoch 819/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1768 - acc: 0.9298 - val_loss: 1.4620 - val_acc: 0.7483\n",
      "Epoch 820/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1784 - acc: 0.9288 - val_loss: 1.5497 - val_acc: 0.7361\n",
      "Epoch 821/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1754 - acc: 0.9295 - val_loss: 1.4316 - val_acc: 0.7440\n",
      "Epoch 822/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1792 - acc: 0.9281 - val_loss: 1.5702 - val_acc: 0.7420\n",
      "Epoch 823/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1775 - acc: 0.9293 - val_loss: 1.6022 - val_acc: 0.7271\n",
      "Epoch 824/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1774 - acc: 0.9292 - val_loss: 1.5542 - val_acc: 0.7335\n",
      "Epoch 825/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1760 - acc: 0.9292 - val_loss: 1.5612 - val_acc: 0.7378\n",
      "Epoch 826/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1762 - acc: 0.9300 - val_loss: 1.6257 - val_acc: 0.7373\n",
      "Epoch 827/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1768 - acc: 0.9297 - val_loss: 1.5671 - val_acc: 0.7387\n",
      "Epoch 828/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1811 - acc: 0.9283 - val_loss: 1.5906 - val_acc: 0.7367\n",
      "Epoch 829/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1754 - acc: 0.9298 - val_loss: 1.5137 - val_acc: 0.7375\n",
      "Epoch 830/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1771 - acc: 0.9293 - val_loss: 1.5179 - val_acc: 0.7274\n",
      "Epoch 831/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1761 - acc: 0.9298 - val_loss: 1.5897 - val_acc: 0.7349\n",
      "Epoch 832/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1765 - acc: 0.9298 - val_loss: 1.7055 - val_acc: 0.7253\n",
      "Epoch 833/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1786 - acc: 0.9295 - val_loss: 1.4746 - val_acc: 0.7444\n",
      "Epoch 834/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1744 - acc: 0.9312 - val_loss: 1.5421 - val_acc: 0.7482\n",
      "Epoch 835/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1755 - acc: 0.9299 - val_loss: 1.5590 - val_acc: 0.7396\n",
      "Epoch 836/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1777 - acc: 0.9298 - val_loss: 1.5067 - val_acc: 0.7365\n",
      "Epoch 837/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1747 - acc: 0.9305 - val_loss: 1.5482 - val_acc: 0.7375\n",
      "Epoch 838/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1759 - acc: 0.9302 - val_loss: 1.7053 - val_acc: 0.7106\n",
      "Epoch 839/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1735 - acc: 0.9312 - val_loss: 1.6871 - val_acc: 0.7347\n",
      "Epoch 840/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1780 - acc: 0.9293 - val_loss: 1.7559 - val_acc: 0.7166\n",
      "Epoch 841/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1783 - acc: 0.9293 - val_loss: 1.7005 - val_acc: 0.7261\n",
      "Epoch 842/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1759 - acc: 0.9303 - val_loss: 1.7061 - val_acc: 0.7275\n",
      "Epoch 843/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1780 - acc: 0.9297 - val_loss: 1.7693 - val_acc: 0.7208\n",
      "Epoch 844/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1742 - acc: 0.9306 - val_loss: 1.4755 - val_acc: 0.7431\n",
      "Epoch 845/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1766 - acc: 0.9284 - val_loss: 1.4850 - val_acc: 0.7472\n",
      "Epoch 846/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1778 - acc: 0.9301 - val_loss: 1.6845 - val_acc: 0.7285\n",
      "Epoch 847/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1747 - acc: 0.9308 - val_loss: 1.7803 - val_acc: 0.7046\n",
      "Epoch 848/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1728 - acc: 0.9312 - val_loss: 1.5198 - val_acc: 0.7432\n",
      "Epoch 849/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1790 - acc: 0.9289 - val_loss: 1.4478 - val_acc: 0.7453\n",
      "Epoch 850/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1745 - acc: 0.9306 - val_loss: 1.5450 - val_acc: 0.7198\n",
      "Epoch 851/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1788 - acc: 0.9297 - val_loss: 1.7605 - val_acc: 0.7214\n",
      "Epoch 852/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1745 - acc: 0.9309 - val_loss: 1.6474 - val_acc: 0.7322\n",
      "Epoch 853/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1739 - acc: 0.9305 - val_loss: 1.5295 - val_acc: 0.7413\n",
      "Epoch 854/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1772 - acc: 0.9297 - val_loss: 1.6030 - val_acc: 0.7365\n",
      "Epoch 855/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1715 - acc: 0.9327 - val_loss: 1.5154 - val_acc: 0.7403\n",
      "Epoch 856/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1671 - acc: 0.9326 - val_loss: 1.4579 - val_acc: 0.7420\n",
      "Epoch 857/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1721 - acc: 0.9304 - val_loss: 1.6199 - val_acc: 0.7196\n",
      "Epoch 858/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1753 - acc: 0.9293 - val_loss: 1.4602 - val_acc: 0.7425\n",
      "Epoch 859/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1734 - acc: 0.9312 - val_loss: 1.5545 - val_acc: 0.7363\n",
      "Epoch 860/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1733 - acc: 0.9311 - val_loss: 1.4523 - val_acc: 0.7457\n",
      "Epoch 861/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1712 - acc: 0.9330 - val_loss: 1.5800 - val_acc: 0.7396\n",
      "Epoch 862/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1774 - acc: 0.9293 - val_loss: 1.5933 - val_acc: 0.7357\n",
      "Epoch 863/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1755 - acc: 0.9303 - val_loss: 1.5072 - val_acc: 0.7439\n",
      "Epoch 864/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1729 - acc: 0.9311 - val_loss: 1.6208 - val_acc: 0.7194\n",
      "Epoch 865/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1751 - acc: 0.9303 - val_loss: 1.4753 - val_acc: 0.7513\n",
      "Epoch 866/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1726 - acc: 0.9310 - val_loss: 1.5705 - val_acc: 0.7337\n",
      "Epoch 867/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1730 - acc: 0.9306 - val_loss: 1.6024 - val_acc: 0.7258\n",
      "Epoch 868/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1728 - acc: 0.9314 - val_loss: 1.7911 - val_acc: 0.7156\n",
      "Epoch 869/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1748 - acc: 0.9301 - val_loss: 1.6675 - val_acc: 0.7287\n",
      "Epoch 870/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1721 - acc: 0.9312 - val_loss: 1.6133 - val_acc: 0.7332\n",
      "Epoch 871/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1711 - acc: 0.9316 - val_loss: 1.6028 - val_acc: 0.7310\n",
      "Epoch 872/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1746 - acc: 0.9312 - val_loss: 1.8603 - val_acc: 0.7165\n",
      "Epoch 873/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1745 - acc: 0.9308 - val_loss: 1.5432 - val_acc: 0.7401\n",
      "Epoch 874/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1718 - acc: 0.9317 - val_loss: 1.6016 - val_acc: 0.7339\n",
      "Epoch 875/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1715 - acc: 0.9315 - val_loss: 1.6981 - val_acc: 0.7275\n",
      "Epoch 876/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1704 - acc: 0.9328 - val_loss: 1.5933 - val_acc: 0.7365\n",
      "Epoch 877/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1682 - acc: 0.9333 - val_loss: 1.4349 - val_acc: 0.7477\n",
      "Epoch 878/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1725 - acc: 0.9313 - val_loss: 1.4657 - val_acc: 0.7446\n",
      "Epoch 879/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1719 - acc: 0.9316 - val_loss: 1.6014 - val_acc: 0.7327\n",
      "Epoch 880/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1721 - acc: 0.9316 - val_loss: 1.6318 - val_acc: 0.7230\n",
      "Epoch 881/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1732 - acc: 0.9309 - val_loss: 1.7066 - val_acc: 0.7259\n",
      "Epoch 882/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1721 - acc: 0.9312 - val_loss: 1.5397 - val_acc: 0.7403\n",
      "Epoch 883/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1706 - acc: 0.9311 - val_loss: 1.7449 - val_acc: 0.7277\n",
      "Epoch 884/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1712 - acc: 0.9321 - val_loss: 1.6516 - val_acc: 0.7378\n",
      "Epoch 885/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1674 - acc: 0.9338 - val_loss: 1.7279 - val_acc: 0.7226\n",
      "Epoch 886/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1702 - acc: 0.9326 - val_loss: 1.4737 - val_acc: 0.7443\n",
      "Epoch 887/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1704 - acc: 0.9331 - val_loss: 1.6508 - val_acc: 0.7406\n",
      "Epoch 888/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1729 - acc: 0.9313 - val_loss: 1.7256 - val_acc: 0.7245\n",
      "Epoch 889/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1700 - acc: 0.9318 - val_loss: 1.6712 - val_acc: 0.7341\n",
      "Epoch 890/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1700 - acc: 0.9322 - val_loss: 1.5427 - val_acc: 0.7294\n",
      "Epoch 891/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1703 - acc: 0.9328 - val_loss: 1.5090 - val_acc: 0.7335\n",
      "Epoch 892/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1706 - acc: 0.9320 - val_loss: 1.5477 - val_acc: 0.7345\n",
      "Epoch 893/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1717 - acc: 0.9312 - val_loss: 1.6973 - val_acc: 0.7316\n",
      "Epoch 894/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1715 - acc: 0.9318 - val_loss: 1.5457 - val_acc: 0.7406\n",
      "Epoch 895/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1703 - acc: 0.9318 - val_loss: 1.6947 - val_acc: 0.7301\n",
      "Epoch 896/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1714 - acc: 0.9317 - val_loss: 1.5637 - val_acc: 0.7361\n",
      "Epoch 897/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1715 - acc: 0.9321 - val_loss: 1.7139 - val_acc: 0.7312\n",
      "Epoch 898/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1730 - acc: 0.9311 - val_loss: 1.7607 - val_acc: 0.7117\n",
      "Epoch 899/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1691 - acc: 0.9335 - val_loss: 1.7829 - val_acc: 0.7092\n",
      "Epoch 900/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1665 - acc: 0.9340 - val_loss: 1.6352 - val_acc: 0.7435\n",
      "Epoch 901/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1721 - acc: 0.9313 - val_loss: 1.5476 - val_acc: 0.7521\n",
      "Epoch 902/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1660 - acc: 0.9338 - val_loss: 1.8925 - val_acc: 0.7142\n",
      "Epoch 903/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1691 - acc: 0.9328 - val_loss: 1.7288 - val_acc: 0.7206\n",
      "Epoch 904/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1707 - acc: 0.9320 - val_loss: 1.5888 - val_acc: 0.7330\n",
      "Epoch 905/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1687 - acc: 0.9334 - val_loss: 1.7852 - val_acc: 0.7137\n",
      "Epoch 906/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1682 - acc: 0.9334 - val_loss: 1.4998 - val_acc: 0.7465\n",
      "Epoch 907/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1664 - acc: 0.9342 - val_loss: 1.6112 - val_acc: 0.7311\n",
      "Epoch 908/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1695 - acc: 0.9335 - val_loss: 1.9356 - val_acc: 0.6968\n",
      "Epoch 909/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1681 - acc: 0.9334 - val_loss: 1.5899 - val_acc: 0.7375\n",
      "Epoch 910/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1699 - acc: 0.9319 - val_loss: 1.5496 - val_acc: 0.7397\n",
      "Epoch 911/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1673 - acc: 0.9335 - val_loss: 1.5370 - val_acc: 0.7372\n",
      "Epoch 912/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1685 - acc: 0.9333 - val_loss: 1.5047 - val_acc: 0.7437\n",
      "Epoch 913/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1677 - acc: 0.9340 - val_loss: 1.5659 - val_acc: 0.7432\n",
      "Epoch 914/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1686 - acc: 0.9326 - val_loss: 1.9148 - val_acc: 0.7092\n",
      "Epoch 915/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1688 - acc: 0.9329 - val_loss: 1.7619 - val_acc: 0.7190\n",
      "Epoch 916/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1693 - acc: 0.9328 - val_loss: 1.6579 - val_acc: 0.7321\n",
      "Epoch 917/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1660 - acc: 0.9339 - val_loss: 1.5570 - val_acc: 0.7432\n",
      "Epoch 918/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1665 - acc: 0.9346 - val_loss: 1.6486 - val_acc: 0.7301\n",
      "Epoch 919/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1676 - acc: 0.9339 - val_loss: 1.6059 - val_acc: 0.7294\n",
      "Epoch 920/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1646 - acc: 0.9349 - val_loss: 1.6347 - val_acc: 0.7402\n",
      "Epoch 921/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1653 - acc: 0.9344 - val_loss: 1.7656 - val_acc: 0.7292\n",
      "Epoch 922/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1680 - acc: 0.9330 - val_loss: 1.7996 - val_acc: 0.7192\n",
      "Epoch 923/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1672 - acc: 0.9336 - val_loss: 1.4472 - val_acc: 0.7425\n",
      "Epoch 924/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1677 - acc: 0.9336 - val_loss: 1.8321 - val_acc: 0.7094\n",
      "Epoch 925/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1663 - acc: 0.9350 - val_loss: 1.6105 - val_acc: 0.7459\n",
      "Epoch 926/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1669 - acc: 0.9337 - val_loss: 1.4936 - val_acc: 0.7461\n",
      "Epoch 927/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1652 - acc: 0.9340 - val_loss: 1.5698 - val_acc: 0.7451\n",
      "Epoch 928/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1669 - acc: 0.9341 - val_loss: 1.7513 - val_acc: 0.7232\n",
      "Epoch 929/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1666 - acc: 0.9336 - val_loss: 1.4013 - val_acc: 0.7523\n",
      "Epoch 930/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1674 - acc: 0.9337 - val_loss: 1.7470 - val_acc: 0.7077\n",
      "Epoch 931/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1666 - acc: 0.9335 - val_loss: 1.7614 - val_acc: 0.7268\n",
      "Epoch 932/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1651 - acc: 0.9350 - val_loss: 1.7032 - val_acc: 0.7206\n",
      "Epoch 933/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1664 - acc: 0.9348 - val_loss: 1.7136 - val_acc: 0.7287\n",
      "Epoch 934/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1682 - acc: 0.9341 - val_loss: 1.4236 - val_acc: 0.7427\n",
      "Epoch 935/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1670 - acc: 0.9338 - val_loss: 1.6700 - val_acc: 0.7310\n",
      "Epoch 936/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1671 - acc: 0.9334 - val_loss: 1.5498 - val_acc: 0.7315\n",
      "Epoch 937/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1648 - acc: 0.9349 - val_loss: 1.5276 - val_acc: 0.7485\n",
      "Epoch 938/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1633 - acc: 0.9345 - val_loss: 1.6253 - val_acc: 0.7352\n",
      "Epoch 939/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1680 - acc: 0.9331 - val_loss: 1.6919 - val_acc: 0.7334\n",
      "Epoch 940/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1618 - acc: 0.9357 - val_loss: 1.7269 - val_acc: 0.7266\n",
      "Epoch 941/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1660 - acc: 0.9341 - val_loss: 1.6756 - val_acc: 0.7225\n",
      "Epoch 942/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1645 - acc: 0.9349 - val_loss: 1.6645 - val_acc: 0.7320\n",
      "Epoch 943/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1683 - acc: 0.9335 - val_loss: 1.6031 - val_acc: 0.7375\n",
      "Epoch 944/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1646 - acc: 0.9350 - val_loss: 1.5236 - val_acc: 0.7400\n",
      "Epoch 945/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1639 - acc: 0.9355 - val_loss: 1.7524 - val_acc: 0.7220\n",
      "Epoch 946/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1658 - acc: 0.9345 - val_loss: 1.5896 - val_acc: 0.7297\n",
      "Epoch 947/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1630 - acc: 0.9350 - val_loss: 1.6297 - val_acc: 0.7423\n",
      "Epoch 948/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1665 - acc: 0.9341 - val_loss: 1.8298 - val_acc: 0.7158\n",
      "Epoch 949/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1649 - acc: 0.9348 - val_loss: 1.5385 - val_acc: 0.7382\n",
      "Epoch 950/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1650 - acc: 0.9342 - val_loss: 1.5708 - val_acc: 0.7420\n",
      "Epoch 951/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1629 - acc: 0.9358 - val_loss: 1.6817 - val_acc: 0.7354\n",
      "Epoch 952/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1630 - acc: 0.9357 - val_loss: 1.4582 - val_acc: 0.7511\n",
      "Epoch 953/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1614 - acc: 0.9351 - val_loss: 1.6554 - val_acc: 0.7401\n",
      "Epoch 954/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1611 - acc: 0.9359 - val_loss: 1.7952 - val_acc: 0.7269\n",
      "Epoch 955/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1644 - acc: 0.9350 - val_loss: 1.4565 - val_acc: 0.7477\n",
      "Epoch 956/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1630 - acc: 0.9358 - val_loss: 1.9206 - val_acc: 0.7130\n",
      "Epoch 957/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1667 - acc: 0.9331 - val_loss: 1.7242 - val_acc: 0.7225\n",
      "Epoch 958/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1625 - acc: 0.9361 - val_loss: 1.7740 - val_acc: 0.7227\n",
      "Epoch 959/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1630 - acc: 0.9356 - val_loss: 1.6522 - val_acc: 0.7363\n",
      "Epoch 960/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1656 - acc: 0.9343 - val_loss: 1.6413 - val_acc: 0.7265\n",
      "Epoch 961/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1634 - acc: 0.9345 - val_loss: 1.7669 - val_acc: 0.7320\n",
      "Epoch 962/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1614 - acc: 0.9360 - val_loss: 1.5682 - val_acc: 0.7403\n",
      "Epoch 963/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1595 - acc: 0.9372 - val_loss: 1.7086 - val_acc: 0.7294\n",
      "Epoch 964/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1649 - acc: 0.9339 - val_loss: 1.5289 - val_acc: 0.7387\n",
      "Epoch 965/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1646 - acc: 0.9349 - val_loss: 1.6574 - val_acc: 0.7376\n",
      "Epoch 966/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1617 - acc: 0.9362 - val_loss: 1.6429 - val_acc: 0.7430\n",
      "Epoch 967/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1591 - acc: 0.9367 - val_loss: 1.4855 - val_acc: 0.7453\n",
      "Epoch 968/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1600 - acc: 0.9367 - val_loss: 1.5797 - val_acc: 0.7435\n",
      "Epoch 969/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1635 - acc: 0.9352 - val_loss: 1.6495 - val_acc: 0.7208\n",
      "Epoch 970/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1612 - acc: 0.9358 - val_loss: 1.6100 - val_acc: 0.7432\n",
      "Epoch 971/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1603 - acc: 0.9366 - val_loss: 1.8325 - val_acc: 0.7211\n",
      "Epoch 972/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1632 - acc: 0.9345 - val_loss: 1.8818 - val_acc: 0.7242\n",
      "Epoch 973/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1619 - acc: 0.9348 - val_loss: 1.5396 - val_acc: 0.7477\n",
      "Epoch 974/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1589 - acc: 0.9373 - val_loss: 1.5467 - val_acc: 0.7475\n",
      "Epoch 975/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1626 - acc: 0.9354 - val_loss: 1.7289 - val_acc: 0.7358\n",
      "Epoch 976/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1651 - acc: 0.9341 - val_loss: 1.5599 - val_acc: 0.7483\n",
      "Epoch 977/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1611 - acc: 0.9360 - val_loss: 1.6631 - val_acc: 0.7420\n",
      "Epoch 978/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1619 - acc: 0.9363 - val_loss: 2.0659 - val_acc: 0.6874\n",
      "Epoch 979/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1643 - acc: 0.9349 - val_loss: 1.6767 - val_acc: 0.7324\n",
      "Epoch 980/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1625 - acc: 0.9363 - val_loss: 1.7935 - val_acc: 0.7223\n",
      "Epoch 981/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1614 - acc: 0.9360 - val_loss: 1.5997 - val_acc: 0.7448\n",
      "Epoch 982/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1647 - acc: 0.9351 - val_loss: 1.7047 - val_acc: 0.7230\n",
      "Epoch 983/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1624 - acc: 0.9358 - val_loss: 1.4569 - val_acc: 0.7471\n",
      "Epoch 984/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1578 - acc: 0.9376 - val_loss: 1.4971 - val_acc: 0.7412\n",
      "Epoch 985/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1605 - acc: 0.9371 - val_loss: 1.6630 - val_acc: 0.7356\n",
      "Epoch 986/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1632 - acc: 0.9353 - val_loss: 1.5586 - val_acc: 0.7440\n",
      "Epoch 987/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1620 - acc: 0.9362 - val_loss: 1.5482 - val_acc: 0.7461\n",
      "Epoch 988/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1600 - acc: 0.9368 - val_loss: 1.7704 - val_acc: 0.7159\n",
      "Epoch 989/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1577 - acc: 0.9371 - val_loss: 1.6737 - val_acc: 0.7334\n",
      "Epoch 990/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1607 - acc: 0.9363 - val_loss: 1.6266 - val_acc: 0.7451\n",
      "Epoch 991/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1611 - acc: 0.9359 - val_loss: 1.7915 - val_acc: 0.7207\n",
      "Epoch 992/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1580 - acc: 0.9373 - val_loss: 1.5895 - val_acc: 0.7400\n",
      "Epoch 993/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1600 - acc: 0.9365 - val_loss: 1.8542 - val_acc: 0.7154\n",
      "Epoch 994/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1612 - acc: 0.9362 - val_loss: 1.7117 - val_acc: 0.7333\n",
      "Epoch 995/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1619 - acc: 0.9359 - val_loss: 1.7211 - val_acc: 0.7292\n",
      "Epoch 996/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1593 - acc: 0.9372 - val_loss: 1.7143 - val_acc: 0.7313\n",
      "Epoch 997/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1610 - acc: 0.9366 - val_loss: 1.6027 - val_acc: 0.7430\n",
      "Epoch 998/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1612 - acc: 0.9370 - val_loss: 1.5762 - val_acc: 0.7323\n",
      "Epoch 999/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1642 - acc: 0.9356 - val_loss: 1.6498 - val_acc: 0.7194\n",
      "Epoch 1000/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1573 - acc: 0.9381 - val_loss: 1.8946 - val_acc: 0.7024\n",
      "14200/14200 [==============================] - 1s 36us/sample - loss: 1.8946 - acc: 0.7024\n",
      "Train on 113600 samples, validate on 14200 samples\n",
      "Epoch 1/1000\n",
      "113600/113600 [==============================] - 3s 29us/sample - loss: 1.2243 - acc: 0.4959 - val_loss: 1.5703 - val_acc: 0.4453\n",
      "Epoch 2/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.9416 - acc: 0.6195 - val_loss: 1.3957 - val_acc: 0.4965\n",
      "Epoch 3/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.8480 - acc: 0.6639 - val_loss: 1.1655 - val_acc: 0.5661\n",
      "Epoch 4/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7793 - acc: 0.6967 - val_loss: 1.8528 - val_acc: 0.4745\n",
      "Epoch 5/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.7214 - acc: 0.7225 - val_loss: 1.3647 - val_acc: 0.5501\n",
      "Epoch 6/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6731 - acc: 0.7441 - val_loss: 1.1468 - val_acc: 0.5830\n",
      "Epoch 7/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.6328 - acc: 0.7598 - val_loss: 1.8241 - val_acc: 0.5391\n",
      "Epoch 8/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5990 - acc: 0.7726 - val_loss: 1.1852 - val_acc: 0.5953\n",
      "Epoch 9/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5674 - acc: 0.7846 - val_loss: 1.3137 - val_acc: 0.5947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5410 - acc: 0.7942 - val_loss: 1.3274 - val_acc: 0.5739\n",
      "Epoch 11/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.5186 - acc: 0.8041 - val_loss: 2.5550 - val_acc: 0.4881\n",
      "Epoch 12/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.4981 - acc: 0.8127 - val_loss: 1.3367 - val_acc: 0.6027\n",
      "Epoch 13/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4811 - acc: 0.8170 - val_loss: 1.3269 - val_acc: 0.6067\n",
      "Epoch 14/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4648 - acc: 0.8249 - val_loss: 1.3000 - val_acc: 0.6340\n",
      "Epoch 15/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4521 - acc: 0.8289 - val_loss: 1.4890 - val_acc: 0.6058\n",
      "Epoch 16/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4343 - acc: 0.8359 - val_loss: 1.1128 - val_acc: 0.6488\n",
      "Epoch 17/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.4246 - acc: 0.8406 - val_loss: 1.1579 - val_acc: 0.6585\n",
      "Epoch 18/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4137 - acc: 0.8437 - val_loss: 1.5682 - val_acc: 0.5904\n",
      "Epoch 19/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.4068 - acc: 0.8462 - val_loss: 1.2786 - val_acc: 0.6286\n",
      "Epoch 20/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3980 - acc: 0.8492 - val_loss: 1.5179 - val_acc: 0.6215\n",
      "Epoch 21/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3883 - acc: 0.8535 - val_loss: 1.3188 - val_acc: 0.6453\n",
      "Epoch 22/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3817 - acc: 0.8562 - val_loss: 1.3020 - val_acc: 0.6443\n",
      "Epoch 23/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3689 - acc: 0.8603 - val_loss: 1.4708 - val_acc: 0.6196\n",
      "Epoch 24/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3727 - acc: 0.8582 - val_loss: 1.4128 - val_acc: 0.6204\n",
      "Epoch 25/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3624 - acc: 0.8627 - val_loss: 1.3788 - val_acc: 0.6557\n",
      "Epoch 26/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3536 - acc: 0.8663 - val_loss: 1.1863 - val_acc: 0.6535\n",
      "Epoch 27/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3468 - acc: 0.8694 - val_loss: 1.3196 - val_acc: 0.6508\n",
      "Epoch 28/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3451 - acc: 0.8703 - val_loss: 1.1154 - val_acc: 0.6912\n",
      "Epoch 29/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3394 - acc: 0.8718 - val_loss: 1.3747 - val_acc: 0.6428\n",
      "Epoch 30/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3339 - acc: 0.8738 - val_loss: 1.3106 - val_acc: 0.6508\n",
      "Epoch 31/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3290 - acc: 0.8753 - val_loss: 1.4423 - val_acc: 0.6590\n",
      "Epoch 32/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.3278 - acc: 0.8764 - val_loss: 1.0830 - val_acc: 0.6922\n",
      "Epoch 33/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3227 - acc: 0.8782 - val_loss: 1.6805 - val_acc: 0.6218\n",
      "Epoch 34/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3173 - acc: 0.8805 - val_loss: 1.1752 - val_acc: 0.6880\n",
      "Epoch 35/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3165 - acc: 0.8803 - val_loss: 1.3702 - val_acc: 0.6279\n",
      "Epoch 36/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3164 - acc: 0.8807 - val_loss: 1.4541 - val_acc: 0.6403\n",
      "Epoch 37/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3072 - acc: 0.8836 - val_loss: 1.1723 - val_acc: 0.6865\n",
      "Epoch 38/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.3057 - acc: 0.8844 - val_loss: 1.5539 - val_acc: 0.6557\n",
      "Epoch 39/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3046 - acc: 0.8857 - val_loss: 1.4313 - val_acc: 0.6541\n",
      "Epoch 40/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.3082 - acc: 0.8845 - val_loss: 1.3169 - val_acc: 0.6728\n",
      "Epoch 41/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2973 - acc: 0.8875 - val_loss: 1.3677 - val_acc: 0.6609\n",
      "Epoch 42/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2935 - acc: 0.8902 - val_loss: 1.3757 - val_acc: 0.6634\n",
      "Epoch 43/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2949 - acc: 0.8889 - val_loss: 2.0155 - val_acc: 0.6088\n",
      "Epoch 44/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2880 - acc: 0.8916 - val_loss: 1.6781 - val_acc: 0.6293\n",
      "Epoch 45/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2866 - acc: 0.8919 - val_loss: 1.6513 - val_acc: 0.6513\n",
      "Epoch 46/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2842 - acc: 0.8922 - val_loss: 1.0949 - val_acc: 0.6978\n",
      "Epoch 47/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2815 - acc: 0.8947 - val_loss: 1.5556 - val_acc: 0.6559\n",
      "Epoch 48/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2812 - acc: 0.8945 - val_loss: 1.3456 - val_acc: 0.6731\n",
      "Epoch 49/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2810 - acc: 0.8944 - val_loss: 1.5832 - val_acc: 0.6453\n",
      "Epoch 50/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2819 - acc: 0.8930 - val_loss: 1.5088 - val_acc: 0.6499\n",
      "Epoch 51/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2796 - acc: 0.8950 - val_loss: 1.2645 - val_acc: 0.6827\n",
      "Epoch 52/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2761 - acc: 0.8966 - val_loss: 1.2224 - val_acc: 0.6906\n",
      "Epoch 53/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2721 - acc: 0.8980 - val_loss: 1.1559 - val_acc: 0.7061\n",
      "Epoch 54/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2692 - acc: 0.8989 - val_loss: 1.4998 - val_acc: 0.6582\n",
      "Epoch 55/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2692 - acc: 0.8997 - val_loss: 1.6057 - val_acc: 0.6385\n",
      "Epoch 56/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2618 - acc: 0.9011 - val_loss: 1.4266 - val_acc: 0.6775\n",
      "Epoch 57/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2624 - acc: 0.9009 - val_loss: 1.2986 - val_acc: 0.6730\n",
      "Epoch 58/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2641 - acc: 0.9007 - val_loss: 1.3484 - val_acc: 0.6744\n",
      "Epoch 59/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2638 - acc: 0.9003 - val_loss: 1.4448 - val_acc: 0.6420\n",
      "Epoch 60/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2579 - acc: 0.9029 - val_loss: 1.5916 - val_acc: 0.6677\n",
      "Epoch 61/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2612 - acc: 0.9021 - val_loss: 1.2126 - val_acc: 0.6785\n",
      "Epoch 62/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2573 - acc: 0.9031 - val_loss: 1.1688 - val_acc: 0.6996\n",
      "Epoch 63/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2555 - acc: 0.9040 - val_loss: 1.2445 - val_acc: 0.6984\n",
      "Epoch 64/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2534 - acc: 0.9046 - val_loss: 1.1991 - val_acc: 0.6972\n",
      "Epoch 65/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2532 - acc: 0.9055 - val_loss: 1.8970 - val_acc: 0.6453\n",
      "Epoch 66/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2507 - acc: 0.9059 - val_loss: 1.3883 - val_acc: 0.6868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2533 - acc: 0.9053 - val_loss: 1.7517 - val_acc: 0.6341\n",
      "Epoch 68/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2493 - acc: 0.9059 - val_loss: 1.4618 - val_acc: 0.6699\n",
      "Epoch 69/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2455 - acc: 0.9071 - val_loss: 1.4141 - val_acc: 0.6895\n",
      "Epoch 70/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2497 - acc: 0.9060 - val_loss: 1.2599 - val_acc: 0.7030\n",
      "Epoch 71/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2428 - acc: 0.9091 - val_loss: 1.6313 - val_acc: 0.6499\n",
      "Epoch 72/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2450 - acc: 0.9086 - val_loss: 1.4480 - val_acc: 0.6906\n",
      "Epoch 73/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2389 - acc: 0.9100 - val_loss: 1.4686 - val_acc: 0.6776\n",
      "Epoch 74/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2437 - acc: 0.9085 - val_loss: 1.6855 - val_acc: 0.6506\n",
      "Epoch 75/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2439 - acc: 0.9088 - val_loss: 1.1892 - val_acc: 0.7020\n",
      "Epoch 76/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2421 - acc: 0.9091 - val_loss: 1.6524 - val_acc: 0.6631\n",
      "Epoch 77/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2380 - acc: 0.9105 - val_loss: 1.3285 - val_acc: 0.7037\n",
      "Epoch 78/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2382 - acc: 0.9106 - val_loss: 1.2870 - val_acc: 0.6856\n",
      "Epoch 79/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2353 - acc: 0.9117 - val_loss: 1.3905 - val_acc: 0.6901\n",
      "Epoch 80/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2353 - acc: 0.9115 - val_loss: 1.5115 - val_acc: 0.6661\n",
      "Epoch 81/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2368 - acc: 0.9115 - val_loss: 1.8246 - val_acc: 0.6538\n",
      "Epoch 82/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2319 - acc: 0.9124 - val_loss: 1.7951 - val_acc: 0.6480\n",
      "Epoch 83/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2342 - acc: 0.9129 - val_loss: 1.5511 - val_acc: 0.6570\n",
      "Epoch 84/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2336 - acc: 0.9122 - val_loss: 1.2927 - val_acc: 0.7025\n",
      "Epoch 85/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2328 - acc: 0.9134 - val_loss: 1.3329 - val_acc: 0.7075\n",
      "Epoch 86/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2315 - acc: 0.9139 - val_loss: 1.4377 - val_acc: 0.6759\n",
      "Epoch 87/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2269 - acc: 0.9156 - val_loss: 1.5120 - val_acc: 0.6579\n",
      "Epoch 88/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2260 - acc: 0.9153 - val_loss: 1.6133 - val_acc: 0.6768\n",
      "Epoch 89/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2294 - acc: 0.9153 - val_loss: 1.6372 - val_acc: 0.6740\n",
      "Epoch 90/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2275 - acc: 0.9150 - val_loss: 1.7569 - val_acc: 0.6294\n",
      "Epoch 91/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2234 - acc: 0.9164 - val_loss: 1.3948 - val_acc: 0.6967\n",
      "Epoch 92/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2260 - acc: 0.9157 - val_loss: 1.2413 - val_acc: 0.6988\n",
      "Epoch 93/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2230 - acc: 0.9169 - val_loss: 1.2682 - val_acc: 0.7135\n",
      "Epoch 94/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2245 - acc: 0.9171 - val_loss: 1.3492 - val_acc: 0.6961\n",
      "Epoch 95/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2243 - acc: 0.9167 - val_loss: 1.3083 - val_acc: 0.6968\n",
      "Epoch 96/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2201 - acc: 0.9178 - val_loss: 1.5289 - val_acc: 0.6828\n",
      "Epoch 97/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2237 - acc: 0.9161 - val_loss: 1.7039 - val_acc: 0.6674\n",
      "Epoch 98/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2217 - acc: 0.9170 - val_loss: 1.5495 - val_acc: 0.6692\n",
      "Epoch 99/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2223 - acc: 0.9175 - val_loss: 1.5859 - val_acc: 0.6719\n",
      "Epoch 100/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2221 - acc: 0.9166 - val_loss: 1.5667 - val_acc: 0.6888\n",
      "Epoch 101/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2188 - acc: 0.9184 - val_loss: 1.4196 - val_acc: 0.7019\n",
      "Epoch 102/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2185 - acc: 0.9183 - val_loss: 1.4617 - val_acc: 0.6972\n",
      "Epoch 103/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2172 - acc: 0.9190 - val_loss: 1.4597 - val_acc: 0.7018\n",
      "Epoch 104/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2172 - acc: 0.9188 - val_loss: 1.3716 - val_acc: 0.7027\n",
      "Epoch 105/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2178 - acc: 0.9190 - val_loss: 1.3628 - val_acc: 0.7008\n",
      "Epoch 106/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.2131 - acc: 0.9201 - val_loss: 1.3355 - val_acc: 0.7106\n",
      "Epoch 107/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2140 - acc: 0.9206 - val_loss: 1.4814 - val_acc: 0.6858\n",
      "Epoch 108/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2134 - acc: 0.9202 - val_loss: 1.3480 - val_acc: 0.7011\n",
      "Epoch 109/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2132 - acc: 0.9203 - val_loss: 1.5344 - val_acc: 0.6854\n",
      "Epoch 110/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2136 - acc: 0.9202 - val_loss: 1.8364 - val_acc: 0.6660\n",
      "Epoch 111/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2126 - acc: 0.9208 - val_loss: 1.2481 - val_acc: 0.7062\n",
      "Epoch 112/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2101 - acc: 0.9221 - val_loss: 1.4473 - val_acc: 0.6890\n",
      "Epoch 113/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2124 - acc: 0.9208 - val_loss: 1.3233 - val_acc: 0.7099\n",
      "Epoch 114/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2107 - acc: 0.9229 - val_loss: 1.4588 - val_acc: 0.6631\n",
      "Epoch 115/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2094 - acc: 0.9213 - val_loss: 1.6721 - val_acc: 0.6639\n",
      "Epoch 116/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2083 - acc: 0.9229 - val_loss: 1.3782 - val_acc: 0.6976\n",
      "Epoch 117/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2062 - acc: 0.9226 - val_loss: 1.6091 - val_acc: 0.6925\n",
      "Epoch 118/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2058 - acc: 0.9237 - val_loss: 1.4154 - val_acc: 0.6982\n",
      "Epoch 119/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2076 - acc: 0.9224 - val_loss: 1.4924 - val_acc: 0.6898\n",
      "Epoch 120/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2056 - acc: 0.9230 - val_loss: 1.3527 - val_acc: 0.7102\n",
      "Epoch 121/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2057 - acc: 0.9231 - val_loss: 1.3626 - val_acc: 0.6992\n",
      "Epoch 122/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2056 - acc: 0.9230 - val_loss: 1.6717 - val_acc: 0.6760\n",
      "Epoch 123/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2054 - acc: 0.9234 - val_loss: 1.8264 - val_acc: 0.6680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2036 - acc: 0.9245 - val_loss: 1.5402 - val_acc: 0.6846\n",
      "Epoch 125/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2000 - acc: 0.9248 - val_loss: 1.4004 - val_acc: 0.7091\n",
      "Epoch 126/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2017 - acc: 0.9249 - val_loss: 1.5492 - val_acc: 0.6882\n",
      "Epoch 127/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2004 - acc: 0.9257 - val_loss: 1.4603 - val_acc: 0.6979\n",
      "Epoch 128/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2032 - acc: 0.9239 - val_loss: 1.4727 - val_acc: 0.6971\n",
      "Epoch 129/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2057 - acc: 0.9232 - val_loss: 1.3724 - val_acc: 0.6932\n",
      "Epoch 130/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1995 - acc: 0.9256 - val_loss: 1.6446 - val_acc: 0.6710\n",
      "Epoch 131/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2008 - acc: 0.9256 - val_loss: 1.3422 - val_acc: 0.7017\n",
      "Epoch 132/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.2011 - acc: 0.9246 - val_loss: 1.4119 - val_acc: 0.6970\n",
      "Epoch 133/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.2000 - acc: 0.9244 - val_loss: 1.4915 - val_acc: 0.6906\n",
      "Epoch 134/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1987 - acc: 0.9254 - val_loss: 1.3829 - val_acc: 0.7071\n",
      "Epoch 135/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1947 - acc: 0.9273 - val_loss: 1.7455 - val_acc: 0.6682\n",
      "Epoch 136/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1989 - acc: 0.9261 - val_loss: 1.3321 - val_acc: 0.7018\n",
      "Epoch 137/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1965 - acc: 0.9273 - val_loss: 1.5917 - val_acc: 0.6847\n",
      "Epoch 138/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1963 - acc: 0.9264 - val_loss: 1.3854 - val_acc: 0.7054\n",
      "Epoch 139/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1969 - acc: 0.9270 - val_loss: 1.3987 - val_acc: 0.6991\n",
      "Epoch 140/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1935 - acc: 0.9280 - val_loss: 1.2471 - val_acc: 0.7095\n",
      "Epoch 141/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1931 - acc: 0.9275 - val_loss: 1.4852 - val_acc: 0.6839\n",
      "Epoch 142/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1929 - acc: 0.9281 - val_loss: 1.3607 - val_acc: 0.7074\n",
      "Epoch 143/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1949 - acc: 0.9272 - val_loss: 1.5385 - val_acc: 0.6961\n",
      "Epoch 144/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1953 - acc: 0.9268 - val_loss: 1.7780 - val_acc: 0.6711\n",
      "Epoch 145/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1930 - acc: 0.9281 - val_loss: 1.4552 - val_acc: 0.7044\n",
      "Epoch 146/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1966 - acc: 0.9272 - val_loss: 1.5220 - val_acc: 0.6905\n",
      "Epoch 147/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1946 - acc: 0.9271 - val_loss: 1.3462 - val_acc: 0.7006\n",
      "Epoch 148/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1943 - acc: 0.9278 - val_loss: 1.6460 - val_acc: 0.6927\n",
      "Epoch 149/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1947 - acc: 0.9273 - val_loss: 1.3278 - val_acc: 0.7081\n",
      "Epoch 150/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1894 - acc: 0.9298 - val_loss: 1.2805 - val_acc: 0.7042\n",
      "Epoch 151/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1912 - acc: 0.9290 - val_loss: 1.5077 - val_acc: 0.7015\n",
      "Epoch 152/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1909 - acc: 0.9288 - val_loss: 1.4697 - val_acc: 0.6935\n",
      "Epoch 153/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1921 - acc: 0.9291 - val_loss: 1.4117 - val_acc: 0.7090\n",
      "Epoch 154/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1913 - acc: 0.9291 - val_loss: 1.5773 - val_acc: 0.6870\n",
      "Epoch 155/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1896 - acc: 0.9303 - val_loss: 1.4619 - val_acc: 0.6899\n",
      "Epoch 156/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1869 - acc: 0.9312 - val_loss: 1.6046 - val_acc: 0.6901\n",
      "Epoch 157/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1880 - acc: 0.9297 - val_loss: 1.4723 - val_acc: 0.7118\n",
      "Epoch 158/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1886 - acc: 0.9297 - val_loss: 1.6660 - val_acc: 0.6842\n",
      "Epoch 159/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1838 - acc: 0.9316 - val_loss: 1.3215 - val_acc: 0.7075\n",
      "Epoch 160/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1879 - acc: 0.9312 - val_loss: 1.5750 - val_acc: 0.7082\n",
      "Epoch 161/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1867 - acc: 0.9313 - val_loss: 1.7789 - val_acc: 0.6749\n",
      "Epoch 162/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1863 - acc: 0.9305 - val_loss: 1.4083 - val_acc: 0.6982\n",
      "Epoch 163/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1867 - acc: 0.9304 - val_loss: 1.4253 - val_acc: 0.6896\n",
      "Epoch 164/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1861 - acc: 0.9310 - val_loss: 1.4900 - val_acc: 0.6826\n",
      "Epoch 165/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1842 - acc: 0.9321 - val_loss: 1.7956 - val_acc: 0.6878\n",
      "Epoch 166/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1874 - acc: 0.9301 - val_loss: 1.4450 - val_acc: 0.7057\n",
      "Epoch 167/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1865 - acc: 0.9306 - val_loss: 1.5471 - val_acc: 0.7027\n",
      "Epoch 168/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1834 - acc: 0.9324 - val_loss: 1.3262 - val_acc: 0.7067\n",
      "Epoch 169/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1858 - acc: 0.9312 - val_loss: 1.3120 - val_acc: 0.7069\n",
      "Epoch 170/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1794 - acc: 0.9338 - val_loss: 1.6089 - val_acc: 0.6878\n",
      "Epoch 171/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1868 - acc: 0.9302 - val_loss: 1.6705 - val_acc: 0.6936\n",
      "Epoch 172/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1816 - acc: 0.9331 - val_loss: 1.5133 - val_acc: 0.6949\n",
      "Epoch 173/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1825 - acc: 0.9325 - val_loss: 1.8423 - val_acc: 0.6714\n",
      "Epoch 174/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1825 - acc: 0.9323 - val_loss: 1.6406 - val_acc: 0.6715\n",
      "Epoch 175/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1806 - acc: 0.9334 - val_loss: 1.5036 - val_acc: 0.6976\n",
      "Epoch 176/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1812 - acc: 0.9324 - val_loss: 1.5384 - val_acc: 0.6981\n",
      "Epoch 177/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1836 - acc: 0.9324 - val_loss: 1.5662 - val_acc: 0.6950\n",
      "Epoch 178/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1810 - acc: 0.9327 - val_loss: 1.5504 - val_acc: 0.6935\n",
      "Epoch 179/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1793 - acc: 0.9335 - val_loss: 1.3511 - val_acc: 0.7084\n",
      "Epoch 180/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1798 - acc: 0.9336 - val_loss: 1.4655 - val_acc: 0.7208\n",
      "Epoch 181/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1805 - acc: 0.9327 - val_loss: 1.4207 - val_acc: 0.7154\n",
      "Epoch 182/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1835 - acc: 0.9313 - val_loss: 1.9392 - val_acc: 0.6644\n",
      "Epoch 183/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1778 - acc: 0.9344 - val_loss: 1.4923 - val_acc: 0.6999\n",
      "Epoch 184/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1753 - acc: 0.9352 - val_loss: 1.4503 - val_acc: 0.7037\n",
      "Epoch 185/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1790 - acc: 0.9337 - val_loss: 1.5237 - val_acc: 0.6986\n",
      "Epoch 186/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1794 - acc: 0.9332 - val_loss: 1.6228 - val_acc: 0.6893\n",
      "Epoch 187/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1765 - acc: 0.9344 - val_loss: 1.4841 - val_acc: 0.7123\n",
      "Epoch 188/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1764 - acc: 0.9336 - val_loss: 1.4399 - val_acc: 0.7074\n",
      "Epoch 189/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1798 - acc: 0.9334 - val_loss: 1.4364 - val_acc: 0.7087\n",
      "Epoch 190/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1762 - acc: 0.9349 - val_loss: 1.4786 - val_acc: 0.7029\n",
      "Epoch 191/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1798 - acc: 0.9330 - val_loss: 1.4871 - val_acc: 0.7071\n",
      "Epoch 192/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1736 - acc: 0.9357 - val_loss: 1.3646 - val_acc: 0.7163\n",
      "Epoch 193/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1729 - acc: 0.9360 - val_loss: 1.7804 - val_acc: 0.6760\n",
      "Epoch 194/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1739 - acc: 0.9355 - val_loss: 1.4249 - val_acc: 0.7139\n",
      "Epoch 195/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1724 - acc: 0.9361 - val_loss: 1.6596 - val_acc: 0.6790\n",
      "Epoch 196/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1734 - acc: 0.9360 - val_loss: 1.6749 - val_acc: 0.6924\n",
      "Epoch 197/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1760 - acc: 0.9352 - val_loss: 1.6509 - val_acc: 0.6968\n",
      "Epoch 198/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1735 - acc: 0.9360 - val_loss: 1.4709 - val_acc: 0.7148\n",
      "Epoch 199/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1740 - acc: 0.9359 - val_loss: 1.5974 - val_acc: 0.7027\n",
      "Epoch 200/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1732 - acc: 0.9365 - val_loss: 1.3536 - val_acc: 0.7197\n",
      "Epoch 201/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1697 - acc: 0.9378 - val_loss: 1.4978 - val_acc: 0.7050\n",
      "Epoch 202/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1719 - acc: 0.9361 - val_loss: 1.4503 - val_acc: 0.7066\n",
      "Epoch 203/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1720 - acc: 0.9357 - val_loss: 1.6592 - val_acc: 0.6920\n",
      "Epoch 204/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1728 - acc: 0.9360 - val_loss: 1.5342 - val_acc: 0.6716\n",
      "Epoch 205/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1721 - acc: 0.9368 - val_loss: 1.5456 - val_acc: 0.7142\n",
      "Epoch 206/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1691 - acc: 0.9370 - val_loss: 1.3723 - val_acc: 0.6993\n",
      "Epoch 207/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1734 - acc: 0.9351 - val_loss: 1.5107 - val_acc: 0.7220\n",
      "Epoch 208/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1710 - acc: 0.9368 - val_loss: 1.3339 - val_acc: 0.7110\n",
      "Epoch 209/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1695 - acc: 0.9372 - val_loss: 1.5260 - val_acc: 0.7064\n",
      "Epoch 210/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1700 - acc: 0.9369 - val_loss: 1.5289 - val_acc: 0.7042\n",
      "Epoch 211/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1702 - acc: 0.9374 - val_loss: 1.5015 - val_acc: 0.7078\n",
      "Epoch 212/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1689 - acc: 0.9375 - val_loss: 1.6347 - val_acc: 0.7006\n",
      "Epoch 213/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1663 - acc: 0.9383 - val_loss: 1.6525 - val_acc: 0.6848\n",
      "Epoch 214/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1677 - acc: 0.9371 - val_loss: 1.6407 - val_acc: 0.6854\n",
      "Epoch 215/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1657 - acc: 0.9388 - val_loss: 1.5737 - val_acc: 0.6906\n",
      "Epoch 216/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1686 - acc: 0.9383 - val_loss: 1.6228 - val_acc: 0.7001\n",
      "Epoch 217/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1669 - acc: 0.9380 - val_loss: 1.5418 - val_acc: 0.6943\n",
      "Epoch 218/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1668 - acc: 0.9380 - val_loss: 1.4560 - val_acc: 0.7027\n",
      "Epoch 219/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1662 - acc: 0.9387 - val_loss: 1.7158 - val_acc: 0.6846\n",
      "Epoch 220/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1651 - acc: 0.9382 - val_loss: 1.6131 - val_acc: 0.6938\n",
      "Epoch 221/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1662 - acc: 0.9383 - val_loss: 1.4765 - val_acc: 0.6987\n",
      "Epoch 222/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1673 - acc: 0.9381 - val_loss: 1.7556 - val_acc: 0.6780\n",
      "Epoch 223/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1682 - acc: 0.9380 - val_loss: 1.4672 - val_acc: 0.7148\n",
      "Epoch 224/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1656 - acc: 0.9383 - val_loss: 1.4769 - val_acc: 0.7029\n",
      "Epoch 225/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1643 - acc: 0.9388 - val_loss: 1.7245 - val_acc: 0.6982\n",
      "Epoch 226/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1675 - acc: 0.9377 - val_loss: 1.5011 - val_acc: 0.7069\n",
      "Epoch 227/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1632 - acc: 0.9399 - val_loss: 1.5389 - val_acc: 0.7057\n",
      "Epoch 228/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1663 - acc: 0.9377 - val_loss: 1.4723 - val_acc: 0.7067\n",
      "Epoch 229/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1647 - acc: 0.9394 - val_loss: 1.3785 - val_acc: 0.7221\n",
      "Epoch 230/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1638 - acc: 0.9393 - val_loss: 1.6035 - val_acc: 0.7058\n",
      "Epoch 231/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1656 - acc: 0.9383 - val_loss: 1.9391 - val_acc: 0.6663\n",
      "Epoch 232/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1621 - acc: 0.9398 - val_loss: 1.6264 - val_acc: 0.7078\n",
      "Epoch 233/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1596 - acc: 0.9402 - val_loss: 1.4906 - val_acc: 0.7041\n",
      "Epoch 234/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1604 - acc: 0.9406 - val_loss: 1.3453 - val_acc: 0.7073\n",
      "Epoch 235/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1619 - acc: 0.9401 - val_loss: 1.4728 - val_acc: 0.6961\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1598 - acc: 0.9414 - val_loss: 1.5988 - val_acc: 0.6990\n",
      "Epoch 237/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1606 - acc: 0.9412 - val_loss: 1.6958 - val_acc: 0.6965\n",
      "Epoch 238/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1607 - acc: 0.9403 - val_loss: 1.5666 - val_acc: 0.6999\n",
      "Epoch 239/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1612 - acc: 0.9403 - val_loss: 1.5078 - val_acc: 0.7013\n",
      "Epoch 240/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1610 - acc: 0.9399 - val_loss: 1.6463 - val_acc: 0.6975\n",
      "Epoch 241/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1623 - acc: 0.9402 - val_loss: 1.8538 - val_acc: 0.6850\n",
      "Epoch 242/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1600 - acc: 0.9412 - val_loss: 1.4737 - val_acc: 0.7158\n",
      "Epoch 243/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1591 - acc: 0.9414 - val_loss: 1.5528 - val_acc: 0.7054\n",
      "Epoch 244/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1589 - acc: 0.9408 - val_loss: 1.6248 - val_acc: 0.7007\n",
      "Epoch 245/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1604 - acc: 0.9410 - val_loss: 1.8531 - val_acc: 0.6814\n",
      "Epoch 246/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1594 - acc: 0.9408 - val_loss: 1.6336 - val_acc: 0.7119\n",
      "Epoch 247/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1588 - acc: 0.9411 - val_loss: 1.5509 - val_acc: 0.6985\n",
      "Epoch 248/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1599 - acc: 0.9404 - val_loss: 1.6381 - val_acc: 0.6945\n",
      "Epoch 249/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1576 - acc: 0.9418 - val_loss: 1.6702 - val_acc: 0.7068\n",
      "Epoch 250/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1591 - acc: 0.9418 - val_loss: 1.6885 - val_acc: 0.7048\n",
      "Epoch 251/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1570 - acc: 0.9415 - val_loss: 1.5279 - val_acc: 0.7124\n",
      "Epoch 252/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1602 - acc: 0.9414 - val_loss: 1.7853 - val_acc: 0.6908\n",
      "Epoch 253/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1582 - acc: 0.9411 - val_loss: 1.5997 - val_acc: 0.6975\n",
      "Epoch 254/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1575 - acc: 0.9427 - val_loss: 1.6822 - val_acc: 0.7031\n",
      "Epoch 255/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1589 - acc: 0.9412 - val_loss: 1.5305 - val_acc: 0.7048\n",
      "Epoch 256/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1581 - acc: 0.9415 - val_loss: 1.6702 - val_acc: 0.7032\n",
      "Epoch 257/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1556 - acc: 0.9422 - val_loss: 1.7302 - val_acc: 0.7029\n",
      "Epoch 258/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1551 - acc: 0.9432 - val_loss: 1.5525 - val_acc: 0.7056\n",
      "Epoch 259/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1565 - acc: 0.9427 - val_loss: 1.5675 - val_acc: 0.7046\n",
      "Epoch 260/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1565 - acc: 0.9416 - val_loss: 1.4897 - val_acc: 0.7194\n",
      "Epoch 261/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1547 - acc: 0.9429 - val_loss: 1.5335 - val_acc: 0.7105\n",
      "Epoch 262/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1553 - acc: 0.9427 - val_loss: 1.4904 - val_acc: 0.7166\n",
      "Epoch 263/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1579 - acc: 0.9423 - val_loss: 1.5511 - val_acc: 0.7001\n",
      "Epoch 264/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1562 - acc: 0.9422 - val_loss: 1.4928 - val_acc: 0.7060\n",
      "Epoch 265/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1536 - acc: 0.9437 - val_loss: 1.6461 - val_acc: 0.7105\n",
      "Epoch 266/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1519 - acc: 0.9435 - val_loss: 1.5211 - val_acc: 0.7018\n",
      "Epoch 267/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1527 - acc: 0.9431 - val_loss: 1.4336 - val_acc: 0.7274\n",
      "Epoch 268/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1539 - acc: 0.9426 - val_loss: 1.6333 - val_acc: 0.7012\n",
      "Epoch 269/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1541 - acc: 0.9424 - val_loss: 1.6292 - val_acc: 0.7094\n",
      "Epoch 270/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1536 - acc: 0.9443 - val_loss: 1.5972 - val_acc: 0.6919\n",
      "Epoch 271/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1551 - acc: 0.9433 - val_loss: 1.6718 - val_acc: 0.6980\n",
      "Epoch 272/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1536 - acc: 0.9438 - val_loss: 1.6480 - val_acc: 0.7075\n",
      "Epoch 273/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1530 - acc: 0.9436 - val_loss: 1.6919 - val_acc: 0.7041\n",
      "Epoch 274/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1527 - acc: 0.9425 - val_loss: 1.6429 - val_acc: 0.7046\n",
      "Epoch 275/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1532 - acc: 0.9441 - val_loss: 1.5864 - val_acc: 0.7174\n",
      "Epoch 276/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1533 - acc: 0.9437 - val_loss: 1.5368 - val_acc: 0.7013\n",
      "Epoch 277/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1510 - acc: 0.9437 - val_loss: 1.6281 - val_acc: 0.7121\n",
      "Epoch 278/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1522 - acc: 0.9438 - val_loss: 1.5395 - val_acc: 0.7013\n",
      "Epoch 279/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1525 - acc: 0.9436 - val_loss: 1.5982 - val_acc: 0.7074\n",
      "Epoch 280/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1498 - acc: 0.9454 - val_loss: 1.5575 - val_acc: 0.7106\n",
      "Epoch 281/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1523 - acc: 0.9429 - val_loss: 1.6269 - val_acc: 0.6983\n",
      "Epoch 282/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1516 - acc: 0.9440 - val_loss: 1.6023 - val_acc: 0.7177\n",
      "Epoch 283/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1517 - acc: 0.9433 - val_loss: 1.7024 - val_acc: 0.7010\n",
      "Epoch 284/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1537 - acc: 0.9435 - val_loss: 1.8335 - val_acc: 0.6817\n",
      "Epoch 285/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1509 - acc: 0.9437 - val_loss: 1.6605 - val_acc: 0.6982\n",
      "Epoch 286/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1513 - acc: 0.9446 - val_loss: 1.6937 - val_acc: 0.6957\n",
      "Epoch 287/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1462 - acc: 0.9463 - val_loss: 1.5729 - val_acc: 0.7045\n",
      "Epoch 288/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1455 - acc: 0.9469 - val_loss: 1.6401 - val_acc: 0.6934\n",
      "Epoch 289/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1491 - acc: 0.9443 - val_loss: 1.6592 - val_acc: 0.6957\n",
      "Epoch 290/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1497 - acc: 0.9440 - val_loss: 1.9912 - val_acc: 0.6902\n",
      "Epoch 291/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1511 - acc: 0.9440 - val_loss: 1.6580 - val_acc: 0.7101\n",
      "Epoch 292/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1480 - acc: 0.9453 - val_loss: 1.8510 - val_acc: 0.6742\n",
      "Epoch 293/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1485 - acc: 0.9454 - val_loss: 1.7478 - val_acc: 0.6995\n",
      "Epoch 294/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1470 - acc: 0.9460 - val_loss: 1.5517 - val_acc: 0.7054\n",
      "Epoch 295/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1472 - acc: 0.9455 - val_loss: 1.5970 - val_acc: 0.7169\n",
      "Epoch 296/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1470 - acc: 0.9455 - val_loss: 1.5556 - val_acc: 0.7118\n",
      "Epoch 297/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1486 - acc: 0.9447 - val_loss: 1.5045 - val_acc: 0.7107\n",
      "Epoch 298/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1472 - acc: 0.9453 - val_loss: 1.6952 - val_acc: 0.7088\n",
      "Epoch 299/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1438 - acc: 0.9465 - val_loss: 1.7973 - val_acc: 0.6788\n",
      "Epoch 300/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1484 - acc: 0.9445 - val_loss: 1.6032 - val_acc: 0.7104\n",
      "Epoch 301/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1474 - acc: 0.9462 - val_loss: 1.4747 - val_acc: 0.7189\n",
      "Epoch 302/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1439 - acc: 0.9465 - val_loss: 1.4662 - val_acc: 0.7068\n",
      "Epoch 303/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1423 - acc: 0.9472 - val_loss: 1.7292 - val_acc: 0.7038\n",
      "Epoch 304/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1470 - acc: 0.9456 - val_loss: 1.5852 - val_acc: 0.6932\n",
      "Epoch 305/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1443 - acc: 0.9472 - val_loss: 1.5541 - val_acc: 0.7041\n",
      "Epoch 306/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1448 - acc: 0.9461 - val_loss: 1.5045 - val_acc: 0.7156\n",
      "Epoch 307/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1439 - acc: 0.9468 - val_loss: 1.5903 - val_acc: 0.7134\n",
      "Epoch 308/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1444 - acc: 0.9466 - val_loss: 1.6205 - val_acc: 0.7073\n",
      "Epoch 309/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1434 - acc: 0.9471 - val_loss: 1.5720 - val_acc: 0.7108\n",
      "Epoch 310/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1420 - acc: 0.9476 - val_loss: 1.5221 - val_acc: 0.7130\n",
      "Epoch 311/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1451 - acc: 0.9464 - val_loss: 1.8062 - val_acc: 0.6908\n",
      "Epoch 312/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1452 - acc: 0.9454 - val_loss: 1.5776 - val_acc: 0.7134\n",
      "Epoch 313/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1423 - acc: 0.9470 - val_loss: 1.5121 - val_acc: 0.7183\n",
      "Epoch 314/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1446 - acc: 0.9459 - val_loss: 1.6286 - val_acc: 0.7073\n",
      "Epoch 315/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1457 - acc: 0.9469 - val_loss: 1.4565 - val_acc: 0.7229\n",
      "Epoch 316/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1402 - acc: 0.9474 - val_loss: 1.7899 - val_acc: 0.6900\n",
      "Epoch 317/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1428 - acc: 0.9472 - val_loss: 1.5634 - val_acc: 0.7108\n",
      "Epoch 318/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1449 - acc: 0.9466 - val_loss: 1.6422 - val_acc: 0.7166\n",
      "Epoch 319/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1419 - acc: 0.9480 - val_loss: 1.6670 - val_acc: 0.7163\n",
      "Epoch 320/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1413 - acc: 0.9478 - val_loss: 1.5927 - val_acc: 0.7264\n",
      "Epoch 321/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1434 - acc: 0.9467 - val_loss: 1.4462 - val_acc: 0.7147\n",
      "Epoch 322/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1438 - acc: 0.9470 - val_loss: 1.6548 - val_acc: 0.7196\n",
      "Epoch 323/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1436 - acc: 0.9476 - val_loss: 1.6483 - val_acc: 0.7022\n",
      "Epoch 324/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1399 - acc: 0.9491 - val_loss: 1.6247 - val_acc: 0.7056\n",
      "Epoch 325/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1405 - acc: 0.9482 - val_loss: 1.5923 - val_acc: 0.7157\n",
      "Epoch 326/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1435 - acc: 0.9474 - val_loss: 1.6520 - val_acc: 0.7017\n",
      "Epoch 327/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1381 - acc: 0.9490 - val_loss: 1.3898 - val_acc: 0.7277\n",
      "Epoch 328/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1446 - acc: 0.9463 - val_loss: 1.8269 - val_acc: 0.7021\n",
      "Epoch 329/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1419 - acc: 0.9475 - val_loss: 1.7051 - val_acc: 0.7202\n",
      "Epoch 330/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1398 - acc: 0.9485 - val_loss: 1.4990 - val_acc: 0.7128\n",
      "Epoch 331/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1393 - acc: 0.9486 - val_loss: 1.5194 - val_acc: 0.7073\n",
      "Epoch 332/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1395 - acc: 0.9488 - val_loss: 1.4976 - val_acc: 0.7131\n",
      "Epoch 333/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1412 - acc: 0.9480 - val_loss: 1.7633 - val_acc: 0.7023\n",
      "Epoch 334/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1388 - acc: 0.9489 - val_loss: 1.4636 - val_acc: 0.7144\n",
      "Epoch 335/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1392 - acc: 0.9485 - val_loss: 1.5534 - val_acc: 0.7087\n",
      "Epoch 336/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1380 - acc: 0.9489 - val_loss: 1.7107 - val_acc: 0.6995\n",
      "Epoch 337/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1399 - acc: 0.9484 - val_loss: 1.5364 - val_acc: 0.7161\n",
      "Epoch 338/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1425 - acc: 0.9476 - val_loss: 1.5574 - val_acc: 0.7206\n",
      "Epoch 339/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1400 - acc: 0.9481 - val_loss: 1.7433 - val_acc: 0.7007\n",
      "Epoch 340/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1363 - acc: 0.9493 - val_loss: 1.6035 - val_acc: 0.7165\n",
      "Epoch 341/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1394 - acc: 0.9486 - val_loss: 1.5259 - val_acc: 0.6999\n",
      "Epoch 342/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1379 - acc: 0.9497 - val_loss: 1.7331 - val_acc: 0.6960\n",
      "Epoch 343/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1371 - acc: 0.9492 - val_loss: 1.4831 - val_acc: 0.7148\n",
      "Epoch 344/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1358 - acc: 0.9498 - val_loss: 1.3546 - val_acc: 0.7259\n",
      "Epoch 345/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1382 - acc: 0.9491 - val_loss: 1.6638 - val_acc: 0.6975\n",
      "Epoch 346/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1370 - acc: 0.9497 - val_loss: 1.5513 - val_acc: 0.7108\n",
      "Epoch 347/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1363 - acc: 0.9489 - val_loss: 1.4714 - val_acc: 0.7209\n",
      "Epoch 348/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1372 - acc: 0.9497 - val_loss: 1.7150 - val_acc: 0.7059\n",
      "Epoch 349/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1368 - acc: 0.9504 - val_loss: 1.7660 - val_acc: 0.7093\n",
      "Epoch 350/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1390 - acc: 0.9488 - val_loss: 1.5422 - val_acc: 0.7033\n",
      "Epoch 351/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1355 - acc: 0.9494 - val_loss: 1.7526 - val_acc: 0.6988\n",
      "Epoch 352/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1378 - acc: 0.9488 - val_loss: 1.6203 - val_acc: 0.7153\n",
      "Epoch 353/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1393 - acc: 0.9488 - val_loss: 1.6893 - val_acc: 0.7150\n",
      "Epoch 354/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1348 - acc: 0.9510 - val_loss: 1.5772 - val_acc: 0.7163\n",
      "Epoch 355/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1332 - acc: 0.9507 - val_loss: 1.7357 - val_acc: 0.7120\n",
      "Epoch 356/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1335 - acc: 0.9511 - val_loss: 1.5570 - val_acc: 0.7271\n",
      "Epoch 357/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1353 - acc: 0.9509 - val_loss: 1.6640 - val_acc: 0.7152\n",
      "Epoch 358/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1373 - acc: 0.9495 - val_loss: 1.8728 - val_acc: 0.6987\n",
      "Epoch 359/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1356 - acc: 0.9493 - val_loss: 1.6452 - val_acc: 0.7153\n",
      "Epoch 360/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1333 - acc: 0.9510 - val_loss: 1.6402 - val_acc: 0.7189\n",
      "Epoch 361/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1316 - acc: 0.9517 - val_loss: 1.7369 - val_acc: 0.7142\n",
      "Epoch 362/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1341 - acc: 0.9507 - val_loss: 1.7022 - val_acc: 0.7123\n",
      "Epoch 363/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1327 - acc: 0.9515 - val_loss: 1.6158 - val_acc: 0.7080\n",
      "Epoch 364/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1351 - acc: 0.9503 - val_loss: 2.0263 - val_acc: 0.6770\n",
      "Epoch 365/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1338 - acc: 0.9512 - val_loss: 1.7096 - val_acc: 0.7159\n",
      "Epoch 366/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1356 - acc: 0.9502 - val_loss: 1.5770 - val_acc: 0.7235\n",
      "Epoch 367/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1334 - acc: 0.9506 - val_loss: 1.7615 - val_acc: 0.7127\n",
      "Epoch 368/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1358 - acc: 0.9504 - val_loss: 1.5695 - val_acc: 0.7081\n",
      "Epoch 369/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1336 - acc: 0.9508 - val_loss: 1.6553 - val_acc: 0.7082\n",
      "Epoch 370/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1344 - acc: 0.9509 - val_loss: 1.6093 - val_acc: 0.7160\n",
      "Epoch 371/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1332 - acc: 0.9503 - val_loss: 1.8478 - val_acc: 0.6935\n",
      "Epoch 372/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1335 - acc: 0.9512 - val_loss: 1.5467 - val_acc: 0.7236\n",
      "Epoch 373/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1341 - acc: 0.9505 - val_loss: 1.8583 - val_acc: 0.7040\n",
      "Epoch 374/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1316 - acc: 0.9520 - val_loss: 1.7171 - val_acc: 0.7070\n",
      "Epoch 375/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1326 - acc: 0.9514 - val_loss: 1.9049 - val_acc: 0.6889\n",
      "Epoch 376/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1316 - acc: 0.9515 - val_loss: 1.4401 - val_acc: 0.7266\n",
      "Epoch 377/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1319 - acc: 0.9511 - val_loss: 2.0839 - val_acc: 0.6970\n",
      "Epoch 378/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1292 - acc: 0.9527 - val_loss: 1.6452 - val_acc: 0.7199\n",
      "Epoch 379/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1295 - acc: 0.9518 - val_loss: 1.5291 - val_acc: 0.7187\n",
      "Epoch 380/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1304 - acc: 0.9514 - val_loss: 1.5690 - val_acc: 0.7170\n",
      "Epoch 381/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1308 - acc: 0.9520 - val_loss: 1.5481 - val_acc: 0.7283\n",
      "Epoch 382/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1347 - acc: 0.9504 - val_loss: 1.6355 - val_acc: 0.7194\n",
      "Epoch 383/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1318 - acc: 0.9518 - val_loss: 1.6443 - val_acc: 0.7138\n",
      "Epoch 384/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1289 - acc: 0.9523 - val_loss: 1.7702 - val_acc: 0.7058\n",
      "Epoch 385/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1296 - acc: 0.9520 - val_loss: 1.5756 - val_acc: 0.7270\n",
      "Epoch 386/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1317 - acc: 0.9515 - val_loss: 1.8059 - val_acc: 0.7051\n",
      "Epoch 387/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1297 - acc: 0.9522 - val_loss: 1.4992 - val_acc: 0.7135\n",
      "Epoch 388/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1315 - acc: 0.9521 - val_loss: 1.6024 - val_acc: 0.7244\n",
      "Epoch 389/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1273 - acc: 0.9532 - val_loss: 1.6200 - val_acc: 0.7067\n",
      "Epoch 390/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1255 - acc: 0.9537 - val_loss: 1.7937 - val_acc: 0.7092\n",
      "Epoch 391/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1293 - acc: 0.9526 - val_loss: 1.7119 - val_acc: 0.7231\n",
      "Epoch 392/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1332 - acc: 0.9512 - val_loss: 1.6861 - val_acc: 0.7109\n",
      "Epoch 393/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1302 - acc: 0.9526 - val_loss: 1.7125 - val_acc: 0.7220\n",
      "Epoch 394/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1304 - acc: 0.9519 - val_loss: 1.7146 - val_acc: 0.7089\n",
      "Epoch 395/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1299 - acc: 0.9520 - val_loss: 2.0302 - val_acc: 0.6956\n",
      "Epoch 396/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1315 - acc: 0.9516 - val_loss: 1.5301 - val_acc: 0.7180\n",
      "Epoch 397/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1287 - acc: 0.9525 - val_loss: 1.6828 - val_acc: 0.7096\n",
      "Epoch 398/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1271 - acc: 0.9527 - val_loss: 1.6642 - val_acc: 0.7075\n",
      "Epoch 399/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1280 - acc: 0.9524 - val_loss: 1.9201 - val_acc: 0.6959\n",
      "Epoch 400/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1288 - acc: 0.9519 - val_loss: 1.7509 - val_acc: 0.7156\n",
      "Epoch 401/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1288 - acc: 0.9531 - val_loss: 1.7380 - val_acc: 0.7113\n",
      "Epoch 402/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1220 - acc: 0.9551 - val_loss: 1.7247 - val_acc: 0.7196\n",
      "Epoch 403/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1261 - acc: 0.9533 - val_loss: 1.6811 - val_acc: 0.7127\n",
      "Epoch 404/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1260 - acc: 0.9539 - val_loss: 1.5942 - val_acc: 0.7141\n",
      "Epoch 405/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1267 - acc: 0.9538 - val_loss: 1.7970 - val_acc: 0.7080\n",
      "Epoch 406/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1301 - acc: 0.9526 - val_loss: 1.5683 - val_acc: 0.7247\n",
      "Epoch 407/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1283 - acc: 0.9532 - val_loss: 1.9035 - val_acc: 0.7014\n",
      "Epoch 408/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1285 - acc: 0.9530 - val_loss: 1.6203 - val_acc: 0.7135\n",
      "Epoch 409/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1290 - acc: 0.9530 - val_loss: 1.5069 - val_acc: 0.7210\n",
      "Epoch 410/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1270 - acc: 0.9532 - val_loss: 1.5868 - val_acc: 0.7156\n",
      "Epoch 411/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1230 - acc: 0.9542 - val_loss: 1.9758 - val_acc: 0.6963\n",
      "Epoch 412/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1260 - acc: 0.9535 - val_loss: 1.4440 - val_acc: 0.7227\n",
      "Epoch 413/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1279 - acc: 0.9534 - val_loss: 1.6097 - val_acc: 0.7009\n",
      "Epoch 414/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1274 - acc: 0.9536 - val_loss: 1.8472 - val_acc: 0.7056\n",
      "Epoch 415/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1250 - acc: 0.9537 - val_loss: 1.6456 - val_acc: 0.7180\n",
      "Epoch 416/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1259 - acc: 0.9537 - val_loss: 1.8874 - val_acc: 0.7063\n",
      "Epoch 417/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1255 - acc: 0.9541 - val_loss: 1.7230 - val_acc: 0.7130\n",
      "Epoch 418/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1282 - acc: 0.9526 - val_loss: 1.5740 - val_acc: 0.7160\n",
      "Epoch 419/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1254 - acc: 0.9536 - val_loss: 1.4929 - val_acc: 0.7246\n",
      "Epoch 420/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1240 - acc: 0.9546 - val_loss: 1.7697 - val_acc: 0.7156\n",
      "Epoch 421/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1250 - acc: 0.9540 - val_loss: 1.7836 - val_acc: 0.6989\n",
      "Epoch 422/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1256 - acc: 0.9536 - val_loss: 2.1641 - val_acc: 0.6712\n",
      "Epoch 423/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1270 - acc: 0.9532 - val_loss: 1.7134 - val_acc: 0.7151\n",
      "Epoch 424/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1251 - acc: 0.9533 - val_loss: 1.8137 - val_acc: 0.7106\n",
      "Epoch 425/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1242 - acc: 0.9545 - val_loss: 1.7132 - val_acc: 0.7121\n",
      "Epoch 426/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1244 - acc: 0.9541 - val_loss: 1.9122 - val_acc: 0.6950\n",
      "Epoch 427/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1248 - acc: 0.9535 - val_loss: 1.5603 - val_acc: 0.7169\n",
      "Epoch 428/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1244 - acc: 0.9537 - val_loss: 1.5581 - val_acc: 0.7210\n",
      "Epoch 429/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1228 - acc: 0.9560 - val_loss: 1.6537 - val_acc: 0.7152\n",
      "Epoch 430/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1246 - acc: 0.9541 - val_loss: 1.6187 - val_acc: 0.7225\n",
      "Epoch 431/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1253 - acc: 0.9539 - val_loss: 1.6620 - val_acc: 0.7218\n",
      "Epoch 432/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1217 - acc: 0.9557 - val_loss: 1.5698 - val_acc: 0.7232\n",
      "Epoch 433/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1206 - acc: 0.9555 - val_loss: 1.7151 - val_acc: 0.7136\n",
      "Epoch 434/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1218 - acc: 0.9552 - val_loss: 1.6783 - val_acc: 0.7172\n",
      "Epoch 435/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1223 - acc: 0.9549 - val_loss: 1.5811 - val_acc: 0.7214\n",
      "Epoch 436/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1248 - acc: 0.9539 - val_loss: 1.7307 - val_acc: 0.7102\n",
      "Epoch 437/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1253 - acc: 0.9543 - val_loss: 1.7089 - val_acc: 0.7136\n",
      "Epoch 438/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1249 - acc: 0.9544 - val_loss: 1.5789 - val_acc: 0.7242\n",
      "Epoch 439/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1229 - acc: 0.9544 - val_loss: 1.6514 - val_acc: 0.7194\n",
      "Epoch 440/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1222 - acc: 0.9546 - val_loss: 1.9328 - val_acc: 0.6931\n",
      "Epoch 441/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1200 - acc: 0.9557 - val_loss: 1.6430 - val_acc: 0.7165\n",
      "Epoch 442/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1249 - acc: 0.9538 - val_loss: 1.6454 - val_acc: 0.7180\n",
      "Epoch 443/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1195 - acc: 0.9559 - val_loss: 1.6224 - val_acc: 0.7345\n",
      "Epoch 444/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1210 - acc: 0.9554 - val_loss: 1.8705 - val_acc: 0.7025\n",
      "Epoch 445/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1218 - acc: 0.9556 - val_loss: 1.6219 - val_acc: 0.7159\n",
      "Epoch 446/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1214 - acc: 0.9554 - val_loss: 1.7485 - val_acc: 0.7015\n",
      "Epoch 447/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1218 - acc: 0.9557 - val_loss: 1.6970 - val_acc: 0.7156\n",
      "Epoch 448/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1182 - acc: 0.9572 - val_loss: 1.7567 - val_acc: 0.7146\n",
      "Epoch 449/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1223 - acc: 0.9548 - val_loss: 1.5961 - val_acc: 0.7191\n",
      "Epoch 450/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1193 - acc: 0.9557 - val_loss: 1.9565 - val_acc: 0.6988\n",
      "Epoch 451/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1188 - acc: 0.9563 - val_loss: 1.7042 - val_acc: 0.7060\n",
      "Epoch 452/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1214 - acc: 0.9556 - val_loss: 1.5550 - val_acc: 0.7244\n",
      "Epoch 453/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1212 - acc: 0.9554 - val_loss: 1.6929 - val_acc: 0.7163\n",
      "Epoch 454/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1212 - acc: 0.9552 - val_loss: 1.6634 - val_acc: 0.7208\n",
      "Epoch 455/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1196 - acc: 0.9556 - val_loss: 1.6212 - val_acc: 0.7211\n",
      "Epoch 456/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1222 - acc: 0.9553 - val_loss: 1.7698 - val_acc: 0.7129\n",
      "Epoch 457/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1208 - acc: 0.9558 - val_loss: 1.6795 - val_acc: 0.7200\n",
      "Epoch 458/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1195 - acc: 0.9561 - val_loss: 1.7985 - val_acc: 0.7142\n",
      "Epoch 459/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1217 - acc: 0.9550 - val_loss: 1.7598 - val_acc: 0.7172\n",
      "Epoch 460/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1191 - acc: 0.9561 - val_loss: 1.6785 - val_acc: 0.7192\n",
      "Epoch 461/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1193 - acc: 0.9566 - val_loss: 1.7221 - val_acc: 0.7104\n",
      "Epoch 462/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1205 - acc: 0.9562 - val_loss: 1.7714 - val_acc: 0.7077\n",
      "Epoch 463/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1201 - acc: 0.9547 - val_loss: 1.6067 - val_acc: 0.7200\n",
      "Epoch 464/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1165 - acc: 0.9569 - val_loss: 1.6613 - val_acc: 0.7215\n",
      "Epoch 465/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1203 - acc: 0.9558 - val_loss: 1.6114 - val_acc: 0.7224\n",
      "Epoch 466/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1197 - acc: 0.9562 - val_loss: 1.6519 - val_acc: 0.7074\n",
      "Epoch 467/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1219 - acc: 0.9559 - val_loss: 1.7386 - val_acc: 0.7168\n",
      "Epoch 468/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1188 - acc: 0.9567 - val_loss: 1.6847 - val_acc: 0.7177\n",
      "Epoch 469/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1169 - acc: 0.9571 - val_loss: 1.7179 - val_acc: 0.7242\n",
      "Epoch 470/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1169 - acc: 0.9572 - val_loss: 1.8069 - val_acc: 0.7069\n",
      "Epoch 471/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1191 - acc: 0.9560 - val_loss: 1.7869 - val_acc: 0.7085\n",
      "Epoch 472/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1160 - acc: 0.9576 - val_loss: 1.9383 - val_acc: 0.6997\n",
      "Epoch 473/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1180 - acc: 0.9573 - val_loss: 1.7614 - val_acc: 0.7197\n",
      "Epoch 474/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1175 - acc: 0.9574 - val_loss: 1.6698 - val_acc: 0.7197\n",
      "Epoch 475/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1170 - acc: 0.9569 - val_loss: 1.5725 - val_acc: 0.7191\n",
      "Epoch 476/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1159 - acc: 0.9572 - val_loss: 1.8440 - val_acc: 0.7149\n",
      "Epoch 477/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1148 - acc: 0.9581 - val_loss: 1.6326 - val_acc: 0.7236\n",
      "Epoch 478/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1179 - acc: 0.9559 - val_loss: 1.6648 - val_acc: 0.7201\n",
      "Epoch 479/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1151 - acc: 0.9578 - val_loss: 1.5832 - val_acc: 0.7137\n",
      "Epoch 480/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1163 - acc: 0.9572 - val_loss: 1.5376 - val_acc: 0.7274\n",
      "Epoch 481/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1166 - acc: 0.9572 - val_loss: 1.6368 - val_acc: 0.7245\n",
      "Epoch 482/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1158 - acc: 0.9573 - val_loss: 1.6423 - val_acc: 0.7158\n",
      "Epoch 483/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1187 - acc: 0.9565 - val_loss: 1.7318 - val_acc: 0.7229\n",
      "Epoch 484/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1158 - acc: 0.9571 - val_loss: 1.8328 - val_acc: 0.7101\n",
      "Epoch 485/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1178 - acc: 0.9563 - val_loss: 1.6421 - val_acc: 0.7177\n",
      "Epoch 486/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1173 - acc: 0.9570 - val_loss: 1.6968 - val_acc: 0.7178\n",
      "Epoch 487/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1187 - acc: 0.9565 - val_loss: 1.7003 - val_acc: 0.7268\n",
      "Epoch 488/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1177 - acc: 0.9567 - val_loss: 1.7629 - val_acc: 0.7098\n",
      "Epoch 489/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1170 - acc: 0.9576 - val_loss: 1.7861 - val_acc: 0.7032\n",
      "Epoch 490/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1130 - acc: 0.9584 - val_loss: 1.7032 - val_acc: 0.7189\n",
      "Epoch 491/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1178 - acc: 0.9574 - val_loss: 1.7810 - val_acc: 0.7185\n",
      "Epoch 492/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1159 - acc: 0.9572 - val_loss: 1.7702 - val_acc: 0.7227\n",
      "Epoch 493/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1129 - acc: 0.9587 - val_loss: 1.6844 - val_acc: 0.7193\n",
      "Epoch 494/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1145 - acc: 0.9569 - val_loss: 1.6542 - val_acc: 0.7242\n",
      "Epoch 495/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1161 - acc: 0.9571 - val_loss: 1.9643 - val_acc: 0.6784\n",
      "Epoch 496/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1156 - acc: 0.9575 - val_loss: 1.6395 - val_acc: 0.7212\n",
      "Epoch 497/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1161 - acc: 0.9570 - val_loss: 1.9397 - val_acc: 0.6963\n",
      "Epoch 498/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1152 - acc: 0.9583 - val_loss: 1.6928 - val_acc: 0.7271\n",
      "Epoch 499/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9583 - val_loss: 1.8546 - val_acc: 0.7084\n",
      "Epoch 500/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1122 - acc: 0.9587 - val_loss: 1.5248 - val_acc: 0.7153\n",
      "Epoch 501/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1143 - acc: 0.9580 - val_loss: 1.6063 - val_acc: 0.7197\n",
      "Epoch 502/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1164 - acc: 0.9569 - val_loss: 1.6668 - val_acc: 0.7277\n",
      "Epoch 503/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1101 - acc: 0.9600 - val_loss: 1.6885 - val_acc: 0.7199\n",
      "Epoch 504/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1146 - acc: 0.9578 - val_loss: 1.6113 - val_acc: 0.7063\n",
      "Epoch 505/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9582 - val_loss: 1.7129 - val_acc: 0.7137\n",
      "Epoch 506/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1124 - acc: 0.9582 - val_loss: 1.7914 - val_acc: 0.7194\n",
      "Epoch 507/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1127 - acc: 0.9593 - val_loss: 1.7135 - val_acc: 0.7138\n",
      "Epoch 508/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1104 - acc: 0.9588 - val_loss: 1.8054 - val_acc: 0.6932\n",
      "Epoch 509/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1117 - acc: 0.9588 - val_loss: 1.9685 - val_acc: 0.7001\n",
      "Epoch 510/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1148 - acc: 0.9581 - val_loss: 1.7726 - val_acc: 0.7139\n",
      "Epoch 511/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1141 - acc: 0.9581 - val_loss: 1.6571 - val_acc: 0.7162\n",
      "Epoch 512/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1098 - acc: 0.9598 - val_loss: 1.7823 - val_acc: 0.7176\n",
      "Epoch 513/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1120 - acc: 0.9590 - val_loss: 1.6138 - val_acc: 0.7180\n",
      "Epoch 514/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1126 - acc: 0.9580 - val_loss: 1.7675 - val_acc: 0.7094\n",
      "Epoch 515/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1149 - acc: 0.9582 - val_loss: 1.8387 - val_acc: 0.7151\n",
      "Epoch 516/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1131 - acc: 0.9587 - val_loss: 2.0942 - val_acc: 0.6868\n",
      "Epoch 517/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1095 - acc: 0.9604 - val_loss: 1.7448 - val_acc: 0.7195\n",
      "Epoch 518/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1125 - acc: 0.9584 - val_loss: 1.6435 - val_acc: 0.7277\n",
      "Epoch 519/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1116 - acc: 0.9591 - val_loss: 1.6830 - val_acc: 0.7296\n",
      "Epoch 520/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1122 - acc: 0.9593 - val_loss: 1.8209 - val_acc: 0.7088\n",
      "Epoch 521/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1126 - acc: 0.9583 - val_loss: 1.6904 - val_acc: 0.7189\n",
      "Epoch 522/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1133 - acc: 0.9576 - val_loss: 2.0106 - val_acc: 0.6999\n",
      "Epoch 523/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1116 - acc: 0.9594 - val_loss: 1.7077 - val_acc: 0.7280\n",
      "Epoch 524/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1133 - acc: 0.9580 - val_loss: 1.8020 - val_acc: 0.7111\n",
      "Epoch 525/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1140 - acc: 0.9579 - val_loss: 1.7880 - val_acc: 0.7120\n",
      "Epoch 526/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1126 - acc: 0.9588 - val_loss: 1.9006 - val_acc: 0.7083\n",
      "Epoch 527/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1124 - acc: 0.9582 - val_loss: 1.7345 - val_acc: 0.7237\n",
      "Epoch 528/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1100 - acc: 0.9594 - val_loss: 1.7969 - val_acc: 0.7184\n",
      "Epoch 529/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1114 - acc: 0.9592 - val_loss: 1.6580 - val_acc: 0.7287\n",
      "Epoch 530/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1104 - acc: 0.9594 - val_loss: 1.8534 - val_acc: 0.7095\n",
      "Epoch 531/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1150 - acc: 0.9575 - val_loss: 1.6131 - val_acc: 0.7251\n",
      "Epoch 532/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1086 - acc: 0.9604 - val_loss: 1.7782 - val_acc: 0.7250\n",
      "Epoch 533/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1072 - acc: 0.9604 - val_loss: 1.6073 - val_acc: 0.7281\n",
      "Epoch 534/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1112 - acc: 0.9584 - val_loss: 1.7839 - val_acc: 0.7203\n",
      "Epoch 535/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1098 - acc: 0.9596 - val_loss: 1.6266 - val_acc: 0.7171\n",
      "Epoch 536/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1101 - acc: 0.9594 - val_loss: 1.6549 - val_acc: 0.7210\n",
      "Epoch 537/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1128 - acc: 0.9584 - val_loss: 1.5489 - val_acc: 0.7218\n",
      "Epoch 538/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1092 - acc: 0.9601 - val_loss: 1.8541 - val_acc: 0.7016\n",
      "Epoch 539/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1103 - acc: 0.9598 - val_loss: 1.7727 - val_acc: 0.7177\n",
      "Epoch 540/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1120 - acc: 0.9588 - val_loss: 1.7381 - val_acc: 0.7216\n",
      "Epoch 541/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1128 - acc: 0.9586 - val_loss: 1.6816 - val_acc: 0.7311\n",
      "Epoch 542/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1069 - acc: 0.9606 - val_loss: 1.6577 - val_acc: 0.7232\n",
      "Epoch 543/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1086 - acc: 0.9606 - val_loss: 1.7025 - val_acc: 0.7206\n",
      "Epoch 544/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1091 - acc: 0.9602 - val_loss: 1.6405 - val_acc: 0.7213\n",
      "Epoch 545/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1113 - acc: 0.9595 - val_loss: 1.7600 - val_acc: 0.7270\n",
      "Epoch 546/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1080 - acc: 0.9607 - val_loss: 1.8534 - val_acc: 0.7085\n",
      "Epoch 547/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1117 - acc: 0.9592 - val_loss: 1.6830 - val_acc: 0.7131\n",
      "Epoch 548/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1103 - acc: 0.9595 - val_loss: 1.6819 - val_acc: 0.7222\n",
      "Epoch 549/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1080 - acc: 0.9603 - val_loss: 1.6621 - val_acc: 0.7247\n",
      "Epoch 550/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1095 - acc: 0.9593 - val_loss: 1.8143 - val_acc: 0.7214\n",
      "Epoch 551/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1093 - acc: 0.9596 - val_loss: 1.6663 - val_acc: 0.7261\n",
      "Epoch 552/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1099 - acc: 0.9600 - val_loss: 1.7053 - val_acc: 0.7250\n",
      "Epoch 553/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1089 - acc: 0.9601 - val_loss: 1.7564 - val_acc: 0.7197\n",
      "Epoch 554/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1090 - acc: 0.9604 - val_loss: 1.6218 - val_acc: 0.7206\n",
      "Epoch 555/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1060 - acc: 0.9607 - val_loss: 1.9485 - val_acc: 0.7030\n",
      "Epoch 556/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1058 - acc: 0.9609 - val_loss: 1.7003 - val_acc: 0.7280\n",
      "Epoch 557/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1080 - acc: 0.9605 - val_loss: 1.9130 - val_acc: 0.7001\n",
      "Epoch 558/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1074 - acc: 0.9600 - val_loss: 1.9388 - val_acc: 0.7009\n",
      "Epoch 559/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1082 - acc: 0.9604 - val_loss: 1.7165 - val_acc: 0.7273\n",
      "Epoch 560/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1080 - acc: 0.9604 - val_loss: 1.8541 - val_acc: 0.7124\n",
      "Epoch 561/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1088 - acc: 0.9600 - val_loss: 1.6539 - val_acc: 0.7299\n",
      "Epoch 562/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1094 - acc: 0.9602 - val_loss: 1.7245 - val_acc: 0.7191\n",
      "Epoch 563/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1107 - acc: 0.9593 - val_loss: 1.7292 - val_acc: 0.7175\n",
      "Epoch 564/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1090 - acc: 0.9596 - val_loss: 1.7839 - val_acc: 0.7222\n",
      "Epoch 565/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1098 - acc: 0.9594 - val_loss: 1.8469 - val_acc: 0.7073\n",
      "Epoch 566/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1060 - acc: 0.9614 - val_loss: 1.6485 - val_acc: 0.7263\n",
      "Epoch 567/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1038 - acc: 0.9620 - val_loss: 1.6341 - val_acc: 0.7221\n",
      "Epoch 568/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1087 - acc: 0.9604 - val_loss: 2.0569 - val_acc: 0.7060\n",
      "Epoch 569/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1064 - acc: 0.9609 - val_loss: 1.8106 - val_acc: 0.7229\n",
      "Epoch 570/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1060 - acc: 0.9606 - val_loss: 1.9287 - val_acc: 0.7058\n",
      "Epoch 571/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1054 - acc: 0.9610 - val_loss: 1.7641 - val_acc: 0.7252\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1092 - acc: 0.9607 - val_loss: 1.7989 - val_acc: 0.7135\n",
      "Epoch 573/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1051 - acc: 0.9612 - val_loss: 1.7353 - val_acc: 0.7258\n",
      "Epoch 574/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1041 - acc: 0.9622 - val_loss: 1.9566 - val_acc: 0.7155\n",
      "Epoch 575/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1075 - acc: 0.9603 - val_loss: 1.7661 - val_acc: 0.7186\n",
      "Epoch 576/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1079 - acc: 0.9610 - val_loss: 1.7006 - val_acc: 0.7277\n",
      "Epoch 577/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1065 - acc: 0.9608 - val_loss: 1.8947 - val_acc: 0.7084\n",
      "Epoch 578/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1087 - acc: 0.9599 - val_loss: 1.8612 - val_acc: 0.7134\n",
      "Epoch 579/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1064 - acc: 0.9612 - val_loss: 1.8405 - val_acc: 0.7250\n",
      "Epoch 580/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1065 - acc: 0.9616 - val_loss: 1.7343 - val_acc: 0.7192\n",
      "Epoch 581/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1054 - acc: 0.9614 - val_loss: 1.9153 - val_acc: 0.7185\n",
      "Epoch 582/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1024 - acc: 0.9629 - val_loss: 1.6717 - val_acc: 0.7222\n",
      "Epoch 583/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1065 - acc: 0.9608 - val_loss: 1.8920 - val_acc: 0.7177\n",
      "Epoch 584/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1049 - acc: 0.9618 - val_loss: 2.1192 - val_acc: 0.6989\n",
      "Epoch 585/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1044 - acc: 0.9616 - val_loss: 1.7600 - val_acc: 0.7111\n",
      "Epoch 586/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1070 - acc: 0.9605 - val_loss: 1.7720 - val_acc: 0.7218\n",
      "Epoch 587/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1046 - acc: 0.9619 - val_loss: 1.9316 - val_acc: 0.7116\n",
      "Epoch 588/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1059 - acc: 0.9615 - val_loss: 1.8979 - val_acc: 0.6949\n",
      "Epoch 589/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1065 - acc: 0.9613 - val_loss: 1.7794 - val_acc: 0.7170\n",
      "Epoch 590/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1036 - acc: 0.9620 - val_loss: 1.6050 - val_acc: 0.7353\n",
      "Epoch 591/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1083 - acc: 0.9605 - val_loss: 1.7040 - val_acc: 0.7224\n",
      "Epoch 592/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9617 - val_loss: 1.9868 - val_acc: 0.7099\n",
      "Epoch 593/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1049 - acc: 0.9618 - val_loss: 1.7720 - val_acc: 0.7161\n",
      "Epoch 594/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1057 - acc: 0.9610 - val_loss: 1.7535 - val_acc: 0.7262\n",
      "Epoch 595/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1038 - acc: 0.9623 - val_loss: 1.7812 - val_acc: 0.7218\n",
      "Epoch 596/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1028 - acc: 0.9623 - val_loss: 1.7671 - val_acc: 0.7210\n",
      "Epoch 597/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9624 - val_loss: 1.6826 - val_acc: 0.7244\n",
      "Epoch 598/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1049 - acc: 0.9617 - val_loss: 1.7167 - val_acc: 0.7234\n",
      "Epoch 599/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1053 - acc: 0.9619 - val_loss: 1.8961 - val_acc: 0.7107\n",
      "Epoch 600/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1052 - acc: 0.9618 - val_loss: 1.6928 - val_acc: 0.7294\n",
      "Epoch 601/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1047 - acc: 0.9621 - val_loss: 1.8691 - val_acc: 0.7137\n",
      "Epoch 602/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1042 - acc: 0.9625 - val_loss: 1.6833 - val_acc: 0.7269\n",
      "Epoch 603/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1021 - acc: 0.9628 - val_loss: 1.8282 - val_acc: 0.7177\n",
      "Epoch 604/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1026 - acc: 0.9624 - val_loss: 1.6611 - val_acc: 0.7285\n",
      "Epoch 605/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1076 - acc: 0.9609 - val_loss: 1.8188 - val_acc: 0.7121\n",
      "Epoch 606/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1018 - acc: 0.9628 - val_loss: 1.8856 - val_acc: 0.7104\n",
      "Epoch 607/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1048 - acc: 0.9618 - val_loss: 1.6874 - val_acc: 0.7291\n",
      "Epoch 608/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1032 - acc: 0.9630 - val_loss: 1.8143 - val_acc: 0.7057\n",
      "Epoch 609/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1051 - acc: 0.9617 - val_loss: 1.7773 - val_acc: 0.7251\n",
      "Epoch 610/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1030 - acc: 0.9628 - val_loss: 1.5869 - val_acc: 0.7268\n",
      "Epoch 611/1000\n",
      "113600/113600 [==============================] - 3s 28us/sample - loss: 0.1018 - acc: 0.9627 - val_loss: 1.9065 - val_acc: 0.7092\n",
      "Epoch 612/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1041 - acc: 0.9621 - val_loss: 1.6669 - val_acc: 0.7307\n",
      "Epoch 613/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1008 - acc: 0.9637 - val_loss: 1.8835 - val_acc: 0.7142\n",
      "Epoch 614/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1000 - acc: 0.9631 - val_loss: 1.7617 - val_acc: 0.7201\n",
      "Epoch 615/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1018 - acc: 0.9632 - val_loss: 2.1811 - val_acc: 0.6889\n",
      "Epoch 616/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1015 - acc: 0.9630 - val_loss: 1.7834 - val_acc: 0.7172\n",
      "Epoch 617/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1042 - acc: 0.9623 - val_loss: 1.9474 - val_acc: 0.7106\n",
      "Epoch 618/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1046 - acc: 0.9613 - val_loss: 1.6755 - val_acc: 0.7131\n",
      "Epoch 619/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1047 - acc: 0.9621 - val_loss: 1.5461 - val_acc: 0.7368\n",
      "Epoch 620/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1021 - acc: 0.9626 - val_loss: 1.7164 - val_acc: 0.7282\n",
      "Epoch 621/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1029 - acc: 0.9624 - val_loss: 1.7398 - val_acc: 0.7165\n",
      "Epoch 622/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1013 - acc: 0.9626 - val_loss: 1.9388 - val_acc: 0.7062\n",
      "Epoch 623/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1020 - acc: 0.9628 - val_loss: 1.7165 - val_acc: 0.7303\n",
      "Epoch 624/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1021 - acc: 0.9629 - val_loss: 1.8906 - val_acc: 0.7139\n",
      "Epoch 625/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0997 - acc: 0.9634 - val_loss: 1.6460 - val_acc: 0.7262\n",
      "Epoch 626/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1014 - acc: 0.9635 - val_loss: 1.7251 - val_acc: 0.7270\n",
      "Epoch 627/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1018 - acc: 0.9626 - val_loss: 1.7115 - val_acc: 0.7291\n",
      "Epoch 628/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0981 - acc: 0.9638 - val_loss: 1.7388 - val_acc: 0.7327\n",
      "Epoch 629/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1003 - acc: 0.9632 - val_loss: 1.6521 - val_acc: 0.7283\n",
      "Epoch 630/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0985 - acc: 0.9639 - val_loss: 1.7419 - val_acc: 0.7209\n",
      "Epoch 631/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1029 - acc: 0.9622 - val_loss: 2.0027 - val_acc: 0.7023\n",
      "Epoch 632/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1006 - acc: 0.9635 - val_loss: 1.7094 - val_acc: 0.7261\n",
      "Epoch 633/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1005 - acc: 0.9631 - val_loss: 1.6638 - val_acc: 0.7216\n",
      "Epoch 634/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1026 - acc: 0.9624 - val_loss: 1.8235 - val_acc: 0.7168\n",
      "Epoch 635/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0979 - acc: 0.9644 - val_loss: 1.7192 - val_acc: 0.7321\n",
      "Epoch 636/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1001 - acc: 0.9632 - val_loss: 1.7012 - val_acc: 0.7341\n",
      "Epoch 637/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1014 - acc: 0.9633 - val_loss: 1.6070 - val_acc: 0.7302\n",
      "Epoch 638/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.1012 - acc: 0.9636 - val_loss: 1.6896 - val_acc: 0.7325\n",
      "Epoch 639/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9638 - val_loss: 1.8082 - val_acc: 0.7220\n",
      "Epoch 640/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1038 - acc: 0.9620 - val_loss: 1.7575 - val_acc: 0.7263\n",
      "Epoch 641/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1003 - acc: 0.9638 - val_loss: 1.7601 - val_acc: 0.7196\n",
      "Epoch 642/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1018 - acc: 0.9628 - val_loss: 1.6825 - val_acc: 0.7292\n",
      "Epoch 643/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1013 - acc: 0.9632 - val_loss: 1.8719 - val_acc: 0.7277\n",
      "Epoch 644/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1012 - acc: 0.9628 - val_loss: 1.6668 - val_acc: 0.7332\n",
      "Epoch 645/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0987 - acc: 0.9637 - val_loss: 2.1310 - val_acc: 0.7040\n",
      "Epoch 646/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1006 - acc: 0.9638 - val_loss: 1.8714 - val_acc: 0.7249\n",
      "Epoch 647/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9636 - val_loss: 1.6953 - val_acc: 0.7286\n",
      "Epoch 648/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0986 - acc: 0.9642 - val_loss: 2.0461 - val_acc: 0.7078\n",
      "Epoch 649/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1007 - acc: 0.9632 - val_loss: 1.7549 - val_acc: 0.7200\n",
      "Epoch 650/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0993 - acc: 0.9637 - val_loss: 1.7294 - val_acc: 0.7306\n",
      "Epoch 651/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1035 - acc: 0.9624 - val_loss: 1.8770 - val_acc: 0.7144\n",
      "Epoch 652/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0991 - acc: 0.9639 - val_loss: 1.7934 - val_acc: 0.7180\n",
      "Epoch 653/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1000 - acc: 0.9640 - val_loss: 1.6746 - val_acc: 0.7271\n",
      "Epoch 654/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0992 - acc: 0.9641 - val_loss: 1.9293 - val_acc: 0.7122\n",
      "Epoch 655/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0977 - acc: 0.9640 - val_loss: 1.9457 - val_acc: 0.7130\n",
      "Epoch 656/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0992 - acc: 0.9635 - val_loss: 1.8111 - val_acc: 0.7223\n",
      "Epoch 657/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0993 - acc: 0.9635 - val_loss: 1.6537 - val_acc: 0.7265\n",
      "Epoch 658/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1010 - acc: 0.9628 - val_loss: 1.9657 - val_acc: 0.7162\n",
      "Epoch 659/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0975 - acc: 0.9637 - val_loss: 1.6269 - val_acc: 0.7352\n",
      "Epoch 660/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0996 - acc: 0.9637 - val_loss: 1.7080 - val_acc: 0.7270\n",
      "Epoch 661/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0997 - acc: 0.9634 - val_loss: 1.7613 - val_acc: 0.7267\n",
      "Epoch 662/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0975 - acc: 0.9642 - val_loss: 1.5851 - val_acc: 0.7250\n",
      "Epoch 663/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0963 - acc: 0.9653 - val_loss: 1.7344 - val_acc: 0.7283\n",
      "Epoch 664/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0978 - acc: 0.9642 - val_loss: 1.8415 - val_acc: 0.7122\n",
      "Epoch 665/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1012 - acc: 0.9636 - val_loss: 1.8373 - val_acc: 0.7209\n",
      "Epoch 666/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0983 - acc: 0.9642 - val_loss: 1.7719 - val_acc: 0.7282\n",
      "Epoch 667/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0999 - acc: 0.9634 - val_loss: 1.8979 - val_acc: 0.7129\n",
      "Epoch 668/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.1016 - acc: 0.9631 - val_loss: 1.7835 - val_acc: 0.7216\n",
      "Epoch 669/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.1002 - acc: 0.9635 - val_loss: 1.7471 - val_acc: 0.7224\n",
      "Epoch 670/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0994 - acc: 0.9636 - val_loss: 1.6201 - val_acc: 0.7358\n",
      "Epoch 671/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0939 - acc: 0.9652 - val_loss: 1.7656 - val_acc: 0.7248\n",
      "Epoch 672/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0994 - acc: 0.9643 - val_loss: 1.8356 - val_acc: 0.7201\n",
      "Epoch 673/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0977 - acc: 0.9645 - val_loss: 1.7958 - val_acc: 0.7143\n",
      "Epoch 674/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0983 - acc: 0.9640 - val_loss: 2.0300 - val_acc: 0.7042\n",
      "Epoch 675/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0996 - acc: 0.9638 - val_loss: 1.9435 - val_acc: 0.7132\n",
      "Epoch 676/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0968 - acc: 0.9642 - val_loss: 1.8178 - val_acc: 0.7282\n",
      "Epoch 677/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0967 - acc: 0.9648 - val_loss: 1.8700 - val_acc: 0.7185\n",
      "Epoch 678/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0945 - acc: 0.9657 - val_loss: 1.8358 - val_acc: 0.7180\n",
      "Epoch 679/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0972 - acc: 0.9649 - val_loss: 1.8110 - val_acc: 0.7237\n",
      "Epoch 680/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0943 - acc: 0.9651 - val_loss: 1.7373 - val_acc: 0.7256\n",
      "Epoch 681/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0977 - acc: 0.9644 - val_loss: 1.6905 - val_acc: 0.7327\n",
      "Epoch 682/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0958 - acc: 0.9650 - val_loss: 1.7486 - val_acc: 0.7201\n",
      "Epoch 683/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0979 - acc: 0.9643 - val_loss: 1.8161 - val_acc: 0.7311\n",
      "Epoch 684/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0967 - acc: 0.9651 - val_loss: 1.7703 - val_acc: 0.7204\n",
      "Epoch 685/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0941 - acc: 0.9653 - val_loss: 1.8374 - val_acc: 0.7197\n",
      "Epoch 686/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0966 - acc: 0.9651 - val_loss: 1.6483 - val_acc: 0.7361\n",
      "Epoch 687/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0979 - acc: 0.9643 - val_loss: 1.9671 - val_acc: 0.7113\n",
      "Epoch 688/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0962 - acc: 0.9650 - val_loss: 1.7996 - val_acc: 0.7258\n",
      "Epoch 689/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0951 - acc: 0.9648 - val_loss: 1.8087 - val_acc: 0.7310\n",
      "Epoch 690/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0929 - acc: 0.9662 - val_loss: 1.8689 - val_acc: 0.7216\n",
      "Epoch 691/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0957 - acc: 0.9647 - val_loss: 1.8401 - val_acc: 0.7098\n",
      "Epoch 692/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0960 - acc: 0.9648 - val_loss: 1.8489 - val_acc: 0.7061\n",
      "Epoch 693/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0943 - acc: 0.9660 - val_loss: 1.6111 - val_acc: 0.7325\n",
      "Epoch 694/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0938 - acc: 0.9652 - val_loss: 1.8366 - val_acc: 0.7233\n",
      "Epoch 695/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0957 - acc: 0.9650 - val_loss: 1.7430 - val_acc: 0.7311\n",
      "Epoch 696/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0965 - acc: 0.9646 - val_loss: 1.7163 - val_acc: 0.7297\n",
      "Epoch 697/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0967 - acc: 0.9646 - val_loss: 1.7601 - val_acc: 0.7318\n",
      "Epoch 698/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0973 - acc: 0.9647 - val_loss: 1.9508 - val_acc: 0.7047\n",
      "Epoch 699/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0990 - acc: 0.9637 - val_loss: 1.9805 - val_acc: 0.7058\n",
      "Epoch 700/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0956 - acc: 0.9652 - val_loss: 1.8357 - val_acc: 0.7211\n",
      "Epoch 701/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0973 - acc: 0.9642 - val_loss: 1.8704 - val_acc: 0.7139\n",
      "Epoch 702/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0982 - acc: 0.9640 - val_loss: 1.6265 - val_acc: 0.7298\n",
      "Epoch 703/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0958 - acc: 0.9651 - val_loss: 1.8685 - val_acc: 0.7157\n",
      "Epoch 704/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0929 - acc: 0.9663 - val_loss: 1.8228 - val_acc: 0.7260\n",
      "Epoch 705/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0961 - acc: 0.9655 - val_loss: 1.9088 - val_acc: 0.7189\n",
      "Epoch 706/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0978 - acc: 0.9644 - val_loss: 1.9764 - val_acc: 0.7174\n",
      "Epoch 707/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0952 - acc: 0.9646 - val_loss: 1.8103 - val_acc: 0.7223\n",
      "Epoch 708/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0948 - acc: 0.9653 - val_loss: 1.6524 - val_acc: 0.7398\n",
      "Epoch 709/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0944 - acc: 0.9656 - val_loss: 1.7520 - val_acc: 0.7057\n",
      "Epoch 710/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0973 - acc: 0.9646 - val_loss: 1.8093 - val_acc: 0.7222\n",
      "Epoch 711/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0966 - acc: 0.9649 - val_loss: 1.8399 - val_acc: 0.7132\n",
      "Epoch 712/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0970 - acc: 0.9647 - val_loss: 1.6598 - val_acc: 0.7301\n",
      "Epoch 713/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0938 - acc: 0.9655 - val_loss: 1.8447 - val_acc: 0.7164\n",
      "Epoch 714/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0936 - acc: 0.9664 - val_loss: 1.7422 - val_acc: 0.7163\n",
      "Epoch 715/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0947 - acc: 0.9654 - val_loss: 1.9711 - val_acc: 0.7170\n",
      "Epoch 716/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0929 - acc: 0.9662 - val_loss: 1.8078 - val_acc: 0.7232\n",
      "Epoch 717/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0939 - acc: 0.9655 - val_loss: 2.0321 - val_acc: 0.7000\n",
      "Epoch 718/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0944 - acc: 0.9652 - val_loss: 1.9204 - val_acc: 0.7099\n",
      "Epoch 719/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0950 - acc: 0.9651 - val_loss: 1.6351 - val_acc: 0.7325\n",
      "Epoch 720/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0941 - acc: 0.9649 - val_loss: 2.2009 - val_acc: 0.6898\n",
      "Epoch 721/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0951 - acc: 0.9651 - val_loss: 1.8058 - val_acc: 0.7258\n",
      "Epoch 722/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0945 - acc: 0.9658 - val_loss: 1.8112 - val_acc: 0.7309\n",
      "Epoch 723/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0944 - acc: 0.9652 - val_loss: 1.7496 - val_acc: 0.7194\n",
      "Epoch 724/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0941 - acc: 0.9657 - val_loss: 1.7230 - val_acc: 0.7250\n",
      "Epoch 725/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0940 - acc: 0.9650 - val_loss: 1.7887 - val_acc: 0.7259\n",
      "Epoch 726/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0930 - acc: 0.9654 - val_loss: 1.9258 - val_acc: 0.7161\n",
      "Epoch 727/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0937 - acc: 0.9657 - val_loss: 1.7155 - val_acc: 0.7340\n",
      "Epoch 728/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0952 - acc: 0.9659 - val_loss: 1.7790 - val_acc: 0.7239\n",
      "Epoch 729/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0931 - acc: 0.9660 - val_loss: 1.7139 - val_acc: 0.7308\n",
      "Epoch 730/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0936 - acc: 0.9665 - val_loss: 1.9491 - val_acc: 0.7180\n",
      "Epoch 731/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0935 - acc: 0.9658 - val_loss: 1.8226 - val_acc: 0.7285\n",
      "Epoch 732/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0927 - acc: 0.9661 - val_loss: 1.7981 - val_acc: 0.7316\n",
      "Epoch 733/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0883 - acc: 0.9678 - val_loss: 1.7922 - val_acc: 0.7311\n",
      "Epoch 734/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0946 - acc: 0.9658 - val_loss: 1.7283 - val_acc: 0.7309\n",
      "Epoch 735/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0939 - acc: 0.9656 - val_loss: 2.0953 - val_acc: 0.7154\n",
      "Epoch 736/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0954 - acc: 0.9655 - val_loss: 1.7072 - val_acc: 0.7132\n",
      "Epoch 737/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0946 - acc: 0.9650 - val_loss: 1.8845 - val_acc: 0.7009\n",
      "Epoch 738/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0935 - acc: 0.9656 - val_loss: 1.6696 - val_acc: 0.7311\n",
      "Epoch 739/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0908 - acc: 0.9673 - val_loss: 1.6794 - val_acc: 0.7264\n",
      "Epoch 740/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0913 - acc: 0.9667 - val_loss: 1.7763 - val_acc: 0.7296\n",
      "Epoch 741/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0942 - acc: 0.9652 - val_loss: 1.6696 - val_acc: 0.7273\n",
      "Epoch 742/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0942 - acc: 0.9659 - val_loss: 1.9371 - val_acc: 0.7208\n",
      "Epoch 743/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0922 - acc: 0.9659 - val_loss: 1.6669 - val_acc: 0.7244\n",
      "Epoch 744/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0918 - acc: 0.9668 - val_loss: 1.8534 - val_acc: 0.7234\n",
      "Epoch 745/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0923 - acc: 0.9666 - val_loss: 1.7863 - val_acc: 0.7281\n",
      "Epoch 746/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0915 - acc: 0.9664 - val_loss: 1.5746 - val_acc: 0.7285\n",
      "Epoch 747/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0908 - acc: 0.9671 - val_loss: 1.9043 - val_acc: 0.7229\n",
      "Epoch 748/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0911 - acc: 0.9668 - val_loss: 1.8391 - val_acc: 0.7205\n",
      "Epoch 749/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0894 - acc: 0.9673 - val_loss: 1.6649 - val_acc: 0.7325\n",
      "Epoch 750/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0920 - acc: 0.9663 - val_loss: 1.7524 - val_acc: 0.7268\n",
      "Epoch 751/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0927 - acc: 0.9665 - val_loss: 1.8095 - val_acc: 0.7199\n",
      "Epoch 752/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0924 - acc: 0.9659 - val_loss: 1.7514 - val_acc: 0.7294\n",
      "Epoch 753/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0901 - acc: 0.9671 - val_loss: 1.8716 - val_acc: 0.7226\n",
      "Epoch 754/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0921 - acc: 0.9665 - val_loss: 1.9085 - val_acc: 0.7182\n",
      "Epoch 755/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0936 - acc: 0.9656 - val_loss: 1.8473 - val_acc: 0.7215\n",
      "Epoch 756/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0910 - acc: 0.9675 - val_loss: 1.6603 - val_acc: 0.7375\n",
      "Epoch 757/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0900 - acc: 0.9677 - val_loss: 2.0123 - val_acc: 0.7081\n",
      "Epoch 758/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0925 - acc: 0.9654 - val_loss: 1.8162 - val_acc: 0.7312\n",
      "Epoch 759/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0910 - acc: 0.9671 - val_loss: 1.8415 - val_acc: 0.7278\n",
      "Epoch 760/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0927 - acc: 0.9659 - val_loss: 1.7667 - val_acc: 0.7265\n",
      "Epoch 761/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0917 - acc: 0.9663 - val_loss: 1.9212 - val_acc: 0.7197\n",
      "Epoch 762/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0912 - acc: 0.9666 - val_loss: 1.8672 - val_acc: 0.7268\n",
      "Epoch 763/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0924 - acc: 0.9663 - val_loss: 1.8249 - val_acc: 0.7248\n",
      "Epoch 764/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0891 - acc: 0.9676 - val_loss: 1.9470 - val_acc: 0.7136\n",
      "Epoch 765/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0906 - acc: 0.9671 - val_loss: 1.7081 - val_acc: 0.7374\n",
      "Epoch 766/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0904 - acc: 0.9668 - val_loss: 1.6975 - val_acc: 0.7289\n",
      "Epoch 767/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0896 - acc: 0.9676 - val_loss: 1.9481 - val_acc: 0.7103\n",
      "Epoch 768/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0894 - acc: 0.9675 - val_loss: 1.8654 - val_acc: 0.7226\n",
      "Epoch 769/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0927 - acc: 0.9662 - val_loss: 2.0169 - val_acc: 0.7120\n",
      "Epoch 770/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0907 - acc: 0.9668 - val_loss: 1.9107 - val_acc: 0.7254\n",
      "Epoch 771/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0919 - acc: 0.9662 - val_loss: 1.8312 - val_acc: 0.7263\n",
      "Epoch 772/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0901 - acc: 0.9675 - val_loss: 1.8948 - val_acc: 0.7192\n",
      "Epoch 773/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0877 - acc: 0.9678 - val_loss: 1.7863 - val_acc: 0.7226\n",
      "Epoch 774/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0909 - acc: 0.9670 - val_loss: 1.9051 - val_acc: 0.7118\n",
      "Epoch 775/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0870 - acc: 0.9689 - val_loss: 1.7691 - val_acc: 0.7301\n",
      "Epoch 776/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0878 - acc: 0.9676 - val_loss: 1.8512 - val_acc: 0.7257\n",
      "Epoch 777/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0875 - acc: 0.9676 - val_loss: 1.7932 - val_acc: 0.7264\n",
      "Epoch 778/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0916 - acc: 0.9666 - val_loss: 1.8488 - val_acc: 0.7262\n",
      "Epoch 779/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0900 - acc: 0.9674 - val_loss: 1.8051 - val_acc: 0.7307\n",
      "Epoch 780/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0883 - acc: 0.9682 - val_loss: 1.8514 - val_acc: 0.7342\n",
      "Epoch 781/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0910 - acc: 0.9671 - val_loss: 1.8294 - val_acc: 0.7335\n",
      "Epoch 782/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0894 - acc: 0.9675 - val_loss: 1.8962 - val_acc: 0.7259\n",
      "Epoch 783/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0914 - acc: 0.9666 - val_loss: 1.7850 - val_acc: 0.7292\n",
      "Epoch 784/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0911 - acc: 0.9668 - val_loss: 1.9447 - val_acc: 0.7189\n",
      "Epoch 785/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0909 - acc: 0.9666 - val_loss: 1.8557 - val_acc: 0.7289\n",
      "Epoch 786/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0913 - acc: 0.9661 - val_loss: 1.7569 - val_acc: 0.7289\n",
      "Epoch 787/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0908 - acc: 0.9670 - val_loss: 1.7843 - val_acc: 0.7318\n",
      "Epoch 788/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0885 - acc: 0.9673 - val_loss: 1.9032 - val_acc: 0.7249\n",
      "Epoch 789/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0906 - acc: 0.9668 - val_loss: 2.0092 - val_acc: 0.7177\n",
      "Epoch 790/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0876 - acc: 0.9679 - val_loss: 1.8418 - val_acc: 0.7313\n",
      "Epoch 791/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0886 - acc: 0.9680 - val_loss: 1.7532 - val_acc: 0.7320\n",
      "Epoch 792/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0876 - acc: 0.9677 - val_loss: 2.3303 - val_acc: 0.7074\n",
      "Epoch 793/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0893 - acc: 0.9671 - val_loss: 1.8781 - val_acc: 0.7213\n",
      "Epoch 794/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0895 - acc: 0.9677 - val_loss: 1.7570 - val_acc: 0.7251\n",
      "Epoch 795/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0874 - acc: 0.9677 - val_loss: 1.9004 - val_acc: 0.7242\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0906 - acc: 0.9667 - val_loss: 1.8535 - val_acc: 0.7215\n",
      "Epoch 797/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0891 - acc: 0.9672 - val_loss: 1.8952 - val_acc: 0.7165\n",
      "Epoch 798/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0889 - acc: 0.9679 - val_loss: 1.7891 - val_acc: 0.7291\n",
      "Epoch 799/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0882 - acc: 0.9679 - val_loss: 1.8701 - val_acc: 0.7366\n",
      "Epoch 800/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0888 - acc: 0.9671 - val_loss: 1.7716 - val_acc: 0.7275\n",
      "Epoch 801/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0887 - acc: 0.9684 - val_loss: 1.8689 - val_acc: 0.7296\n",
      "Epoch 802/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0894 - acc: 0.9678 - val_loss: 1.7287 - val_acc: 0.7330\n",
      "Epoch 803/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0888 - acc: 0.9678 - val_loss: 2.0669 - val_acc: 0.7125\n",
      "Epoch 804/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0890 - acc: 0.9668 - val_loss: 1.8339 - val_acc: 0.7249\n",
      "Epoch 805/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0864 - acc: 0.9681 - val_loss: 1.8998 - val_acc: 0.7351\n",
      "Epoch 806/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0901 - acc: 0.9676 - val_loss: 1.7266 - val_acc: 0.7218\n",
      "Epoch 807/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0872 - acc: 0.9685 - val_loss: 1.9467 - val_acc: 0.7105\n",
      "Epoch 808/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0868 - acc: 0.9683 - val_loss: 1.8330 - val_acc: 0.7192\n",
      "Epoch 809/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0871 - acc: 0.9680 - val_loss: 1.8568 - val_acc: 0.7167\n",
      "Epoch 810/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0882 - acc: 0.9680 - val_loss: 1.8233 - val_acc: 0.7275\n",
      "Epoch 811/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0857 - acc: 0.9686 - val_loss: 1.7869 - val_acc: 0.7347\n",
      "Epoch 812/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0873 - acc: 0.9681 - val_loss: 1.8719 - val_acc: 0.7230\n",
      "Epoch 813/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0888 - acc: 0.9672 - val_loss: 1.7850 - val_acc: 0.7249\n",
      "Epoch 814/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0869 - acc: 0.9685 - val_loss: 1.7452 - val_acc: 0.7234\n",
      "Epoch 815/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0868 - acc: 0.9679 - val_loss: 1.9667 - val_acc: 0.7135\n",
      "Epoch 816/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0862 - acc: 0.9685 - val_loss: 1.9598 - val_acc: 0.7219\n",
      "Epoch 817/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0887 - acc: 0.9679 - val_loss: 1.8374 - val_acc: 0.7288\n",
      "Epoch 818/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0869 - acc: 0.9679 - val_loss: 1.7146 - val_acc: 0.7303\n",
      "Epoch 819/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0872 - acc: 0.9684 - val_loss: 1.9640 - val_acc: 0.7197\n",
      "Epoch 820/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0890 - acc: 0.9680 - val_loss: 1.7958 - val_acc: 0.7305\n",
      "Epoch 821/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0873 - acc: 0.9682 - val_loss: 1.7414 - val_acc: 0.7347\n",
      "Epoch 822/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0876 - acc: 0.9678 - val_loss: 1.8789 - val_acc: 0.7204\n",
      "Epoch 823/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0890 - acc: 0.9679 - val_loss: 1.8624 - val_acc: 0.7269\n",
      "Epoch 824/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0863 - acc: 0.9683 - val_loss: 1.8005 - val_acc: 0.7358\n",
      "Epoch 825/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0868 - acc: 0.9687 - val_loss: 1.9940 - val_acc: 0.7166\n",
      "Epoch 826/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0878 - acc: 0.9680 - val_loss: 1.8140 - val_acc: 0.7273\n",
      "Epoch 827/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0864 - acc: 0.9686 - val_loss: 1.8674 - val_acc: 0.7286\n",
      "Epoch 828/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0871 - acc: 0.9689 - val_loss: 2.0250 - val_acc: 0.7185\n",
      "Epoch 829/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0864 - acc: 0.9686 - val_loss: 1.8575 - val_acc: 0.7286\n",
      "Epoch 830/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0871 - acc: 0.9681 - val_loss: 1.9561 - val_acc: 0.7254\n",
      "Epoch 831/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0872 - acc: 0.9683 - val_loss: 1.9617 - val_acc: 0.7025\n",
      "Epoch 832/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0865 - acc: 0.9688 - val_loss: 1.9186 - val_acc: 0.7251\n",
      "Epoch 833/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0862 - acc: 0.9686 - val_loss: 1.7947 - val_acc: 0.7265\n",
      "Epoch 834/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0865 - acc: 0.9682 - val_loss: 2.0735 - val_acc: 0.7008\n",
      "Epoch 835/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0847 - acc: 0.9698 - val_loss: 2.0273 - val_acc: 0.7088\n",
      "Epoch 836/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0889 - acc: 0.9678 - val_loss: 1.8570 - val_acc: 0.7248\n",
      "Epoch 837/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0863 - acc: 0.9689 - val_loss: 1.9491 - val_acc: 0.7242\n",
      "Epoch 838/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0889 - acc: 0.9676 - val_loss: 1.9229 - val_acc: 0.7219\n",
      "Epoch 839/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0864 - acc: 0.9688 - val_loss: 1.7630 - val_acc: 0.7242\n",
      "Epoch 840/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0846 - acc: 0.9695 - val_loss: 1.6669 - val_acc: 0.7287\n",
      "Epoch 841/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0884 - acc: 0.9685 - val_loss: 2.0303 - val_acc: 0.7114\n",
      "Epoch 842/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0842 - acc: 0.9691 - val_loss: 1.6647 - val_acc: 0.7346\n",
      "Epoch 843/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0863 - acc: 0.9685 - val_loss: 1.7599 - val_acc: 0.7333\n",
      "Epoch 844/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0856 - acc: 0.9687 - val_loss: 1.8558 - val_acc: 0.7249\n",
      "Epoch 845/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0875 - acc: 0.9678 - val_loss: 1.9141 - val_acc: 0.7237\n",
      "Epoch 846/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0862 - acc: 0.9687 - val_loss: 1.8055 - val_acc: 0.7306\n",
      "Epoch 847/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0846 - acc: 0.9695 - val_loss: 1.8368 - val_acc: 0.7323\n",
      "Epoch 848/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0869 - acc: 0.9691 - val_loss: 1.9500 - val_acc: 0.7137\n",
      "Epoch 849/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0860 - acc: 0.9690 - val_loss: 1.8159 - val_acc: 0.7292\n",
      "Epoch 850/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0842 - acc: 0.9694 - val_loss: 1.7909 - val_acc: 0.7275\n",
      "Epoch 851/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0853 - acc: 0.9690 - val_loss: 1.8493 - val_acc: 0.7230\n",
      "Epoch 852/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0852 - acc: 0.9690 - val_loss: 1.9405 - val_acc: 0.7214\n",
      "Epoch 853/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0842 - acc: 0.9694 - val_loss: 1.7941 - val_acc: 0.7352\n",
      "Epoch 854/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0845 - acc: 0.9694 - val_loss: 1.6843 - val_acc: 0.7396\n",
      "Epoch 855/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0840 - acc: 0.9695 - val_loss: 2.0430 - val_acc: 0.7203\n",
      "Epoch 856/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0852 - acc: 0.9691 - val_loss: 1.7901 - val_acc: 0.7346\n",
      "Epoch 857/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0851 - acc: 0.9688 - val_loss: 1.9242 - val_acc: 0.7165\n",
      "Epoch 858/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0856 - acc: 0.9689 - val_loss: 1.7547 - val_acc: 0.7380\n",
      "Epoch 859/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0840 - acc: 0.9690 - val_loss: 1.7239 - val_acc: 0.7368\n",
      "Epoch 860/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0857 - acc: 0.9693 - val_loss: 1.6986 - val_acc: 0.7311\n",
      "Epoch 861/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0838 - acc: 0.9689 - val_loss: 1.8985 - val_acc: 0.7244\n",
      "Epoch 862/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0829 - acc: 0.9696 - val_loss: 2.0289 - val_acc: 0.7196\n",
      "Epoch 863/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0807 - acc: 0.9702 - val_loss: 1.8841 - val_acc: 0.7308\n",
      "Epoch 864/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0832 - acc: 0.9702 - val_loss: 1.9823 - val_acc: 0.7225\n",
      "Epoch 865/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0832 - acc: 0.9697 - val_loss: 1.9128 - val_acc: 0.7273\n",
      "Epoch 866/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0858 - acc: 0.9691 - val_loss: 1.7580 - val_acc: 0.7322\n",
      "Epoch 867/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0846 - acc: 0.9687 - val_loss: 1.9059 - val_acc: 0.7283\n",
      "Epoch 868/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0839 - acc: 0.9697 - val_loss: 1.7656 - val_acc: 0.7289\n",
      "Epoch 869/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0866 - acc: 0.9683 - val_loss: 1.7539 - val_acc: 0.7325\n",
      "Epoch 870/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0824 - acc: 0.9697 - val_loss: 1.8545 - val_acc: 0.7305\n",
      "Epoch 871/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0848 - acc: 0.9690 - val_loss: 1.8296 - val_acc: 0.7227\n",
      "Epoch 872/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0836 - acc: 0.9688 - val_loss: 1.9250 - val_acc: 0.7282\n",
      "Epoch 873/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0848 - acc: 0.9691 - val_loss: 1.7644 - val_acc: 0.7301\n",
      "Epoch 874/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0810 - acc: 0.9703 - val_loss: 1.8617 - val_acc: 0.7272\n",
      "Epoch 875/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0841 - acc: 0.9694 - val_loss: 1.8684 - val_acc: 0.7345\n",
      "Epoch 876/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0832 - acc: 0.9699 - val_loss: 1.9908 - val_acc: 0.7227\n",
      "Epoch 877/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0842 - acc: 0.9691 - val_loss: 1.8122 - val_acc: 0.7237\n",
      "Epoch 878/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0849 - acc: 0.9690 - val_loss: 1.9134 - val_acc: 0.7216\n",
      "Epoch 879/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0834 - acc: 0.9697 - val_loss: 1.9310 - val_acc: 0.7201\n",
      "Epoch 880/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0862 - acc: 0.9687 - val_loss: 1.7985 - val_acc: 0.7325\n",
      "Epoch 881/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0846 - acc: 0.9689 - val_loss: 1.8854 - val_acc: 0.7249\n",
      "Epoch 882/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0853 - acc: 0.9684 - val_loss: 2.0740 - val_acc: 0.7093\n",
      "Epoch 883/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0850 - acc: 0.9685 - val_loss: 1.7660 - val_acc: 0.7288\n",
      "Epoch 884/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0829 - acc: 0.9698 - val_loss: 1.7843 - val_acc: 0.7291\n",
      "Epoch 885/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0815 - acc: 0.9707 - val_loss: 2.0582 - val_acc: 0.7146\n",
      "Epoch 886/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0846 - acc: 0.9690 - val_loss: 1.8547 - val_acc: 0.7215\n",
      "Epoch 887/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0813 - acc: 0.9707 - val_loss: 1.9205 - val_acc: 0.7254\n",
      "Epoch 888/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0834 - acc: 0.9696 - val_loss: 1.9265 - val_acc: 0.7160\n",
      "Epoch 889/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0845 - acc: 0.9693 - val_loss: 1.8257 - val_acc: 0.7177\n",
      "Epoch 890/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0831 - acc: 0.9702 - val_loss: 2.0834 - val_acc: 0.7180\n",
      "Epoch 891/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0841 - acc: 0.9694 - val_loss: 1.8400 - val_acc: 0.7242\n",
      "Epoch 892/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0840 - acc: 0.9696 - val_loss: 1.9077 - val_acc: 0.7200\n",
      "Epoch 893/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0814 - acc: 0.9699 - val_loss: 1.7562 - val_acc: 0.7254\n",
      "Epoch 894/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0819 - acc: 0.9704 - val_loss: 1.8410 - val_acc: 0.7257\n",
      "Epoch 895/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0829 - acc: 0.9697 - val_loss: 1.8332 - val_acc: 0.7316\n",
      "Epoch 896/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0818 - acc: 0.9706 - val_loss: 1.9620 - val_acc: 0.7275\n",
      "Epoch 897/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0818 - acc: 0.9703 - val_loss: 2.0740 - val_acc: 0.7235\n",
      "Epoch 898/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0825 - acc: 0.9696 - val_loss: 1.8286 - val_acc: 0.7287\n",
      "Epoch 899/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0817 - acc: 0.9699 - val_loss: 1.8542 - val_acc: 0.7309\n",
      "Epoch 900/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0813 - acc: 0.9704 - val_loss: 1.6585 - val_acc: 0.7289\n",
      "Epoch 901/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0793 - acc: 0.9708 - val_loss: 1.8097 - val_acc: 0.7310\n",
      "Epoch 902/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0810 - acc: 0.9707 - val_loss: 1.9284 - val_acc: 0.7346\n",
      "Epoch 903/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0840 - acc: 0.9695 - val_loss: 1.8449 - val_acc: 0.7315\n",
      "Epoch 904/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0817 - acc: 0.9696 - val_loss: 1.8197 - val_acc: 0.7309\n",
      "Epoch 905/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0852 - acc: 0.9690 - val_loss: 1.8642 - val_acc: 0.7363\n",
      "Epoch 906/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0820 - acc: 0.9699 - val_loss: 1.8122 - val_acc: 0.7298\n",
      "Epoch 907/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0820 - acc: 0.9703 - val_loss: 1.6854 - val_acc: 0.7378\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0832 - acc: 0.9705 - val_loss: 2.0873 - val_acc: 0.7085\n",
      "Epoch 909/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0833 - acc: 0.9698 - val_loss: 1.9846 - val_acc: 0.7205\n",
      "Epoch 910/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0826 - acc: 0.9702 - val_loss: 2.3286 - val_acc: 0.7033\n",
      "Epoch 911/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0836 - acc: 0.9695 - val_loss: 1.7614 - val_acc: 0.7392\n",
      "Epoch 912/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0800 - acc: 0.9704 - val_loss: 1.8676 - val_acc: 0.7297\n",
      "Epoch 913/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0838 - acc: 0.9698 - val_loss: 1.8497 - val_acc: 0.7276\n",
      "Epoch 914/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0804 - acc: 0.9704 - val_loss: 1.9150 - val_acc: 0.7322\n",
      "Epoch 915/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0834 - acc: 0.9698 - val_loss: 2.0267 - val_acc: 0.7207\n",
      "Epoch 916/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0809 - acc: 0.9706 - val_loss: 1.8395 - val_acc: 0.7208\n",
      "Epoch 917/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0819 - acc: 0.9707 - val_loss: 1.8594 - val_acc: 0.7266\n",
      "Epoch 918/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0835 - acc: 0.9694 - val_loss: 1.8478 - val_acc: 0.7306\n",
      "Epoch 919/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0819 - acc: 0.9699 - val_loss: 1.6462 - val_acc: 0.7450\n",
      "Epoch 920/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0815 - acc: 0.9701 - val_loss: 1.8766 - val_acc: 0.7158\n",
      "Epoch 921/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0833 - acc: 0.9697 - val_loss: 1.8868 - val_acc: 0.7252\n",
      "Epoch 922/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0785 - acc: 0.9713 - val_loss: 1.8057 - val_acc: 0.7320\n",
      "Epoch 923/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0837 - acc: 0.9694 - val_loss: 1.8233 - val_acc: 0.7363\n",
      "Epoch 924/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0801 - acc: 0.9711 - val_loss: 1.8859 - val_acc: 0.7245\n",
      "Epoch 925/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0854 - acc: 0.9692 - val_loss: 1.9505 - val_acc: 0.7263\n",
      "Epoch 926/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0817 - acc: 0.9706 - val_loss: 1.9399 - val_acc: 0.7201\n",
      "Epoch 927/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0816 - acc: 0.9704 - val_loss: 1.8067 - val_acc: 0.7302\n",
      "Epoch 928/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0831 - acc: 0.9692 - val_loss: 1.8934 - val_acc: 0.7300\n",
      "Epoch 929/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0813 - acc: 0.9696 - val_loss: 1.7219 - val_acc: 0.7356\n",
      "Epoch 930/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0803 - acc: 0.9713 - val_loss: 1.7036 - val_acc: 0.7287\n",
      "Epoch 931/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0804 - acc: 0.9702 - val_loss: 1.8702 - val_acc: 0.7238\n",
      "Epoch 932/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0803 - acc: 0.9710 - val_loss: 1.7199 - val_acc: 0.7395\n",
      "Epoch 933/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0799 - acc: 0.9711 - val_loss: 1.8551 - val_acc: 0.7244\n",
      "Epoch 934/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0780 - acc: 0.9714 - val_loss: 2.0646 - val_acc: 0.7269\n",
      "Epoch 935/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0813 - acc: 0.9705 - val_loss: 2.0862 - val_acc: 0.7111\n",
      "Epoch 936/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0805 - acc: 0.9708 - val_loss: 1.9312 - val_acc: 0.7306\n",
      "Epoch 937/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0772 - acc: 0.9721 - val_loss: 1.7929 - val_acc: 0.7285\n",
      "Epoch 938/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0799 - acc: 0.9710 - val_loss: 1.8733 - val_acc: 0.7352\n",
      "Epoch 939/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0798 - acc: 0.9707 - val_loss: 1.8823 - val_acc: 0.7306\n",
      "Epoch 940/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0812 - acc: 0.9703 - val_loss: 1.8221 - val_acc: 0.7287\n",
      "Epoch 941/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0802 - acc: 0.9708 - val_loss: 1.7688 - val_acc: 0.7295\n",
      "Epoch 942/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0802 - acc: 0.9709 - val_loss: 1.8097 - val_acc: 0.7307\n",
      "Epoch 943/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0817 - acc: 0.9709 - val_loss: 1.8693 - val_acc: 0.7342\n",
      "Epoch 944/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0817 - acc: 0.9701 - val_loss: 1.9317 - val_acc: 0.7255\n",
      "Epoch 945/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0805 - acc: 0.9704 - val_loss: 1.9111 - val_acc: 0.7318\n",
      "Epoch 946/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0828 - acc: 0.9703 - val_loss: 1.9556 - val_acc: 0.7192\n",
      "Epoch 947/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0789 - acc: 0.9712 - val_loss: 1.9735 - val_acc: 0.7296\n",
      "Epoch 948/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0791 - acc: 0.9715 - val_loss: 1.9759 - val_acc: 0.7213\n",
      "Epoch 949/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0786 - acc: 0.9714 - val_loss: 1.9011 - val_acc: 0.7207\n",
      "Epoch 950/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0814 - acc: 0.9704 - val_loss: 1.8152 - val_acc: 0.7276\n",
      "Epoch 951/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0806 - acc: 0.9708 - val_loss: 1.7757 - val_acc: 0.7307\n",
      "Epoch 952/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0786 - acc: 0.9716 - val_loss: 1.8892 - val_acc: 0.7337\n",
      "Epoch 953/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0797 - acc: 0.9709 - val_loss: 1.9076 - val_acc: 0.7237\n",
      "Epoch 954/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0797 - acc: 0.9710 - val_loss: 2.0622 - val_acc: 0.7170\n",
      "Epoch 955/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0807 - acc: 0.9704 - val_loss: 1.7186 - val_acc: 0.7336\n",
      "Epoch 956/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0806 - acc: 0.9707 - val_loss: 1.8417 - val_acc: 0.7399\n",
      "Epoch 957/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0810 - acc: 0.9709 - val_loss: 1.8516 - val_acc: 0.7222\n",
      "Epoch 958/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0796 - acc: 0.9708 - val_loss: 1.9062 - val_acc: 0.7331\n",
      "Epoch 959/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0798 - acc: 0.9713 - val_loss: 2.0487 - val_acc: 0.7184\n",
      "Epoch 960/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0818 - acc: 0.9704 - val_loss: 1.9497 - val_acc: 0.7222\n",
      "Epoch 961/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0780 - acc: 0.9717 - val_loss: 1.7388 - val_acc: 0.7290\n",
      "Epoch 962/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0801 - acc: 0.9703 - val_loss: 2.0128 - val_acc: 0.7267\n",
      "Epoch 963/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0776 - acc: 0.9721 - val_loss: 1.8298 - val_acc: 0.7347\n",
      "Epoch 964/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0800 - acc: 0.9712 - val_loss: 1.9628 - val_acc: 0.7176\n",
      "Epoch 965/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0817 - acc: 0.9701 - val_loss: 1.8873 - val_acc: 0.7376\n",
      "Epoch 966/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0771 - acc: 0.9721 - val_loss: 2.0310 - val_acc: 0.7232\n",
      "Epoch 967/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0792 - acc: 0.9713 - val_loss: 1.8264 - val_acc: 0.7366\n",
      "Epoch 968/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0799 - acc: 0.9704 - val_loss: 1.8565 - val_acc: 0.7296\n",
      "Epoch 969/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0805 - acc: 0.9707 - val_loss: 1.9308 - val_acc: 0.7312\n",
      "Epoch 970/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0779 - acc: 0.9718 - val_loss: 1.7193 - val_acc: 0.7332\n",
      "Epoch 971/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0786 - acc: 0.9711 - val_loss: 2.0670 - val_acc: 0.7111\n",
      "Epoch 972/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0786 - acc: 0.9715 - val_loss: 1.8148 - val_acc: 0.7284\n",
      "Epoch 973/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0766 - acc: 0.9719 - val_loss: 1.8874 - val_acc: 0.7247\n",
      "Epoch 974/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0781 - acc: 0.9718 - val_loss: 1.8059 - val_acc: 0.7340\n",
      "Epoch 975/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0807 - acc: 0.9708 - val_loss: 2.0002 - val_acc: 0.7207\n",
      "Epoch 976/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0778 - acc: 0.9718 - val_loss: 1.8448 - val_acc: 0.7345\n",
      "Epoch 977/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0794 - acc: 0.9714 - val_loss: 1.7485 - val_acc: 0.7360\n",
      "Epoch 978/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0772 - acc: 0.9723 - val_loss: 1.7986 - val_acc: 0.7394\n",
      "Epoch 979/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0787 - acc: 0.9714 - val_loss: 1.9895 - val_acc: 0.7265\n",
      "Epoch 980/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0781 - acc: 0.9717 - val_loss: 1.9848 - val_acc: 0.7212\n",
      "Epoch 981/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0777 - acc: 0.9715 - val_loss: 1.8414 - val_acc: 0.7327\n",
      "Epoch 982/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0774 - acc: 0.9716 - val_loss: 1.8930 - val_acc: 0.7417\n",
      "Epoch 983/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0807 - acc: 0.9703 - val_loss: 1.9617 - val_acc: 0.7249\n",
      "Epoch 984/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0778 - acc: 0.9717 - val_loss: 1.8987 - val_acc: 0.7264\n",
      "Epoch 985/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0781 - acc: 0.9717 - val_loss: 1.9814 - val_acc: 0.7220\n",
      "Epoch 986/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0777 - acc: 0.9715 - val_loss: 1.9134 - val_acc: 0.7264\n",
      "Epoch 987/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0798 - acc: 0.9711 - val_loss: 1.9832 - val_acc: 0.7147\n",
      "Epoch 988/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0796 - acc: 0.9712 - val_loss: 1.8725 - val_acc: 0.7265\n",
      "Epoch 989/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0805 - acc: 0.9710 - val_loss: 1.7292 - val_acc: 0.7298\n",
      "Epoch 990/1000\n",
      "113600/113600 [==============================] - 3s 27us/sample - loss: 0.0798 - acc: 0.9712 - val_loss: 1.8910 - val_acc: 0.7365\n",
      "Epoch 991/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0759 - acc: 0.9726 - val_loss: 1.7651 - val_acc: 0.7359\n",
      "Epoch 992/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0776 - acc: 0.9715 - val_loss: 1.7548 - val_acc: 0.7375\n",
      "Epoch 993/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0774 - acc: 0.9716 - val_loss: 1.9773 - val_acc: 0.7283\n",
      "Epoch 994/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0766 - acc: 0.9722 - val_loss: 1.7734 - val_acc: 0.7315\n",
      "Epoch 995/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0803 - acc: 0.9714 - val_loss: 1.8782 - val_acc: 0.7292\n",
      "Epoch 996/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0772 - acc: 0.9722 - val_loss: 1.7637 - val_acc: 0.7304\n",
      "Epoch 997/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0769 - acc: 0.9719 - val_loss: 1.6987 - val_acc: 0.7348\n",
      "Epoch 998/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0777 - acc: 0.9714 - val_loss: 1.8892 - val_acc: 0.7277\n",
      "Epoch 999/1000\n",
      "113600/113600 [==============================] - 3s 26us/sample - loss: 0.0753 - acc: 0.9731 - val_loss: 1.9414 - val_acc: 0.7266\n",
      "Epoch 1000/1000\n",
      "113600/113600 [==============================] - 3s 25us/sample - loss: 0.0767 - acc: 0.9725 - val_loss: 1.8856 - val_acc: 0.7355\n",
      "14200/14200 [==============================] - 1s 37us/sample - loss: 1.8856 - acc: 0.7355\n"
     ]
    }
   ],
   "source": [
    "run_custom_training(conf_list, x_train, y_train, x_valid, y_valid,1000, 512,model_path_prefix='5_lbls_relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2500],\n",
       "       [   1, 3300],\n",
       "       [   2, 3300],\n",
       "       [   3, 3000],\n",
       "       [   4, 2100]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e04365074842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/5_lbls_relu_[32, 300, 100, 0.2]_2019518_2_11.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "trained_model = tf.keras.models.load_model('../models/5_lbls_relu_[32, 300, 100, 0.2]_2019518_2_11.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = trained_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  73.83098591549296\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "total = 0\n",
    "for i, lbl in enumerate(y_test):\n",
    "#     if lbl != 1:\n",
    "        total += 1\n",
    "        if np.argmax(test_predicted[i]) == lbl:\n",
    "            acc += 1\n",
    "#     else:\n",
    "#         print(lbl)\n",
    "print('acc: ', (acc/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1916,   52,  280,  118,  134],\n",
       "       [ 181, 2409,  244,  261,  205],\n",
       "       [ 457,   98, 2344,  362,   39],\n",
       "       [ 263,   82,  375, 2211,   69],\n",
       "       [ 247,  110,   75,   64, 1604]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, np.argmax(test_predicted,axis=1))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1453894e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(confusion, labels, labels)\n",
    "plt.figure(figsize = (12, 9))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, fmt='.5g', annot_kws={\"size\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeev</th>\n",
       "      <th>or</th>\n",
       "      <th>ron</th>\n",
       "      <th>aviya</th>\n",
       "      <th>felix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zeev</th>\n",
       "      <td>1916</td>\n",
       "      <td>52</td>\n",
       "      <td>280</td>\n",
       "      <td>118</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>181</td>\n",
       "      <td>2409</td>\n",
       "      <td>244</td>\n",
       "      <td>261</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ron</th>\n",
       "      <td>457</td>\n",
       "      <td>98</td>\n",
       "      <td>2344</td>\n",
       "      <td>362</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aviya</th>\n",
       "      <td>263</td>\n",
       "      <td>82</td>\n",
       "      <td>375</td>\n",
       "      <td>2211</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felix</th>\n",
       "      <td>247</td>\n",
       "      <td>110</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       zeev    or   ron  aviya  felix\n",
       "zeev   1916    52   280    118    134\n",
       "or      181  2409   244    261    205\n",
       "ron     457    98  2344    362     39\n",
       "aviya   263    82   375   2211     69\n",
       "felix   247   110    75     64   1604"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 51.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# plot decision per label\n",
    "plot_dict = {}\n",
    "for label in tqdm(range(0, len(np.unique(y_test)))):\n",
    "    label_data = []\n",
    "    random.shuffle(y_test)\n",
    "    for i in y_test[:1000]:\n",
    "        if i == label:\n",
    "            label_data.append(test_predicted[i]*100)\n",
    "    plot_dict[label] = label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:00<00:00, 304.49it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [00:00<00:00, 297.17it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAFWCAYAAADKT050AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlYVPX+B/D3sAzMuC+j3jRFUMRcIOEy3cql3AgUzMTHcKkHCsHUzCe3zLiapahJoqSZWKlZbriUC5WYW8VtUVGTdRQlEkfyZ7KMA8z5/eH1XCcUZ1C+M4zv1/P0PPA93znn8/Hk28OXM2cUkiRJICIiIZxsXQAR0YOEoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0qd4oKChAly5dkJ2dbfFrfv75ZwwYMAA9evTA559/fs81pKeno0uXLigtLbVofpcuXXDgwIFaH6+2r//www8xefLkWh+X6g5DlxxaUlISPDw8sHfvXgwdOtTW5QixY8cOvP/++7Yug+7AxdYFENWlv/76C3379kW7du1sXUqdMxgMmDt3Lvbs2YMOHTrYuhy6A17pUq39/vvviIqKgp+fHwYNGoRNmzahS5cuAP63FPDBBx8gMDAQL7/8MgBg165dGDp0KLp3745evXohNjYWly9fBnDjR/eAgACkpKTgySefREBAAGbPno3y8nKz4x45cgQhISHo0aMHwsPDkZOTc9v6nn76aZw6dQpJSUlyXSUlJZg/fz769OkDX19fREVFQafTya/p0qUL3n//fTz++OMIDQ1FVVVVjX8GGRkZeOGFF/Doo4/K9Rw/frzanKFDh6JHjx4YO3Ys8vLy5G0lJSWYM2cOAgMDodVqMXnyZBQVFd32WMuXL5f7uJ3i4mIUFBRg69at8PPzq7Fush2GLtVKZWUlxo8fDycnJ2zevBkzZ87EsmXLqs07dOgQNm/ejOnTp+PXX3/FG2+8gaioKKSmpiIpKQlnzpzBqlWr5PllZWVITk5GYmIiVq5ciR9//BFz58412+emTZvw73//GykpKVAoFJgzZ85ta9y6dSt8fHwQGRmJI0eOAABeffVVpKenY+nSpdi8eTPc3NwQFRVlFuy7d+/GunXrEB8fD2dn5zv+GZSUlODll19G165dsXPnTmzevBlqtRpvvfWW2bz169fjlVdeQUpKCho0aICJEyfCZDIBAN566y2cO3cOycnJWL9+PRQKBV566SVUVlZWO96tfdxO27ZtsX79enTu3PmOc8gOSES1cPjwYalbt25ScXGxPLZx40bJ29tbkiRJunDhguTt7S3t3r1b3n7q1CkpJSXFbD/z5s2Txo0bJ0mSJP3444+St7e39NNPP8nbv/nmG6lbt27StWvX5H2mpqbK23fs2CH17NnzjnU+++yzUmJioiRJkpSVlSV5e3tLGRkZ8vbS0lIpMDBQ2rRpkyRJkuTt7S19+OGHd9zfzRpLSkokvV4vrV69WqqoqJC379u3T/Lx8ZG/9/b2llatWiV/X1xcLHXr1k06evSodP78ecnb21u6ePGivP369euSn5+fdODAAfn1aWlpd6znTmbMmCFNmjTJ6tdR3eOaLtVKVlYW2rZti+bNm8tjjz76aLV5t66lduvWDQ0aNEBSUhLy8vKQl5eHnJwc+Pv7y3OcnZ3NfjTu0aMHKioqoNPp5GO1b99e3t64cWMYDAaLas7NzYWrqyu6d+8uj6nVajzyyCNmSxQPP/ywRftr2bIlRo4ciY0bNyIzMxPnzp3Db7/9Jl/F3uTr6yt/3bx5c7Rt2xbZ2dm4fv06ACAoKMhsfnl5OXQ6Hfr162dRHVS/MHSpVlxcXCBZ8IA6d3d3+evvv/8e48ePR3BwMAICAjBu3Dh89dVXyMrKkuc4OTnByel/q143A+zWH/Nv3W4NNze3246bTCazoLy15poUFRUhPDwcHTt2RJ8+fRAcHIwrV67g9ddfN5v39yUKk8kEV1dXVFVVwdXVFTt27Ki27yZNmlhUA9U/XNOlWvH29kZhYSH+/PNPeezkyZM1vmbdunV45plnEB8fj4iICPj5+SE/P98svCsqKszuwz1x4gTc3NzQsWPHe67Zy8sLFRUVZnWWlZUhMzMTnp6eVu9v9+7dcHFxwSeffIKoqCg8+eSTuHjxIgCY9ZSZmSl/XVRUhMLCQnTq1Amenp6oqKhAWVkZOnTogA4dOqBly5ZYsGABzp07V/tGya4xdKlWHnvsMXh6emLWrFnIzs7G4cOHb/uLtFu1atUKGRkZOH36NM6ePYuEhAQcOnQIRqPRbN6cOXNw+vRp/Pjjj1i0aBHCw8OhVqvvuWYPDw8MGjQIs2fPxs8//4ysrCzMmDEDLi4uCAkJsXp/rVu3xuXLl/Hdd9+hoKAAKSkpWLlyJQCY9bRixQrs378fmZmZmD59Orp16watVgtPT088/fTTmD59On7++Wfk5eVh2rRpOHXqFLy8vKodr7S0FHq9vvZ/AGQXGLpUKwqFAklJSTAYDHjuuecwf/58hIeHw9XV9Y6vmTx5Mtq3b48xY8bg+eefR3Z2NmbMmIHc3Fx5fRMAQkJCEBUVhVdffRWDBw/GzJkz71vd7777Lnr06IHY2FiMGjUK169fx4YNG9C0aVOr9/XMM89g5MiRmDlzJkJDQ7Fp0ybMnz8fCoUCp06dkufFxsZi0aJFGDlyJNzd3bF8+XJ5W3x8PLp3745XXnkFI0aMgMFgwCeffIJGjRpVO97atWvx5JNP1q5xshsKyZKFOaK/KS4uxqlTp9C3b195bO/evViyZAn2799fq32mp6dj3Lhx+PXXX9GgQYP7VSqRXeGVLtWKQqHAxIkT8fHHH6OgoAC//PILVqxYgeDgYFuXRmTXePcC1Urz5s2xbNkyLFu2DAkJCWjSpAnCwsL4kBWiu+DyAhGRQFxeICISiKFLRCQQQ5eISKAH5hdpV66UwmSyfPm6RYuGKC4uqcOKxGAf9sVR+gAcp5fa9uHkpECzZtbf2vjAhK7JJFkVujdf4wjYh31xlD4Ax+lFZB9cXiAiEoihS0QkEEOXiEgghi4RkUAMXSIigWwSuhkZGQgMDJS/NxqNiIuLg1arhVarxYIFC8w+hXXfvn0YNGgQ/Pz8MGbMGD7gmYjqLeGhu2fPHkRGRqKiokIeW758OXJzc5GamoqdO3ciPT0dycnJAICcnBzMmjUL7777Lv7zn//A398fr7zySrXPoSIiqg+Ehm5CQgLWrFmDCRMmmI1v374d0dHRaNq0Kdq0aYOYmBhs27YNALBr1y706dMHAQEBUCqVmDx5MoqKinD8+HGRpRMR3RdC3xwRERGB1157Denp6fLYX3/9Bb1eb/bxJJ6ensjPz4fRaEReXh66du0qb3N2dkb79u2Rm5uLXr161Umdc+LX4i+JHwxI9CBprLiKt2dE1vlxhIZu69atq42VlZUBAFQqlTymUqkgSRIMBgPKysqqfTqrSqWSX2epFi0a1qJiInqQaDTVPybpfrP524Bvhq3BYJDHysvLAQBqtRoqlcrs87Nubrf241yKi0ssfqvf2zMiodE0gl5/zapj2CP2YV8cpQ/AcXq5tQ9r+nFyUtTqYs7mt4w1adIEGo0GOp1OHtPpdPDw8ICLiws6depktq2qqgrnz5+/7aelEhHZO5uHLgCEhoYiKSkJxcXFKCoqwqpVqzBs2DAAwJAhQ3DgwAEcPXoURqMRiYmJaNmyJXx9fW1cNRGR9Wy+vAAAr776KuLj4xEaGorKykqEhYUhOjoaANClSxfEx8dj/vz5uHjxIrp164aVK1fC2dnZxlUTEVnvgfmMNGvWdAHHXK+qz9iH/XGUXmrbR71d0yUiepAwdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXSIigRi6REQCMXSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUB2E7oZGRkYOXIk/P398fTTT2P9+vUAAKPRiLi4OGi1Wmi1WixYsABVVVU2rpaIqHZcbF0AAJhMJsTGxmLatGkYNmwYzpw5g4iICHTt2hUHDx5Ebm4uUlNTYTAYEBMTg+TkZERHR9u6bCIiq9nFle7Vq1dx+fJlmEwmmEwmKBQKODk5wdXVFdu3b0d0dDSaNm2KNm3aICYmBtu2bbN1yUREtWIXodusWTOMHj0ab7zxBrp3746wsDBERkaiY8eO0Ov18PLykud6enoiPz8fRqPRhhUTEdWO3SwvqFQqLF68GIMHD8axY8cwceJEtG3bFgCgUqnkuSqVCpIkwWAwQKlUWnyMFi0aWl2XRtPI6tfYI/ZhXxylD8BxehHZh12E7jfffIP09HRMmzYNAKDVajF8+HBs374dAGAwGOS55eXlAAC1Wm3VMYqLS2AySRbP12gaQa+/ZtUx7BH7sC+O0gfgOL3Utg8nJ0WtLubsYnmhsLCw2nKBi4sLmjdvDo1GA51OJ4/rdDp4eHjAxcUu/r0gIrKKXYTuE088AZ1Oh88//xySJOHkyZPYunUrQkJCEBoaiqSkJBQXF6OoqAirVq3CsGHDbF0yEVGt2MXlore3N5KSkrBs2TIsWbIELVu2xOuvv44BAwagd+/eiI+PR2hoKCorKxEWFsbbxYio3lJIkmT5Qmc9xjXd+o192B9H6eWBXNMlInpQMHSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXSIigRi6REQCMXSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIItDd+bMmfjhhx8gSVJd1kNE5NBcLJ0oSRImTZoElUqFkJAQhIWFoWvXrnVZGxGRw7H4Sjc+Ph7ff/89Zs+ejcLCQowaNQohISH48MMPUVBQcM+FXLp0CRMmTIC/vz+eeOIJLFu2DABgNBoRFxcHrVYLrVaLBQsWoKqq6p6PR0RkCxZf6QKAUqlEUFAQgoKCUFpaio8//hgffPAB3n//ffTq1QvPP/88hgwZUqtCJkyYgO7du+OHH35AUVERxo4dCy8vL2RlZSE3NxepqakwGAyIiYlBcnIyoqOja3UcIiJbsip0AeDMmTPYs2cP9u7di0uXLqFfv34YOnQoLl26hEWLFuHIkSNYuHChVfs8ceIE8vPzsXHjRiiVSjz88MNYv3493NzcsHDhQrzzzjto2rQpACAmJgYJCQkMXSKqlywO3cTEROzZswfnz5+Hv78/xo8fj6CgIDRq1Eie07hxY7z11ltWh+6pU6fg7e2NxMRE7NixA25ubhg9ejRGjBgBvV4PLy8vea6npyfy8/NhNBqhVCqtOg4Rka1ZHLqpqal49tlnMXToUDz00EO3nePj44N58+ZZXcTVq1dx7NgxaLVapKWlQafTISoqCs2bNwcAqFQqea5KpYIkSTAYDFaFbosWDa2uS6NpdPdJ9QD7sC+O0gfgOL2I7MPi0H3mmWcwbtw4swAEgJKSEixfvhyzZs1C586d0blzZ6uLUCqVUKlUmDRpEhQKBXx8fDB8+HBs374dAGAwGOS55eXlAAC1Wm3VMYqLS2AyWX67m0bTCHr9NauOYY/Yh31xlD4Ax+mltn04OSlqdTFXY+gWFRXh2rUbxSQlJeGxxx6T11ZvOnPmDL744gvMmjXL6oPf5OnpCZPJhMrKSri6ugIAKisr0aRJE2g0Guh0OrRt2xYAoNPp4OHhARcXq5ejiYhsrsbkOnnyJCZOnAiFQgEAGDNmzG3nhYeH31MRTzzxBBo3boyEhARMmTIFOp0OKSkpmDdvHtq1a4ekpCQ88sgjqKysxKpVqzBs2LB7Oh4Rka3UGLoDBgxAWloaTCYTBgwYgC1btsjrrACgUCigVqurXf1ay83NDRs2bMDbb7+N3r17Q6lUIjo6GoMHD0a/fv0QHx+P0NBQVFZWIiwsjHcuEFG9pZAekPf1ck23fmMf9sdRerGrNd0RI0YgOTkZTZo0wYgRI2rc0datW60+OBHRg6bG0O3Xr598W1bfvn3ltV0iIqqdGkN34sSJ8teTJk2q82KIiBxdjaG7aNEii3c0ffr0ey6GiMjR3fWWMSIiun9qDN3169eLqoOI6IFQY+h+9tlnGDFiBNzc3PDZZ5/dcZ5CoUBERMR9L46IyNHUGLrJyckIDg6Gm5sbkpOT7ziPoUtEZJkaQzctLe22XxMRUe1Y/dSYH374ATk5OXB1dUXnzp0REBBQF3URETkki0NXp9Nh4sSJuHDhAh566CFIkoTCwkJ0794diYmJaNWqVV3WSUTkECz+YMp///vfaN++PQ4dOoTU1FR8/fXX2L9/P9zd3REXF1eXNRIROQyLr3SPHz+O7du3o1mzZvJY69atMXPmTIwaNapOiiMicjQWX+l26NABOp2u2nhhYSHatGlzX4siInJUNV7pHjx4UP564MCBmD17Ns6dOwdfX184OTkhKysLK1asQExMTJ0XSkTkCGp8nq6Pj49lO1EocObMmftWVF3g83TrN/ZhfxylF7t6nm5mZqbVOyQiojuzeE33ToxGI44dO3Y/aiEicngW371w4sQJxMXFIScnByaTyWybQqHAb7/9dt+LIyJyNBZf6b7zzjto2rQpli5dCnd3dyxevBhTp06FWq3Ge++9V5c1EhE5DIuvdDMzM7F582b4+Phg3bp1aN68OYYMGYIWLVrg008/xTPPPFOXdRIROQSLr3SdnZ3RsOGN39R5eHggKysLAKDVapGbm1s31RERORiLQ9fX1xcbN26EyWSCj48PDh06BADyw2+IiOjuLF5emDp1KqKjo9GiRQuEh4djzZo16N+/P4qLixEeHl6XNRIROQyLQ7dnz57Yv38/DAYDGjdujC1btmD37t1o3bo113OJiCxk1fN0GzRogD///BPHjx+Hq6srBg0ahLZt29ZVbUREDsfi0NXr9Zg5cyaOHj0KpVIJk8mEqqoqBAcHY+7cufIv2YiI6M6sep5uSUkJdu3ahYyMDJw8eRKbNm1Cbm4u3n777bqskYjIYVgcukePHsXcuXPh7e0N4Ma70Hr27Im3334b33zzTZ0VSETkSCwO3ZYtW+LKlSvVxm/+Yo2IiO6uxjXdW9/0MGrUKLzxxhuYNm0afH194ezsjMzMTLzzzjuYMGFCnRdKROQI7vo8XYVCgRqm3NgJn6drt9iHfXGUPgDH6cWunqe7f/9+q3dIRER3VmPo3u4e3PPnz8uPd/Ty8oKnp2edFUdE5Ggsvk+3tLQUs2fPxr59++Dq6gpJklBVVYXHH38cy5cvh1qtrss6iYgcgsV3LyxcuBDZ2dnYvHmzfJ/uF198gaKiIixZsqQuayQichgWh+7XX3+NefPmoWfPnlAoFFAoFPD19UVcXBz27dtXlzUSETkMi0NXkiQ0a9as2njTpk1RVlZ2X4siInJUFofuP//5T6xYsQJGo1EeMxqNSEpKgr+/f50UR0TkaCz+Rdr06dMxevRo9OvXD127dgUAnDlzBm5ublizZs19K6isrAzDhw9HeHg4oqKicO3aNbz55ps4evQo3Nzc8MILLyA6Ovq+HY+ISCSLQ7d9+/bYs2cPdu3ahby8PLi5uSEoKAhDhw6Fu7v7fSto/vz5yM/Pl7+Pi4sDABw+fBiFhYV46aWX0K5dOwQHB9+3YxIRiWJx6D777LNYuHAhxowZU2fF7N27F+fOnUOvXr0A3LjqTU1Nxc6dO6FSqeDl5YUxY8Zg69atDF0iqpcsXtPV6/VQKpV1VkhhYSEWL16MRYsWwcnpRln5+fkwmUzo2LGjPM/T0xM5OTl1VgcRUV2y+Ep35MiRiI2NxciRI9GuXbtqSwp9+/atdRFVVVWYNm0aXn31VbRr104eLy0thVKphLOzszzm7u6O8vJyq49Rm/dIazSNrH6NPWIf9sVR+gAcpxeRfVgcuitXrgQALF68uNq2e33gzcqVK9G6dWuEhYWZjavValRUVMBkMslXvwaDoVbvfuMDb+o39mF/HKUXu3rgza0yMzOt3rmlvvrqK1y6dAkBAQEAbqzlnjhxArm5uVAoFDh37pz8jAedTodOnTrVWS1ERHXJqg+mrKqqwvfff4+cnBw4OTmha9euCAwMhEKhuKci/v6OtrFjx6Jfv36IiopCWVkZ3nvvPcTHx6OoqAgbNmzAa6+9dk/HIyKyFYtD98KFC3jppZdQWFiIhx56CCaTCX/88Qe8vb2xevVqtGzZsk4KnDdvHubNm4f+/fvD1dUVY8eORWhoaJ0ci4iortX4EPNbRUZGwsnJCfHx8WjRogUA4NKlS5g5cyYaNmyIxMTEOi30XnFNt35jH/bHUXqx2zXdY8eOYcuWLXLgAkCrVq0wY8YMPP/881YfmIjoQWTxfbrt2rUz+8y0my5evIhWrVrd16KIiByVxVe648aNw9y5c3Hu3Dn4+/vD2dkZp0+fxqpVqzBy5EgcPHhQnnsv9+wSETkyi9d0fXx8LNuhnX5IJdd06zf2YX8cpRe7XdOty/t0iYgeFBav6RIR0b1j6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXSIigRi6REQCMXSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhLIbkI3IyMDERERCAgIQL9+/bB8+XJIkgSj0Yi4uDhotVpotVosWLAAVVVVti6XiKhWXGxdAACUlpZi/PjxeOWVV7B+/XpcuHABUVFRaN68OS5evIjc3FykpqbCYDAgJiYGycnJiI6OtnXZRERWs4sr3T/++AO9evXCmDFj4OzsDA8PDwwcOBC//vortm/fjujoaDRt2hRt2rRBTEwMtm3bZuuSiYhqxS5Ct1OnTkhKSpK/NxqNOHToEHx8fKDX6+Hl5SVv8/T0RH5+PoxGoy1KJSK6J3axvHAro9GIqVOnQqlUIjg4GEuWLIFKpZK3q1QqSJIEg8EApVJp8X5btGhodS0aTSOrX2OP2Id9cZQ+AMfpRWQfdhW6er0ekyZNAgB8/PHHcHK6cSFuMBjkOeXl5QAAtVpt1b6Li0tgMkkWz9doGkGvv2bVMewR+7AvjtIH4Di91LYPJydFrS7m7GJ5AQCys7Px3HPPwcPDA+vWrUOzZs3QpEkTaDQa6HQ6eZ5Op4OHhwdcXOzq3wsiIovYRXJduXIFkZGRCA0NxfTp0822hYaGIikpCY888ggqKyuxatUqDBs2zEaVEhHdG7sI3R07dkCv12Pjxo34/PPP5fHevXtj8eLFiI+PR2hoKCorKxEWFsbbxYio3lJIkmT5Qmc9xjXd+o192B9H6eWBXdMlInoQMHSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFADF0iIoEYukREAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXSIigRi6REQCMXSJiARi6BIRCcTQJSISiKFLRCQQQ5eISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIYuEZFA9SJ0s7KyMGrUKPj5+SEoKAgHDx60dUlERLVi96FrNBoRGxuLwYMH46effsK0adMwZcoU/P7777YujYjIanYfuunp6TAYDHjxxRfh6uqK/v37IzAwEF9++aWtSyMispqLrQu4m7y8PHh5eUGhUMhjnp6eyMnJqbNjbnk/EeUlbeps/0Rkf1QNLyJ8yuQ6P47dh25ZWRnc3d3Nxtzd3VFeXm7Vflq0aHg/yyIiB6TRNKrzY9h96KrVahgMBrMxg8EAtVpt1X6Ki0tgMkkWzQ2fMhkaTSPo9desOoY9Yh/2xVH6ABynl1v7sKYfJydFrS7m7H5N18vLC2fPnjUb0+l06NSpk40qIiKqPbsPXa1WC2dnZ6xevRpGoxFpaWlIT09HSEiIrUsjIrKa3YeuUqnERx99hO+++w6PPfYYFi9ejISEBDz88MO2Lo2IyGp2v6YLAN7e3ti4caOtyyAiumd2f6VLRORIGLpERAIxdImIBGLoEhEJxNAlIhKoXty9cD84OSnuPuk+vMYesQ/74ih9AI7Ti8h8UEiSZNl7Y4mI6J5xeYGISCCGLhGRQAxdIiKBGLpERAIxdImIBGLoEhEJxNAlIhKIoUtEJBBDl4hIIIbuLbKysjBq1Cj4+fkhKCgIBw8etHVJFtu8eTO6deuGRx99VP5v+/btMBqNiIuLg1arhVarxYIFC1BVVWXrcm8rIyMDgYGB8vd3q33fvn0YNGgQ/Pz8MGbMGJw7d84GVVf39z4MBkO1cxMZGSlvt7c+MjIyEBERgYCAAPTr1w/Lly+HJEn18nzcqRebnhOJJEmSpOvXr0tPPfWUtHbtWsloNErffvut5OfnJxUUFNi6NIvMmTNHWrp0abXxJUuWSBEREdKVK1ekP/74QwoLC5M+/PBDG1RYs927d0v+/v6Sn5+fPFZT7dnZ2ZKfn5/0008/SdevX5eWLl0qBQcHS1VVVbZqQZKk2/dx7NgxqXfv3redb299lJSUSI899pi0fv16qbKyUjp79qz09NNPSxs2bKh356OmXmx5Tnil+1/p6ekwGAx48cUX4erqiv79+yMwMBBffvmlrUuzyOnTp9G1a9dq49u3b0d0dDSaNm2KNm0wi8YjAAAGZUlEQVTaICYmBtu2bbNBhXeWkJCANWvWYMKECWbjNdW+a9cu9OnTBwEBAVAqlZg8eTKKiopw/PhxW7QA4M593OncAPbXxx9//IFevXphzJgxcHZ2hoeHBwYOHIhff/213p2Pmnqx5Tlh6P5XXl4evLy8oFD878lBnp6eyMnJsWFVlqmoqEB2djZSUlLw5JNPYuDAgVi9ejWuXr0KvV4PLy8vea6npyfy8/NhNBptWLG5iIgIpKSkoFu3bvLYX3/9VWPteXl56NSpk7zN2dkZ7du3R25urtDab3W7PoAboavX6zF06FA8/vjj8l9iAHbXR6dOnZCUlCR/bzQacejQIfj4+NS781FTL7Y8Jwzd/yorK4O7u7vZmLu7O8rLy21UkeX+/PNP9OzZE8OHD0daWhqWLVuGjRs3YsOGDQAAlUolz1WpVPKalr1o3bp1tbGysjIAd679dudLpVLJr7OF2/UBAGq1Gv7+/vj000+xd+9euLm5ITY2FsDt/7+zdR83GY1GTJ06FUqlEsHBwQDq1/m41a29jB492qbn5IF5nu7dqNXqakFkMBigVqttVJHlWrdujc8++0z+/pFHHsHYsWOxc+dOADDr6+Y/Ivbe182/3HeqXaVS4fr162avKS8vR4MGDcQVaaE333zT7PtZs2bhX//6FwoKCuy2D71ej0mTJgEAPv74Yzg53bg+q4/n4++9qNVqm54TXun+l5eXF86ePWs2ptPpzH7MsFdZWVlYsWKF2dj169eh0Wig0Wig0+nkcZ1OBw8PD7i42Pe/t02aNKmx9k6dOpltq6qqwvnz581+/LUHkiQhISHBrNabSztubm522Ud2djaee+45eHh4YN26dWjWrFm9PR+368XW54Sh+19arRbOzs5YvXo1jEYj0tLSkJ6ejpCQEFuXdlcNGjTA6tWrsW3bNphMJmRkZGDDhg0YMWIEQkNDkZSUhOLiYhQVFWHVqlUYNmyYrUu2SE21DxkyBAcOHMDRo0dhNBqRmJiIli1bwtfX18ZVm1MoFDh9+jQWLVqEa9eu4erVq5g/fz769u0LjUZjd31cuXIFkZGRGDJkCBYuXAilUilvq2/n40692Pyc3Jd7IBxEVlaW9Pzzz0uPPvqoFBQUJKWlpdm6JIsdPnxYevbZZyU/Pz/pqaeekjZs2CBJkiQZDAZp7ty50uOPPy4FBgZK77zzjlRZWWnjam/vxx9/NLvV6m61p6amSkFBQZKfn580evRoSafT2aLsav7ex+XLl6UpU6ZIgYGBkr+/vzR16lTp//7v/+Tt9tTH2rVrJW9vb8nX11fy8/OT/5s0aVK9Ox819WLLc8KP6yEiEojLC0REAjF0iYgEYugSEQnE0CUiEoihS0QkEEOXiEgghi4RkUAMXXJIXbp0wYEDB4Qcq7S0FFu2bBFyLKr/+OYIckh6vR5NmjQxextrXVmxYgXS0tKQkpJS58ei+s++n3pCVEsajUbYsXjdQtbg8gI5pFuXF8aOHYvExETExsaiZ8+e6Nu3r9lywNixY5GQkICoqCj07NkTQ4cOxeHDh822x8fH33b/KSkpWLFiBU6fPo0uXbqgoKBATINUbzF06YHw0UcfoXfv3ti9ezcGDhyIuXPn4vLly/L25ORk+cM8+/bti9jY2GqP+ryd4OBgREZGwsfHB0eOHME//vGPumyDHABDlx4IWq0WERERePjhhzFlyhRUVFQgMzNT3u7v74+JEyfCy8sLr7/+Ory8vLB169a77tfd3R1qtRrOzs7QaDRwdnauyzbIATB06YHg4eEhf92wYUMAQGVlpTwWEBBgNr9nz5714vPxqP5h6NIDwdXVtdrYrb8A+/sValVVlfwRNX93a1gTWYuhS4Qbn9h7kyRJOHnyJHx8fAAASqUSpaWl8vYLFy6YvfbWT5AmuhuGLhGAtLQ0bNiwAWfPnsWiRYtQUFCAkSNHAgC6d++Ob7/9Fr/88gsyMzMxd+5cs/t/1Wo1Ll++jAsXLvAqmO6KoUsEICQkBN9++y3CwsLw888/Y+3atXjooYcAAJGRkfD390dkZCRiYmIQGhqKNm3ayK8dPHgwGjRogODgYPz222+2aoHqCb4jjR54Y8eORffu3TFjxgxbl0IPAF7pEhEJxNAlIhKIywtERALxSpeISCCGLhGRQAxdIiKBGLpERAIxdImIBPp/dcxYo5swdwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:00<00:00, 301.88it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:00<00:00, 309.76it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 313.09it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, val_lists in plot_dict.items():\n",
    "    plt.xlabel('input')\n",
    "    plt.ylabel('probability')\n",
    "    plt.title('graph for label: {0}'.format(label))\n",
    "    for i in tqdm(range(len(val_lists))):\n",
    "        plt.plot(np.arange(0, len(val_lists)), [pt[:5] for pt in val_lists])\n",
    "#     plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:00<00:00, 5854.51it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253/253 [00:00<00:00, 3402.46it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:00<00:00, 3523.03it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAFWCAYAAADKT050AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlcVOXCB/DfsAyLC4qg5haBASoiBi+oaJIrYkJuZKZWkut1KW8u5U2z5SpqmQtpvtqmZuWCt9y4Jrnlcs1M1GRX0RAcEReWYWDmef/w9VwnFQZjHmbg9/18/ATPnHOe3xynn4czhzkqIYQAERFJYVPdAYiIahOWLhGRRCxdIiKJWLpERBKxdImIJGLpEhFJxNIli3L58mX4+PggNTXV5HV++eUX9OrVC+3bt8fGjRv/coZjx47Bx8cHhYWFJi3v4+ODn3766ZHnq8z6JSUlWLhwIcLCwhAYGIhXXnkFaWlpjzw3ycfSJasXFxcHDw8P7Nq1CwMGDKjuOGa1ePFiJCQkYP78+di0aRPc3NwwevRoFBQUVHc0MhFLl6zerVu34O/vjxYtWqBu3brVHcdsDAYD4uPjMW3aNHTu3Bmenp744IMPcPv2bRw9erS645GJWLpUrj/++AMxMTEICAhAnz598O2338LHxwfAf08FfPLJJwgODsaYMWMAAN9//z0GDBgAPz8/PPXUU5gwYQKuXbsG4M6P7kFBQdi6dSu6du2KoKAgzJ49G8XFxUbzHjp0CP3790f79u0xdOjQh/4I3aNHD5w5cwZxcXFKroKCArz//vt4+umn0aFDB8TExCAzM1NZx8fHBx9//DG6dOmCyMhI6PX6cvdBUlISXnrpJXTs2FHJ89tvv923zIABA9C+fXuMHDkSGRkZymMFBQV4++23ERwcjJCQEEyZMgW5ubkPnGv58uXK8/gzg8GApUuXIjQ0VBmzsbnzv/CtW7fKfQ5kQQTRQ5SWlor+/fuLV199VaSkpIi9e/eKzp07C29vbyGEEJcuXRLe3t7i+eefF+fPnxepqanixIkTol27diI+Pl5cvnxZHD58WHTv3l289957Qgghjh49Ktq0aSMiIiLEiRMnxH/+8x/Ro0cPMXPmTKNt9unTR/znP/8RqampYujQoeL5559/YMa8vDwRGRkpFixYIK5evSqEEGL06NHi2WefFcePHxfJycliwoQJIiwsTBQVFQkhhPD29ha9evUSaWlp4vfff79vm0ePHhXe3t6ioKBA3L59WwQHB4v58+eLixcvit9//12MGjVKDBgwQFne29tbBAYGil27donU1FQxbtw4ER4eLvR6vRBCiNdff12MGDFCJCUliZSUFDFlyhTx7LPPitLSUmX9xMREIYQQBQUFyvMwxfr160WbNm3EpUuXTF6HqhdLlx7q4MGDol27diIvL08Z+/rrr+8r3R07diiPnzlzRmzdutVoO++++64YNWqUEOK/hXb8+HHl8T179oh27dqJ27dvK9tMSEhQHt+2bZvw9/d/aM6BAweKZcuWCSGESElJEd7e3iIpKUl5vLCwUAQHB4tvv/1WCHGn5D799NOHbu/e0tVoNGL16tVKQQohxO7du4Wvr6/yvbe3t1i1apXyfV5enmjXrp34+eefRVZWlvD29hY5OTnK4yUlJSIgIED89NNPyvp3S7cyjh07Jtq3by8+/PDDSq9L1ceuuo+0yXKlpKSgefPmcHV1VcY6dux433ItWrRQvm7Xrh3q1KmDuLg4ZGRkICMjA2lpaQgMDFSWsbW1RUBAgPJ9+/btUVpaiszMTGWuVq1aKY/Xr18fWq3WpMzp6emwt7eHn5+fMubs7Iy2bdsanaJo2bKlSdtzc3NDdHQ0vv76ayQnJ+PChQv4/fffYTAYjJbr0KGD8rWrqyuaN2+O1NRUlJSUAADCw8ONli8uLkZmZibCwsJMyvFnBw4cwJQpU9CzZ0+89tprj7QNqh4sXXooOzs7CBM+hM7R0VH5+vDhwxg3bhwiIiIQFBSEUaNGYfv27UhJSVGWsbGxUc5FAlAKzNbW1miZR+Hg4PDAcYPBYFSU92YuT25uLoYOHYonnngCTz/9NCIiIpCfn4833njDaLl7s9+dz97eHnq9Hvb29ti2bdt923ZxcTEpw5/t3LkTM2bMQL9+/bBgwYJH3ldUPfi3RQ/l7e2N7OxsXL9+XRk7ffp0uet89dVX6NevH2JjYzF8+HAEBATg4sWLRuVdWlpqdB3uqVOn4ODggCeeeOIvZ/by8kJpaalRzqKiIiQnJ8PT07PS29uxYwfs7OzwxRdfICYmBl27dkVOTg4AGD2n5ORk5evc3FxkZ2ejdevW8PT0RGlpKYqKivD444/j8ccfh5ubG+bPn48LFy5UOs+hQ4cwffp0DBw4ELGxsfeVPVk+li49VKdOneDp6Yk333wTqampOHjwIJYuXVruOo0bN0ZSUhLOnj2L8+fPY8mSJThw4AB0Op3Rcm+//TbOnj2Lo0ePYuHChRg6dCicnZ3/cmYPDw/06dMHs2fPxi+//IKUlBTMnDkTdnZ26N+/f6W316RJE1y7dg379u3D5cuXsXXrVqxcuRIAjJ7TihUrsHfvXiQnJ2PGjBlo164dQkJC4OnpiR49emDGjBn45ZdfkJGRgenTp+PMmTPw8vK6b77CwkJoNJoHZikpKcGsWbPQsWNHTJ48GXl5edBoNNBoNPdd/UGWi6VLD6VSqRAXFwetVovBgwfj/fffx9ChQ2Fvb//QdaZMmYJWrVphxIgReOGFF5CamoqZM2ciPT1dOb8JAP3790dMTAymTp2Kvn37YtasWVWW+5///Cfat2+PCRMmYNiwYSgpKcH69evRoEGDSm+rX79+iI6OxqxZsxAZGYlvv/0W77//PlQqFc6cOaMsN2HCBCxcuBDR0dFwdHTE8uXLlcdiY2Ph5+eHv/3tbxgyZAi0Wi2++OIL1KtX7775PvvsM3Tt2vWBWU6cOAGNRoPjx4+jW7du6Nq1q/Jny5YtlX5uVD1UwpSTdlQr5eXl4cyZM+jevbsytmvXLixevBh79+59pG0eO3YMo0aNwq+//oo6depUVVQiq8EjXXoolUqFSZMm4fPPP8fly5dx4sQJrFixAhEREdUdjchq8eoFeihXV1csXboUS5cuxZIlS+Di4oKoqChMmTKluqMRWS2eXiAikoinF4iIJGLpEhFJxNIlIpKoxryRlp9fCIPB9NPTjRrVRV6e9XzwszXltaasAPOakzVlBYzz2tio0LBh1V/WWGNK12AQlSrdu+tYE2vKa01ZAeY1J2vKCpg/L08vEBFJxNIlIpKIpUtEJBFLl4hIIpYuEZFELF0iIolqzGcv5OUVmHSpR+qrL5s/DBFZPO81X9w35u5eDxrNbQB3rtNt1Khulc9bq450WbhEdFd19UGtKl0iourG0iUikoilS0QkEUuXiEiiWlW6D3q3kohqp+rqg1p3ydhd914aYg2sKa81ZQWY15ysKSvAS8aIiGocli4RkUQsXSIiiVi6REQSsXSJiCRi6RIRScTSJSKSiKVLRCQRS5eISCKWLhGRRCxdIiKJWLpERBKxdImIJGLpEhFJxNIlIpJIaukmJSUhOjoagYGB6NGjB9atWwcA0Ol0mDt3LkJCQhASEoL58+dDr9fLjEZEJIWdrIkMBgMmTJiA6dOn47nnnsO5c+cwfPhwtGnTBvv370d6ejoSEhKg1Woxfvx4rF27FmPHjpUVj4hICmlHujdv3sS1a9dgMBhgMBigUqlgY2MDe3t7xMfHY+zYsWjQoAGaNm2K8ePHY8uWLbKiERFJI610GzZsiBdffBFvvfUW/Pz8EBUVhdGjR+OJJ56ARqOBl5eXsqynpycuXrwInU4nKx4RkRRSTy84OTlh0aJF6Nu3L06ePIlJkyahefPmAAAnJydlWScnJwghoNVqoVarTdr+o9zLyN29XqXXqU7WlNeasgLMa07WlBUwf15ppbtnzx4cO3YM06dPBwCEhIRg0KBBiI+PBwBotVpl2eLiYgCAs7OzydvnjSkthzVlBZjXnKwpK1DDbkyZnZ193+kCOzs7uLq6wt3dHZmZmcp4ZmYmPDw8YGcn7d8EIiIppJVuaGgoMjMzsXHjRgghcPr0aWzevBn9+/dHZGQk4uLikJeXh9zcXKxatQrPPfecrGhERNJIO5T09vZGXFwcli5disWLF8PNzQ1vvPEGevXqhW7duiE2NhaRkZEoKytDVFQULxcjohpJJYQw/USoBeM5XcthTVkB5jUna8oK1LBzukRExNIlIpKKpUtEJBFLl4hIIpYuEZFELF0iIolYukREErF0iYgkYukSEUnE0iUikoilS0QkEUuXiEgili4RkUQsXSIiiVi6REQSsXSJiCRi6RIRScTSJSKSiKVLRCQRS5eISCKWLhGRRCxdIiKJWLpERBKxdImIJGLpEhFJxNIlIpKIpUtEJBFLl4hIIpYuEZFELF0iIolYukREErF0iYgkYukSEUnE0iUikoilS0QkEUuXiEgili4RkUQsXSIiiVi6REQSsXSJiCRi6RIRScTSJSKSiKVLRCQRS5eISCK76g5ARNZBCIH8fA10Oi0AYdI6V6/awGAwmDfYX2Bra4e6dRvAyamOtDlZukRkkoKCm1CpVGjSpAVUKtN+SLazs0FZmWWWrhACpaU63LihAQBpxSv19MLVq1cxceJEBAYGIjQ0FEuXLgUA6HQ6zJ07FyEhIQgJCcH8+fOh1+tlRiOiChQXF6BevQYmF66lU6lUUKsd0KCBOwoKbkibV+qR7sSJE+Hn54cjR44gNzcXI0eOhJeXF1JSUpCeno6EhARotVqMHz8ea9euxdixY2XGI6JyGAx62NrWvB+O7e3V0OvLpM0n7Z+sU6dO4eLFi3jrrbegVqvRsmVLrFu3DsHBwYiPj8fYsWPRoEEDNG3aFOPHj8eWLVtkRSMiE6lUquqOUOVkPydppXvmzBl4e3tj2bJl6Nq1K3r27Ik9e/bA0dERGo0GXl5eyrKenp64ePEidDqdrHhERFJI+1nh5s2bOHnyJEJCQpCYmIjMzEzExMTA1dUVAODk5KQs6+TkBCEEtFot1Gq1Sdtv1KhupTO5u9er9DrVyZryWlNWgHlNcfWqDezsKn+c9ijryGZjY6PsU3PvW2mlq1ar4eTkhMmTJ0OlUsHX1xeDBg1CfHw8AECr1SrLFhcXAwCcnZ1N3n5eXgEMBtMuYwHu7FiN5rbJy1c3a8prTVkB5jWVwWCo9JUI9169cOvoYVzbugVl1/Ng59oIboMGo36nLuaIWmkGgwEazW2jfWtjo3qkg7mKSPsnyNPT8///0v57wrqsrAwuLi5wd3dHZmamMp6ZmQkPDw/Y2dW8k/ZEtdGto4eR+9UXKLueBwAou56H3K++wK2jh6s5mXzSSjc0NBT169fHkiVLoNPpkJycjK1bt6J///6IjIxEXFwc8vLykJubi1WrVuG5556TFY2IzOza1i0Qf3qPRuh0uLbVfG+Y//TTj3j11VHo168HwsPD8N57c4wO+qqLtENJBwcHrF+/Hu+99x66desGtVqNsWPHom/fvggLC0NsbCwiIyNRVlaGqKgoXi5GVIPcPcI1dfyvunIlG++/PxdLlsTB3z8Aly9fwrhxL2P//kT07NnHLHOaSurP7y1btsTq1avvG3dwcMCcOXMwZ84cmXGISBI710YPLFg710Zmmc/NzR3r1n2HZs2a49atm8jPv4769V2g0Vw1y3yVwZOmRGR2boMGI/erL4xOMajUargNGmyW+ezs7LBjx/fYvn0bHBwc4e3tg9LS0kq92W4uLF0iMru7VynIunphz54E7N69A2vWrIO7e2MAwEsvDTPLXJXF0iUiKep36iLtErGiogLY2tpCrVajrKwM27ZtRkZGutRf930Yli4R1Tj9+g3Ar7+ewNChUVCr1WjfvgP69OmHCxfOV3c0li4R1TwODg5499351R3jgSz/9/OIiGoQli4RkUQml+6sWbNw5MgRCFH9l1wQEVkrk8/pCiEwefJkODk5oX///oiKikKbNm3MmY2IqMYxuXRjY2Oh0+mQmJiInTt3YtiwYWjRogUiIyPRv39/tGjRwpw5iYhqhEqd01Wr1QgPD8eyZctw+PBh9OvXD5988gl69+6NF198Edu3bzdXTiKiGqHSl4ydO3cOO3fuxK5du3D16lWEhYVhwIABuHr1KhYuXIhDhw5hwYIF5shKRGT1TC7dZcuWYefOncjKykJgYCDGjRuH8PBw1Kv3309Zr1+/PubMmcPSJSJ6CJNLNyEhAQMHDsSAAQPQrFmzBy7j6+uLd999t8rCERE9iitXsjF0aCS2b/8RDRo0qO44Rkwu3X79+mHUqFFG9zIDgIKCAixfvhxvvvkmnnzySTz55JNVHpKIrN+RsznYuj8DebdK0Ki+AwZ190Lndk2rO5Z05ZZubm4ubt++c7+guLg4dOrU6b5/Nc6dO4dvvvkGb775pvlSEpFVO3I2B1/uSobu/++XlnerBF/uSgYAsxbvli3fYvv2f6G0VIdhw0bgxRdfqvbbyJdbuqdPn8akSZOUkCNGjHjgckOHDq36ZERUY2zdn6EU7l26MgO27s8wa+leuHAeGzZsRk5ONqZOnYhmzVqgR49eZpvPFOWWbq9evZCYmAiDwYBevXph06ZNyi3TAUClUsHZ2dnizpkQkWXJu1VSqfGqMmnSa3B2doanZ2sMGPAcfvwxwbJLF4DypllycrLZwxBRzdSovsMDC7ZRfQezzWljY4MmTf57FN24cWMcP37MbPOZqtzSHTJkCNauXQsXFxcMGTKk3A1t3ry5SoMRUc0xqLuX0TldAFDb2WBQdy+zzWkwGJCXdw2NGrkBAHJyctC06WNmm89U5ZZuWFgY1Go1AKB79+7VfgKaiKzT3fO2sq9eWLlyOaZNm4nLl7Pwww/xmDPnfbPOZ4pyS3fSpEnK15MnTzZ7GCKquTq3ayr1EjFbW1s0b94Cgwb1R7169TBu3CSEhHSWNv/DlFu6CxcuNHlDM2bM+MthiIiqwmOPNcP+/XfO377yyphqTmOswkvGiIio6pRbuuvWrZOVg4ioVii3dDds2IAhQ4bAwcEBGzZseOhyKpUKw4cPr/JwREQ1Tbmlu3btWkRERMDBwQFr16596HIsXSIi05RbuomJiQ/8moiIHk2lP8T8yJEjSEtLg729PZ588kkEBQWZIxcRUY1kculmZmZi0qRJuHTpEpo1awYhBLKzs+Hn54dly5ahcePG5sxJRFQjmHyPtHfeeQetWrXCgQMHkJCQgH//+9/Yu3cvHB0dMXfuXHNmJCKqMUw+0v3tt98QHx+Phg0bKmNNmjTBrFmzMGzYMLOEIyKqaUw+0n388ceRmZl533h2djaaNq19n/5ORPQoyj3S3b9/v/J17969MXv2bFy4cAEdOnSAjY0NUlJSsGLFCowfP97sQYnIuhVcP42b2YnQl96Erb0LXJr1QF3X9tUdS7pyS3fcuHH3jX344Yf3jS1YsAAvvfRS1aUiohql4Ppp5GdthxClAAB96U3kZ20HALMVb1LSb1ix4mOcP5+JRo3cMGbMBPTs2dssc1VGuaXLDy4noqpwMztRKdy7hCjFzexEs5Rufv51TJ8+FWPH/g1RUYNw5kwS/v73yfDx8UWLFi2rfL7KMPmc7sPodDqcPHmyKrIQUQ2lL71ZqfG/6vDhQ2jUyA2DB0fDzs4OAQFP4ZNP1hpdCFBdTL564dSpU5g7dy7S0tJgMBjfYE6lUuH333+v8nBEVDPY2rs8sGBt7V3MMt/169fRuHETozEfH1+zzFVZJh/pfvDBB2jQoAE++ugjODo6YtGiRZg2bRqcnZ0feJ6XiOgul2Y9oFLZG42pVPZwadbDLPM1btwYGs1Vo7HvvtuI5OTqPzg0uXSTk5Mxa9Ys9O3bF23btoWrqyvGjBmD2bNn48svvzRnRiKycnVd26Nhq2eVI1tbexc0bPWs2d5E69w5FPn5+di2bQv0ej1OnjyBtWtXoU6dumaZrzJMPr1ga2uLunXvBPbw8EBKSgq6dOmCkJAQ/POf/zRbQCKqGeq6tpd2iVj9+i5YvHgpli//CCtXLoO7e2O8/fZ7aNmylZT5y2Ny6Xbo0AFff/013njjDfj6+iIxMRGvvPKK8uE3RESWpG1bP6xc+Vl1x7iPyaU7bdo0jB07Fo0aNcLQoUOxZs0a9OzZE3l5eRg6dKg5MxIR1Rgml66/vz/27t0LrVaL+vXrY9OmTdixYweaNGmCfv36mTMjEVGNUanP061Tpw6uX7+O3377Dfb29ujTpw+aN29urmxERDWOyaWr0Wgwa9Ys/Pzzz1Cr1TAYDNDr9YiIiMC8efOUN9mIiOjhKvV5ugUFBfj++++RlJSE06dP49tvv0V6ejree+89kycsKipCeHi4cs+127dvY+rUqQgKCkJoaChWr15d+WdBRGQlTC7dn3/+GfPmzYO3tzeAO7+F5u/vj/feew979uwxecL3338fFy9eVL6/+wHoBw8exFdffYWNGzdi586dJm+PiMiamFy6bm5uyM/Pv2/87htrpti1axcuXLiAp556CsCdo96EhARMnjwZTk5O8PLywogRI7B582ZTYxERWZVySzc9PV35M2zYMLz11lvYuXMn/vjjD+Tk5GDfvn2YPXs2Jk6cWOFE2dnZWLRoERYuXAgbmzvTXrx4EQaDAU888YSynKenJ9LS0v7i0yIiskzlvpH27LPPQqVSQQihjE2bNu2+5ebOnYvo6OiHbkev12P69OmYOnUqWrRooYwXFhZCrVbD1tZWGXN0dERxcXGlngQANGpU+Tfy3N3rVXqd6mRNea0pK8C8prh61QZ2dpX/YMJHWUc2GxsbZZ+ae9+WW7p79+6tkklWrlyJJk2aICoqymjc2dkZpaWlMBgMytGvVquFs7NzpefIyyuAwSAqXvD/ubvXg0Zzu9LzVBdrymtNWQHmNZXBYEBZmaHiBe9hZ2dT6XXMZcaM1+Dj0wYxMfffnMFgMECjuW20b21sVI90MFeRckv3QdfgZmVlKR/v6OXlBU9Pzwon2b59O65evYqgoCAAd87lnjp1Cunp6VCpVLhw4YKynczMTLRu3fpRngsRWTgbGxXq1XPErVtao5+gaxOTr9MtLCzE7NmzsXv3btjb20MIAb1ejy5dumD58uXlHp3u3r3b6PuRI0ciLCwMMTExKCoqwocffojY2Fjk5uZi/fr1eP311x/9GRGRxXJ2VsPe3hZ16qhRUFBi1rl+/fUXLF36If744xKCgzujsLDQrPOZyuSTLQsWLEBqaiq+++475Trdb775Brm5uVi8ePEjB3j33Xfh6OiInj174qWXXsKwYcMQGRn5yNsjIstkY6OCo6M9VKr//tdc8vPzMWvW3zFkyPPYvXsfevbsjVOnLOMONyYf6f773/9GXFwc/P39lbEOHTpg7ty5mDp1KubMmWPypOvWrVO+dnFx4YegE9UCzs5qo+/NebR7+PBBuLu7Y8CA5wAAPXv2QXy8ZVyKavKRrhDigfcXatCgAYqKiqo0FBHVLPce5QIw+9FuXt41uLs3Nhp77LFmZpmrskwu3f/5n//BihUroNPplDGdToe4uDgEBgaaJRwR1Qx/Psq9q06dB4//Ve7ujZGTk2M09ufb91QXk0t3xowZOH78uPIGWExMDMLCwnDq1Cm89dZb5sxIRFbOzs72vqNalUoFOzvbh6zx14SGdsOtWzfx3XcbUVZWhgMH9uHXX38xy1yVZfI53VatWmHnzp34/vvvkZGRAQcHB4SHh2PAgAFwdHQ0Z0YisnI3bsg9BVm/vgsWLVqKjz6KxaefroCfXwd06tRFaoaHMbl0Bw4ciAULFmDEiBHmzENEVCXatfPD2rXrKl5QMpNPL2g0GqjV5jn/QkRUW5h8pBsdHY0JEyYgOjoaLVq0uO+UQvfu3as8HBFRTWNy6a5cuRIAsGjRovseU6lUOHfuXNWlIiKqoUwu3eTkZHPmICKqFSp1Y0q9Xo/Dhw8jLS0NNjY2aNOmDYKDg83663xERDWJyaV76dIlvPrqq8jOzkazZs1gMBhw5coVeHt7Y/Xq1XBzczNnTiKiGsHkqxfmzp2Lli1bYt++fUhISMCePXuQmJiIBg0a4N133zVnRiKiGsPkI92TJ09i06ZNaNSokTLWuHFjzJw5Ey+88IJZwhER1TQmH+m2aNEC6enp943n5OSgcePGD1iDiIj+zOQj3VGjRmHevHm4cOECAgMDYWtri7Nnz2LVqlWIjo7G/v37lWV5zS4R0YOZXLpvv/02AODjjz++77G71/ACvGaXiB7MYBBIOJ6FnUcvon+nx9Hnf1rBxqb2XfnE63SJyOxyrxfhk21nkJtfBF2pAdsOncfR33MxIcoPTVwrfyNaU5w/n4mPP16MlJRzcHV1xUsvxaBv3wizzFUZlbpOl4jorp9PX8GhpCvlLqNSAUIA6X/chP6eu3XrSg3Iyi3AP9YcQ+vmLibN19X/MYS2f8ykZYuKivD6639DdPQL+PDDZUhLS8GMGa+jceMm6Nixej//2/JvSE9EVk9t/+CqUdub5/N0jxw5BEdHJwwfPgp2dnZo06Yd+vePxPffx5tlvsrgkS4RPZLQ9hUfedrZ2aCszIAjZ3Kw7t8p0Or0ymMOaluM6O2Nzn5NqzxbTs4VXLnyB8LDw5Qxvd4AHx/fKp+rsli6RGR2HVq7YcOeVKMxW5UKHVqb5zdZ3dzc8eSTPliz5itl7Nq1a7CETyxg6RKR2Tk72mHF609Lm69z565YvnwJtm/fhvDwZ3H1ai7+/vfJ6NWrL2JixknL8SAsXSKqcerXr48lS1Zg2bKPsGLFUjg4qNG7dz+89FJMdUdj6RJRzfTkkz5YvvzT6o5xH169QEQkEUuXiEgili4RkUQsXSIiiVi6RGQyIUTFC1kZIQwA5F3Ay9IlIpPY2alRWHirxhSvEAJlZaW4ceMa1GpHafPykjEiMknDhu7Iz9egoOCGyevY2NjAYDCYMdVfY2NjCyenuqhb17QP3akKLF0iMomtrR3c3Ez7lK+73N3rQaO5baakdQwnAAAQo0lEQVRE1omnF4iIJGLpEhFJxNIlIpKIpUtEJBFLl4hIIpYuEZFELF0iIolYukREErF0iYgkYukSEUnE0iUikoilS0QkEUuXiEgiqaWblJSE4cOHIygoCGFhYVi+fDmEENDpdJg7dy5CQkIQEhKC+fPnQ6/Xy4xGRCSFtI92LCwsxLhx4/C3v/0N69atw6VLlxATEwNXV1fk5OQgPT0dCQkJ0Gq1GD9+PNauXYuxY8fKikdEJIW0I90rV67gqaeewogRI2BrawsPDw/07t0bv/76K+Lj4zF27Fg0aNAATZs2xfjx47FlyxZZ0YiIpJFWuq1bt0ZcXJzyvU6nw4EDB+Dr6wuNRgMvLy/lMU9PT1y8eBE6nU5WPCIiKarlzhE6nQ7Tpk2DWq1GREQEFi9eDCcnJ+VxJycnCCGg1WqhVqtN2majRnUrncPdvV6l16lO1pTXmrICzGtO1pQVMH9e6aWr0WgwefJkAMDnn38OG5s7B9tarVZZpri4GADg7Oxs8nbz8gpgMJh+wzxru42INeW1pqwA85qTNWUFjPPa2Kge6WCuIlKvXkhNTcXgwYPh4eGBr776Cg0bNoSLiwvc3d2RmZmpLJeZmQkPDw/Y2fEWbkRUs0hrtfz8fIwePRqRkZGYMWOG0WORkZGIi4tD27ZtUVZWhlWrVuG5556TFY2ISBpppbtt2zZoNBp8/fXX2LhxozLerVs3LFq0CLGxsYiMjERZWRmioqJ4uRgR1UgqIYTpJ0ItGM/pWg5rygowrzlZU1agBp7TJSKq7Vi6REQSsXSJiCRi6RIRScTSJSKSiKVLRCQRS5eISCKWLhGRRCxdIiKJWLpERBKxdImIJGLpEhFJxNIlIpKIpUtEJBFLl4hIIpYuEZFEte4mZFkn373z32rOUVnWlNeasgLMa06WnLVVxznVMm+tOtK9W7hERNXVB7WqdImIqhtLl4hIIpYuEZFELF0iIolqVelW17uVRGR5qqsPat0lY3d39L33t7cG1pTXmrICzGtO1pRVllp1pEtEVN1YukREErF0iYgkYukSEUnE0iUikoilS0QkEUuXiEgili4RkUQsXSIiiVi6REQSsXSJiCRi6RIRScTSJSKSiKVLRCQRS5eISCKWLhGRRCxdIiKJWLpERBKxdImIJGLpEhFJxNIlIpKIpUtEJJHFlG5KSgqGDRuGgIAAhIeHY//+/dUdiYioytlVdwAA0Ol0mDBhAkaOHIl169bhwIEDeO2117B9+3Y0b968SucavSCxSrdHRNbps1k9qmVeizjSPXbsGLRaLV5++WXY29ujZ8+eCA4Oxg8//FCl87Bwieiu6uoDiyjdjIwMeHl5QaVSKWOenp5IS0urxlRERFXPIk4vFBUVwdHR0WjM0dERxcXFJm+jUaO6VR2LiGo4d/d6Jo1VJYsoXWdnZ2i1WqMxrVYLZ2dnk7eRl1cAg0FUdTQiqsE0mttG37u711PGbGxUZjmYs4jTC15eXjh//rzRWGZmJlq3bl1NiYiIzMMijnRDQkJga2uL1atX4+WXX8ahQ4dw7Ngx/OMf/6jSeb5fHGl03piIai8hBK5dK5A+r0oIYRE/k6empuKdd95BcnIymjRpghkzZuCZZ54xef3Knl6498cIa2BNea0pK8C85mRNWQE5pxcs4kgXALy9vfH1119XdwwiIrOyiHO6RES1BUuXiEgili4RkUQsXSIiiVi6REQSWczVC3+VjU3lr799lHWqkzXltaasAPOakzVlBf6b11y5LeY6XSKi2oCnF4iIJGLpEhFJxNIlIpKIpUtEJBFLl4hIIpYuEZFELF0iIolYukREErF0iYgkqnWlm5KSgmHDhiEgIADh4eHYv3+/tLmTkpIQHBysfK/T6TB37lyEhIQgJCQE8+fPh16vVx7fvXs3+vTpg4CAAIwYMQIXLlxQHrty5QpiYmLQsWNH9OjRA1u2bFEeE0Jg6dKl6NKlCwIDAzFz5kwUFRWZnHH48OEICgpCWFgYli9fDiGERWYFgJ9++gkDBgxAx44d0bt3b3zzzTcWu2/vVVRUhPDwcKxduxYAcPv2bUydOhVBQUEIDQ3F6tWrjZbfsGEDunfvjo4dO2L8+PG4du2a8lh5r+mK9kNFvvvuO7Rr1w4dO3ZU/sTHx1vk/r169SomTpyIwMBAhIaGYunSpSbtA+lZRS1SUlIinnnmGfHZZ58JnU4nfvzxRxEQECAuX75s9rl37NghAgMDRUBAgDK2ePFiMXz4cJGfny+uXLkioqKixKeffiqEECI1NVUEBASI48ePi5KSEvHRRx+JiIgIodfrhRBCREdHiw8++ECUlJSIEydOiKCgIHHy5EkhhBAbN24U4eHhIjs7W9y4cUOMHj1azJkzp8KMBQUFolOnTmLdunWirKxMnD9/XvTo0UOsX7/e4rIKIcQff/wh/Pz8xMGDB4UQQpw7d060b99enDp1yiLz3uvNN98Uvr6+Ys2aNUIIIV5//XUxZcoUUVRUJNLT00VYWJjYsWOHEEKIAwcOiM6dO4uUlBRRVFQkZs6cKWJiYoQQFb+my9sPpnj77bfFRx99dN+4Je7fwYMHi7lz54qSkhKRlZUlunfvLn744QeLy1qrSvfui9dgMChjY8eOFStXrjTrvB999JEYOHCgWLt2rVHphoaGin379inf79q1S/Tp00cIcedFPWXKFOWxsrIyERgYKE6cOCEyMjJEmzZtxO3bt5XH582bJ/7xj38IIe68UNavX688lpSUJDp06CB0Ol25OdPS0sTEiRONxubPny+mTZtmcVnvurtdvV4vDh8+LAICAkRGRobF5hVCiJ07d4oXXnhBDB8+XKxZs0YUFhaKtm3birS0NGWZNWvWiFdeeUUIcaeQY2Njlcfy8vKEj4+PyMnJqfA1Xd5+MMWgQYPErl277hu3tP3722+/iaCgIFFSUqKMZWVlidzcXIvLWqtOL2RkZMDLy8vojsCenp5IS0sz67zDhw/H1q1b0a5dO2Xs1q1b0Gg08PLyMspy8eJF6HQ6ZGRkGN2C3tbWFq1atUJ6ejoyMzPRtGlT1K1b12jdu8/jz+t6enqiuLgYf/zxR7k5W7dujbi4OOV7nU6HAwcOwNfX1+Ky3lW3bl0UFBTAz88PL7/8MkaOHAk3NzeLzZudnY1FixZh4cKFsLG587/fxYsXYTAY8MQTT5g0p6urK1xcXJCenl7ua7qi11hFSktLkZqaiq1bt6Jr167o3bs3Vq9ejZs3b1rc/j1z5gy8vb2xbNkydO3aFT179sSePXvg6OhocVlrzEc7mqKoqAiOjo5GY46OjiguLjbrvE2aNHlgFgBwcnJSxpycnCCEgFarfWBWJycnFBUVwcHBodznUVRUdN92AVTqeep0OkybNg1qtRoRERFYvHixxWZ1cnLCb7/9huTkZIwZM0aZz9Ly6vV6TJ8+HVOnTkWLFi2U8cLCQqjVatja2j50zgflLS4uLvc1XdFrTK1Wl5v3+vXr8Pf3x6BBg7BixQqkp6dj4sSJKC0tLXe71bF/b968iZMnTyIkJASJiYnIzMxETEwMXF1dLS5rrSpdZ2dnaLVaozGtVgtnZ2fpWe7+Bd2b5+5flrOzM5ycnFBSUmK0TnFxMerUqVPh83Bycnrodk2h0WgwefJkAMDnn3+uHJFZYlbgztGJra0t/P39MWTIECQlJVlk3pUrV6JJkyaIiooyGnd2dkZpaSkMBoPRvr53zgfldXZ2LjdvRa+xijRp0gQbNmxQvm/bti1GjhyJf/3rX+Vutzr2r1qthpOTEyZPngyVSgVfX18MGjQI8fHxFpe1Vp1e8PLywvnz543GMjMzjX5EkMXFxQXu7u7IzMw0yuLh4QE7Ozu0bt3a6DG9Xo+srCx4eXnBy8sLubm5KCwsNFr37vP487qZmZlwcnJC8+bNK8yVmpqKwYMHw8PDA1999RUaNmxosVmPHDmC6Ohoo7HS0lLUr1/fIvNu374d+/btQ1BQEIKCgnDixAksXboU69atg0qlMnrXvLw5r1+/jhs3bih5H/aarujvrSIpKSlYsWKF0VhJSQnc3d0tbv96enrCYDCgrKxMGSsrK7PM1265Z3xrmJKSEvH000+LTz/9VJSUlIi9e/eKDh06iKysLCnzHz161OiNtNjYWPH888+La9euiZycHBEVFSU++eQTIYQQycnJIiAgQBw6dEh5V7Vv376irKxMCHHnndp33nlHaLVa8euvv4qgoCBx/PhxIYQQ69evF3369BFZWVnKu6qzZ8+uMN/169dFaGio0Zs2lppVCCHy8/NFSEiI+PLLL0VZWZk4fvy4CAoKEseOHbPIvH82YsQI5eqFKVOmiIkTJ4rbt28rVy/861//EkIIsW/fPtGpUydx5swZ5eqFl19+WQhR8Wu6vP1QkUuXLon27duLzZs3C71eL06dOiU6d+4sdu7caXH7V6vViqefflrExsaKkpISce7cOREcHCx2795tcVlrVekKIURKSop44YUXRMeOHUV4eLhITEyUNvefS1er1Yp58+aJLl26iODgYPHBBx8of9lCCJGQkCDCw8NFQECAePHFF0VmZqbyWHZ2thgzZowIDAwUzzzzjNi0aZPymF6vF8uWLRPdunUTQUFB4o033hCFhYUV5vvss8+Et7e36NChgwgICFD+TJ482eKy3pWUlCSef/558dRTT4lnn31WJCQkWOS+fZB7S/fGjRti2rRpIjg4WISGhopVq1YZLbthwwbRo0cP0bFjRzF27Fih0WiUx8p7TVe0Hypy8OBBMXDgQBEQECCeeeYZ5d16S9y/WVlZYsyYMSI4OFh07dpV2beWlpW36yEikqhWndMlIqpuLF0iIolYukREErF0iYgkYukSEUnE0iUikoilS0QkEUuXrJKPjw9++uknKXMVFhZi06ZNUuaimo+/HEFWSaPRwMXFpcJPyqoKK1asQGJiIrZu3Wr2uajmq1WfMkY1h7u7u7S5eFxCVYmnF8gq3Xt6YeTIkVi2bBkmTJgAf39/dO/e3eh0wMiRI7FkyRLExMTA398fAwYMwMGDB40ej42NfeD2t27dihUrVuDs2bPw8fHB5cuX5TxBqrFYulQj/O///i+6deuGHTt2oHfv3pg3b57RzRvXrl2r3FSxe/fumDBhwn0fifggERERGD16NHx9fXHo0CE89thj5nwaVAuwdKlGCAkJwfDhw9GyZUu89tprKC0tRXJysvJ4YGAgJk2aBC8vL7zxxhvw8vLC5s2bK9yuo6MjnJ2dYWtrC3d3d6O7OxA9CpYu1QgeHh7K13fvaXXvB1oHBQUZLe/v72/2e+MRPQhLl2oEe3v7+8bufQPsz0eoer1euTXOn91b1kRVjaVLtcLZs2eVr4UQOH36NHx9fQHcub/WvbdkuXTpktG6995pl+ivYulSrZCYmIj169fj/PnzWLhwIS5fvqzcX83Pzw8//vgjTpw4geTkZMybN8/o+l9nZ2dcu3YNly5d4lEw/WUsXaoV+vfvjx9//BFRUVH45Zdf8Nlnn6FZs2YAgNGjRyMwMBCjR4/G+PHjERkZiaZNmyrr9u3bF3Xq1EFERAR+//336noKVEPwN9Koxhs5ciT8/Pwwc+bM6o5CxCNdIiKZWLpERBLx9AIRkUQ80iUikoilS0QkEUuXiEgili4RkUQsXSIiif4PaXi7BmmjC6QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:00<00:00, 3757.52it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 5423.95it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, val_lists in plot_dict.items():\n",
    "    plt.xlabel('input')\n",
    "    plt.ylabel('probability')\n",
    "    plt.title('graph for label: {0}'.format(label))\n",
    "    a = []; b = []; c = []; d = []; e = [];\n",
    "    for i in tqdm(range(len(val_lists))):\n",
    "        for lst in val_lists:\n",
    "            a.append(lst[0])\n",
    "            b.append(lst[1])\n",
    "            c.append(lst[2])\n",
    "            d.append(lst[3])\n",
    "            e.append(lst[4])\n",
    "    plt.plot(np.arange(0, len(a)), a, 'ro', label='a')\n",
    "    plt.plot(np.arange(0, len(b)), b, 'bo', label='b')\n",
    "    plt.plot(np.arange(0, len(c)), c, 'yo', label='c')\n",
    "    plt.plot(np.arange(0, len(d)), d, 'w^', label='d')\n",
    "    plt.plot(np.arange(0, len(e)), e, 'p-', label='e')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_bar(data, series_labels, category_labels=None, \n",
    "                show_values=False, value_format=\"{}\", y_label=None, \n",
    "                grid=True, reverse=False):\n",
    "    \"\"\"Plots a stacked bar chart with the data and labels provided.\n",
    "\n",
    "    Keyword arguments:\n",
    "    data            -- 2-dimensional numpy array or nested list\n",
    "                       containing data for each series in rows\n",
    "    series_labels   -- list of series labels (these appear in\n",
    "                       the legend)\n",
    "    category_labels -- list of category labels (these appear\n",
    "                       on the x-axis)\n",
    "    show_values     -- If True then numeric value labels will \n",
    "                       be shown on each bar\n",
    "    value_format    -- Format string for numeric value labels\n",
    "                       (default is \"{}\")\n",
    "    y_label         -- Label for y-axis (str)\n",
    "    grid            -- If True display grid\n",
    "    reverse         -- If True reverse the order that the\n",
    "                       series are displayed (left-to-right\n",
    "                       or right-to-left)\n",
    "    \"\"\"\n",
    "\n",
    "    ny = len(data[0])\n",
    "    ind = list(range(ny))\n",
    "\n",
    "    axes = []\n",
    "    cum_size = np.zeros(ny)\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    if reverse:\n",
    "        data = np.flip(data, axis=1)\n",
    "        category_labels = reversed(category_labels)\n",
    "\n",
    "    for i, row_data in enumerate(data):\n",
    "        axes.append(plt.bar(ind, row_data, bottom=cum_size, \n",
    "                            label=series_labels[i]))\n",
    "        cum_size += row_data\n",
    "\n",
    "    if category_labels:\n",
    "        plt.xticks(ind, category_labels)\n",
    "\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    if grid:\n",
    "        plt.grid()\n",
    "\n",
    "    if show_values:\n",
    "        for axis in axes:\n",
    "            for bar in axis:\n",
    "                w, h = bar.get_width(), bar.get_height()\n",
    "                plt.text(bar.get_x() + w/2, bar.get_y() + h/2, \n",
    "                         value_format.format(h), ha=\"center\", \n",
    "                         va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-3be18339208b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mshow_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalue_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{:.1f}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0my_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-189-9f7c5ff66fb8>\u001b[0m in \u001b[0;36mstacked_bar\u001b[0;34m(data, series_labels, category_labels, show_values, value_format, y_label, grid, reverse)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         axes.append(plt.bar(ind, row_data, bottom=cum_size, \n\u001b[0;32m---> 38\u001b[0;31m                             label=series_labels[i]))\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mcum_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     return gca().bar(\n\u001b[1;32m   2456\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m             \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintervaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0mbar_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/speckles-ml/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2426\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "\n",
    "series_labels = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "data = [a, b, c, d, e]\n",
    "\n",
    "category_labels = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "stacked_bar(\n",
    "    data, \n",
    "    series_labels, \n",
    "    category_labels=category_labels, \n",
    "    show_values=True, \n",
    "    value_format=\"{:.1f}\",\n",
    "    y_label=\"Accuracy\"\n",
    ")\n",
    "\n",
    "# plt.savefig('bar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
